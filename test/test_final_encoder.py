#!/usr/bin/env python3
"""
æµ‹è¯•æœ€ç»ˆé‡æ„åçš„å¼‚æ„å›¾ç¼–ç å™¨ (HeteroGraphEncoder)
"""

import sys
sys.path.append('src')
sys.path.append('.')

import torch
from torch_geometric.data import HeteroData
from src.gat import create_hetero_graph_encoder

def create_test_hetero_data():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„å¼‚æ„å›¾æ•°æ®"""
    data = HeteroData()
    
    # èŠ‚ç‚¹ç±»å‹1: bus (æ¯çº¿)
    data['bus'].x = torch.randn(10, 14)  # 10ä¸ªæ¯çº¿èŠ‚ç‚¹ï¼Œ14ç»´ç‰¹å¾
    
    # èŠ‚ç‚¹ç±»å‹2: gen (å‘ç”µæœº)  
    data['gen'].x = torch.randn(3, 8)   # 3ä¸ªå‘ç”µæœºèŠ‚ç‚¹ï¼Œ8ç»´ç‰¹å¾
    
    # è¾¹ç±»å‹1: bus-bus (æ¯çº¿é—´è¿æ¥)
    data['bus', 'connects', 'bus'].edge_index = torch.tensor([[0,1,2,3,4], [1,2,3,4,5]], dtype=torch.long)
    data['bus', 'connects', 'bus'].edge_attr = torch.randn(5, 9)  # 5æ¡è¾¹ï¼Œ9ç»´ç‰¹å¾
    
    # è¾¹ç±»å‹2: gen-bus (å‘ç”µæœº-æ¯çº¿è¿æ¥)
    data['gen', 'connects', 'bus'].edge_index = torch.tensor([[0,1,2], [0,3,7]], dtype=torch.long)
    data['gen', 'connects', 'bus'].edge_attr = torch.randn(3, 9)  # 3æ¡è¾¹ï¼Œ9ç»´ç‰¹å¾
    
    # è¾¹ç±»å‹3: gen-gen (ä¸º'gen'èŠ‚ç‚¹æ·»åŠ è‡ªå¾ªç¯ä»¥ç¡®ä¿å®ƒä»¬èƒ½è¢«æ›´æ–°)
    num_gens = data['gen'].num_nodes
    data['gen', 'loops', 'gen'].edge_index = torch.arange(num_gens).unsqueeze(0).repeat(2, 1)
    data['gen', 'loops', 'gen'].edge_attr = torch.ones(num_gens, 9) # æä¾›è™šæ‹Ÿçš„è¾¹ç‰¹å¾
    
    return data

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”¬ å¼€å§‹æµ‹è¯•æœ€ç»ˆé‡æ„åçš„ HeteroGraphEncoder...")
    
    # æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”© ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
    try:
        data = create_test_hetero_data()
        data = data.to(device)
        print("âœ… æˆåŠŸåˆ›å»ºæµ‹è¯•å¼‚æ„å›¾æ•°æ®")
    except Exception as e:
        print(f"âŒ åˆ›å»ºæµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        return

    # 2. åˆ›å»ºç¼–ç å™¨
    try:
        encoder = create_hetero_graph_encoder(
            data, 
            hidden_channels=32, 
            gnn_layers=2, 
            heads=4, 
            output_dim=64
        )
        encoder = encoder.to(device)
        print("âœ… æˆåŠŸåˆ›å»ºå¼‚æ„å›¾ç¼–ç å™¨")
        print(f"ğŸ“Š ç¼–ç å™¨å‚æ•°é‡: {sum(p.numel() for p in encoder.parameters()):,}")
    except Exception as e:
        print(f"âŒ åˆ›å»ºç¼–ç å™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3. æ‰§è¡Œå‰å‘ä¼ æ’­å¹¶éªŒè¯è¾“å‡º
    try:
        print("\nğŸš€ æ‰§è¡Œå®Œæ•´å‰å‘ä¼ æ’­å¹¶éªŒè¯...")
        with torch.no_grad():
            node_emb, attention_weights, graph_emb = encoder(
                data, 
                return_attention_weights=True, 
                return_graph_embedding=True
            )

        print("âœ… å®Œæ•´å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
        
        # éªŒè¯èŠ‚ç‚¹åµŒå…¥
        print("\n--- èŠ‚ç‚¹åµŒå…¥éªŒè¯ ---")
        for node_type, embeddings in node_emb.items():
            print(f"   - èŠ‚ç‚¹ç±»å‹ '{node_type}' -> åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
            assert embeddings.shape == (data[node_type].num_nodes, 64)
            assert embeddings.device.type == device.type
        print("   âœ… å½¢çŠ¶å’Œè®¾å¤‡æ­£ç¡®")

        # éªŒè¯å›¾åµŒå…¥
        print("\n--- å›¾åµŒå…¥éªŒè¯ ---")
        print(f"   - å›¾çº§åˆ«åµŒå…¥å½¢çŠ¶: {graph_emb.shape}")
        assert graph_emb.shape == (1, 64)
        assert graph_emb.device.type == device.type
        print("   âœ… å½¢çŠ¶å’Œè®¾å¤‡æ­£ç¡®")

        # éªŒè¯æ³¨æ„åŠ›æƒé‡
        print("\n--- æ³¨æ„åŠ›æƒé‡éªŒè¯ ---")
        print(f"   - æå–çš„æ³¨æ„åŠ›æƒé‡æ•°é‡: {len(attention_weights)}")
        assert len(attention_weights) > 0, "å…³é”®å¤±è´¥ï¼šæœªèƒ½æå–åˆ°æ³¨æ„åŠ›æƒé‡ï¼"
        print("   âœ… æˆåŠŸæå–æ³¨æ„åŠ›æƒé‡")

    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰æµ‹è¯•å‡å·²é€šè¿‡ï¼æ‚¨çš„ç¼–ç å™¨å·²å‡†å¤‡å°±ç»ªã€‚ğŸ‰ğŸ‰ğŸ‰")

if __name__ == "__main__":
    main() 