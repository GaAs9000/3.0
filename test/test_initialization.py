# Create new file: test/test_initialization.py

import torch
import numpy as np
import networkx as nx
import sys
import json
import os
from pathlib import Path
from datetime import datetime

# Add project root path
sys.path.append(str(Path(__file__).parent.parent))

from src.rl.utils import MetisInitializer
from src.data_processing import PowerGridDataProcessor
from train_unified import load_power_grid_data

def save_partition_details(partition_info, output_dir="output/partition_analysis"):
    """
    ä¿å­˜åˆ†åŒºè¯¦ç»†ä¿¡æ¯åˆ°æ–‡ä»¶
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"partition_analysis_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    
    # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
    def convert_types(obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {key: convert_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [convert_types(item) for item in obj]
        return obj
    
    # ä¿å­˜ä¸ºJSONæ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(convert_types(partition_info), f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ åˆ†åŒºè¯¦ç»†ä¿¡æ¯å·²ä¿å­˜åˆ°: {filepath}")
    return filepath

def analyze_partition_details(partition, initializer, case_name="unknown", save_to_file=True):
    """
    åˆ†æå¹¶è¾“å‡ºåˆ†åŒºçš„è¯¦ç»†ä¿¡æ¯
    """
    print(f"\n=== ğŸ“Š {case_name.upper()} åˆ†åŒºè¯¦ç»†åˆ†æ ===")
    
    labels_np = partition.cpu().numpy()
    total_nodes = len(labels_np)
    
    # é¦–å…ˆæ£€æŸ¥å›¾çš„åŸºæœ¬è¿é€šæ€§
    print(f"\nğŸ” å›¾ç»“æ„è°ƒè¯•ä¿¡æ¯:")
    print(f"  æ€»èŠ‚ç‚¹æ•°: {total_nodes}")
    
    # ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„åº¦æ•°
    degrees = [len(initializer.adjacency_list[i]) for i in range(total_nodes)]
    print(f"  èŠ‚ç‚¹åº¦æ•°: {degrees}")
    print(f"  æœ€å¤§åº¦æ•°: {max(degrees) if degrees else 0}")
    print(f"  æœ€å°åº¦æ•°: {min(degrees) if degrees else 0}")
    print(f"  å­¤ç«‹èŠ‚ç‚¹æ•°: {degrees.count(0)}")
    
    # æ£€æŸ¥åŸå§‹å›¾çš„è¿é€šæ€§
    G = nx.Graph()
    G.add_nodes_from(range(total_nodes))
    total_edges = 0
    for i in range(total_nodes):
        for neighbor in initializer.adjacency_list[i]:
            if i < neighbor:  # é¿å…é‡å¤
                G.add_edge(i, neighbor)
                total_edges += 1
    
    print(f"  æ€»è¾¹æ•°: {total_edges}")
    if total_edges > 0:
        is_graph_connected = nx.is_connected(G)
        print(f"  åŸå§‹å›¾è¿é€šæ€§: {'âœ… è¿é€š' if is_graph_connected else 'âŒ ä¸è¿é€š'}")
    else:
        is_graph_connected = False
        print(f"  åŸå§‹å›¾è¿é€šæ€§: âŒ æ— è¾¹å›¾")
    
    if not nx.is_connected(G) and total_edges > 0:
        components = list(nx.connected_components(G))
        print(f"  è¿é€šåˆ†é‡æ•°: {len(components)}")
        for i, comp in enumerate(components[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"    åˆ†é‡{i+1}: {sorted(list(comp))}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    unique_labels = np.unique(labels_np)
    num_partitions = len([l for l in unique_labels if l > 0])
    unassigned_count = np.sum(labels_np == 0)
    
    print(f"\nğŸ“ˆ åˆ†åŒºåŸºæœ¬ç»Ÿè®¡:")
    print(f"  æ€»èŠ‚ç‚¹æ•°: {total_nodes}")
    print(f"  åˆ†åŒºæ•°é‡: {num_partitions}")
    print(f"  æœªåˆ†åŒºèŠ‚ç‚¹æ•°: {unassigned_count}")
    print(f"  åˆ†åŒºæ ‡ç­¾: {sorted(unique_labels)}")
    
    # è¯¦ç»†ä¿¡æ¯å­—å…¸
    partition_info = {
        "case_name": case_name,
        "timestamp": datetime.now().isoformat(),
        "total_nodes": total_nodes,
        "num_partitions": num_partitions,
        "unassigned_count": unassigned_count,
        "partitions": {},
        "inter_partition_connections": [],
        "connectivity_analysis": {},
        "graph_structure": {
            "total_edges": total_edges,
            "is_connected": is_graph_connected,
            "num_components": len(list(nx.connected_components(G))) if total_edges > 0 else total_nodes,
            "degrees": degrees
        }
    }
    
    # åˆ†ææ¯ä¸ªåˆ†åŒº
    print(f"\nğŸ¯ å„åˆ†åŒºè¯¦ç»†ä¿¡æ¯:")
    for label in sorted(unique_labels):
        nodes = np.where(labels_np == label)[0].tolist()
        if label == 0:
            partition_name = "æœªåˆ†åŒº"
            print(f"  {partition_name} (æ ‡ç­¾ {label}): {len(nodes)} ä¸ªèŠ‚ç‚¹")
            print(f"    èŠ‚ç‚¹åˆ—è¡¨: {nodes}")
        else:
            partition_name = f"åˆ†åŒº{label}"
            print(f"  {partition_name}: {len(nodes)} ä¸ªèŠ‚ç‚¹")
            print(f"    èŠ‚ç‚¹åˆ—è¡¨: {nodes}")
            
            # æ£€æŸ¥è¿é€šæ€§
            if len(nodes) > 1:
                subgraph = nx.Graph()
                subgraph.add_nodes_from(nodes)
                for node in nodes:
                    for neighbor in initializer.adjacency_list[node]:
                        if neighbor in nodes:
                            subgraph.add_edge(node, neighbor)
                
                is_connected = nx.is_connected(subgraph)
                print(f"    è¿é€šæ€§: {'âœ… è¿é€š' if is_connected else 'âŒ ä¸è¿é€š'}")
                
                if not is_connected:
                    components = list(nx.connected_components(subgraph))
                    print(f"    è¿é€šåˆ†é‡æ•°: {len(components)}")
                    for i, comp in enumerate(components):
                        print(f"      åˆ†é‡{i+1}: {sorted(list(comp))}")
                
                partition_info["connectivity_analysis"][f"partition_{label}"] = {
                    "is_connected": is_connected,
                    "num_components": len(list(nx.connected_components(subgraph))) if not is_connected else 1
                }
            else:
                print(f"    è¿é€šæ€§: âœ… å•èŠ‚ç‚¹ (è‡ªç„¶è¿é€š)")
                partition_info["connectivity_analysis"][f"partition_{label}"] = {
                    "is_connected": True,
                    "num_components": 1
                }
        
        partition_info["partitions"][f"partition_{label}"] = {
            "label": int(label),
            "name": partition_name,
            "nodes": nodes,
            "size": len(nodes)
        }
    
    # åˆ†æåŒºåŸŸé—´è¿æ¥
    print(f"\nğŸ”— åŒºåŸŸé—´è¿æ¥åˆ†æ:")
    inter_connections = {}
    total_inter_edges = 0
    
    for i in range(total_nodes):
        for neighbor in initializer.adjacency_list[i]:
            if i < neighbor:  # é¿å…é‡å¤è®¡ç®—åŒä¸€æ¡è¾¹
                label_i = labels_np[i]
                label_j = labels_np[neighbor]
                
                if label_i != label_j:  # è·¨åˆ†åŒºè¿æ¥
                    key = tuple(sorted([int(label_i), int(label_j)]))
                    if key not in inter_connections:
                        inter_connections[key] = []
                    inter_connections[key].append((int(i), int(neighbor)))
                    total_inter_edges += 1
    
    print(f"  æ€»è·¨åˆ†åŒºè¿æ¥æ•°: {total_inter_edges}")
    
    for (label1, label2), edges in inter_connections.items():
        name1 = "æœªåˆ†åŒº" if label1 == 0 else f"åˆ†åŒº{label1}"
        name2 = "æœªåˆ†åŒº" if label2 == 0 else f"åˆ†åŒº{label2}"
        print(f"  {name1} â†” {name2}: {len(edges)} æ¡è¿æ¥")
        print(f"    è¿æ¥è¯¦æƒ…: {edges[:5]}{'...' if len(edges) > 5 else ''}")  # åªæ˜¾ç¤ºå‰5æ¡
        
        partition_info["inter_partition_connections"].append({
            "partition1": int(label1),
            "partition2": int(label2),
            "connection_count": len(edges),
            "edges": edges
        })
    
    # å°è¯•ä¿å­˜è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if save_to_file:
        try:
            save_partition_details(partition_info)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            print("ğŸ“ åˆ†æç»“æœä»…åœ¨æ§åˆ¶å°æ˜¾ç¤º")
    
    return partition_info

def test_initialization_creates_action_space():
    """
    æµ‹è¯• initialize_partition æ˜¯å¦èƒ½ä¸ºRL Agentç”Ÿæˆä¸€ä¸ªæœ‰æ•ˆçš„åˆå§‹çŠ¶æ€ã€‚
    (å³ï¼ŒåŒ…å«æ ‡ç­¾ä¸º0çš„æœªåˆ†åŒºèŠ‚ç‚¹)
    """
    print("\n--- æµ‹è¯• 1: éªŒè¯æ ‡å‡†æ¡ˆä¾‹(ieee14)çš„åˆå§‹åŒ– ---")
    
    # 1. å‡†å¤‡æ•°æ®
    device = torch.device('cpu')
    mpc = load_power_grid_data('ieee14')
    data = PowerGridDataProcessor(normalize=False, cache_dir='test_cache').graph_from_mpc(mpc)
    
    # 2. åˆå§‹åŒ–
    num_partitions = 3
    initializer = MetisInitializer(data, device)
    partition = initializer.initialize_partition(num_partitions=num_partitions)
    
    # 3. è¯¦ç»†åˆ†æåˆ†åŒºç»“æœ
    partition_info = analyze_partition_details(partition, initializer, "ieee14")
    
    # 4. åŸºæœ¬æ–­è¨€
    # æ–­è¨€1: å¿…é¡»å­˜åœ¨æ ‡ç­¾ä¸º0çš„èŠ‚ç‚¹ (å…³é”®ï¼è¯æ˜åŠ¨ä½œç©ºé—´è¢«åˆ›é€ )
    contains_unassigned = torch.any(partition == 0).item()
    print(f"\nâœ… æ˜¯å¦åŒ…å«'æœªåˆ†åŒº'(0)èŠ‚ç‚¹: {contains_unassigned}")
    assert contains_unassigned, "åˆå§‹åŒ–å¤±è´¥ï¼šæ²¡æœ‰åˆ›é€ å‡ºä»»ä½•æœªåˆ†åŒºèŠ‚ç‚¹ï¼"

    # æ–­è¨€2: æ£€æŸ¥å·²åˆ†åŒºçš„è¿é€šæ€§ï¼ˆå…è®¸éƒ¨åˆ†ä¸è¿é€šï¼Œä½†è¦è®°å½•ï¼‰
    labels_np = partition.cpu().numpy()
    disconnected_partitions = []
    
    for p_id in range(1, num_partitions + 1):
        nodes = np.where(labels_np == p_id)[0]
        if len(nodes) > 1:
            subgraph = nx.Graph()
            subgraph.add_nodes_from(nodes)
            for node in nodes:
                for neighbor in initializer.adjacency_list[node]:
                    if neighbor in nodes:
                        subgraph.add_edge(node, neighbor)
            
            is_conn = nx.is_connected(subgraph)
            if not is_conn:
                disconnected_partitions.append(p_id)
                print(f"âš ï¸ åˆ†åŒº {p_id} (å¤§å°: {len(nodes)}) ä¸è¿é€š")
            else:
                print(f"âœ… åˆ†åŒº {p_id} (å¤§å°: {len(nodes)}) è¿é€š")
    
    if disconnected_partitions:
        print(f"âš ï¸ è­¦å‘Š: å‘ç° {len(disconnected_partitions)} ä¸ªä¸è¿é€šçš„åˆ†åŒº: {disconnected_partitions}")
        print("   è¿™å¯èƒ½æ˜¯ç”±äºå›¾ç»“æ„å¤æ‚æˆ–åˆå§‹åˆ†åŒºç®—æ³•çš„é™åˆ¶å¯¼è‡´çš„")
    else:
        print("âœ… æ‰€æœ‰åˆ†åŒºéƒ½æ˜¯è¿é€šçš„")
        
    print("âœ… æµ‹è¯• 1 é€šè¿‡: åˆå§‹åŒ–ä¸ºAgentåˆ›é€ äº†åŠ¨ä½œç©ºé—´ï¼Œè¯¦ç»†ä¿¡æ¯å·²ä¿å­˜")

def test_different_cases():
    """
    æµ‹è¯•ä¸åŒIEEEæ¡ˆä¾‹çš„åˆå§‹åŒ–
    """
    print("\n--- æµ‹è¯• 2: éªŒè¯ä¸åŒIEEEæ¡ˆä¾‹çš„åˆå§‹åŒ– ---")
    
    device = torch.device('cpu')
    cases = ['ieee14', 'ieee30', 'ieee57', 'ieee118']
    
    for case_name in cases:
        try:
            print(f"\nğŸ” æµ‹è¯•æ¡ˆä¾‹: {case_name}")
            mpc = load_power_grid_data(case_name)
            data = PowerGridDataProcessor(normalize=False, cache_dir='test_cache').graph_from_mpc(mpc)
            
            total_nodes = sum(data.x_dict[node_type].shape[0] for node_type in data.x_dict.keys())
            num_partitions = min(4, total_nodes // 3)  # åŠ¨æ€è°ƒæ•´åˆ†åŒºæ•°
            if num_partitions < 2:
                num_partitions = 2
                
            initializer = MetisInitializer(data, device)
            partition = initializer.initialize_partition(num_partitions=num_partitions)
            
            # è¯¦ç»†åˆ†æï¼ˆä½†ä¸ä¿å­˜ï¼Œé¿å…æ–‡ä»¶è¿‡å¤šï¼‰
            partition_info = analyze_partition_details(partition, initializer, case_name, save_to_file=False)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœªåˆ†åŒºèŠ‚ç‚¹
            unassigned_count = torch.sum(partition == 0).item()
            total_nodes = partition.shape[0]
            
            print(f"\nğŸ“‹ {case_name} æ€»ç»“:")
            print(f"  æ€»èŠ‚ç‚¹æ•°: {total_nodes}")
            print(f"  æœªåˆ†åŒºèŠ‚ç‚¹æ•°: {unassigned_count}")
            print(f"  åˆ†åŒºæ•°: {num_partitions}")
            
            assert unassigned_count > 0, f"æ¡ˆä¾‹ {case_name} æ²¡æœ‰åˆ›é€ æœªåˆ†åŒºèŠ‚ç‚¹"
            assert unassigned_count < total_nodes, f"æ¡ˆä¾‹ {case_name} æ‰€æœ‰èŠ‚ç‚¹éƒ½æœªåˆ†åŒº"
            
            print(f"  âœ… {case_name} æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"  âš ï¸ {case_name} æµ‹è¯•å¤±è´¥: {e}")
            # å¯¹äºæŸäº›æ¡ˆä¾‹ï¼Œå¯èƒ½å› ä¸ºæ•°æ®é—®é¢˜å¤±è´¥ï¼Œè¿™æ˜¯å¯ä»¥æ¥å—çš„
            continue
    
    print("âœ… æµ‹è¯• 2 å®Œæˆ: å¤šæ¡ˆä¾‹åˆå§‹åŒ–æµ‹è¯•")

def test_edge_cases():
    """
    æµ‹è¯•è¾¹ç•Œæƒ…å†µ
    """
    print("\n--- æµ‹è¯• 3: éªŒè¯è¾¹ç•Œæƒ…å†µå¤„ç† ---")
    
    device = torch.device('cpu')
    mpc = load_power_grid_data('ieee14')
    data = PowerGridDataProcessor(normalize=False, cache_dir='test_cache').graph_from_mpc(mpc)
    
    # æµ‹è¯•æç«¯åˆ†åŒºæ•°
    initializer = MetisInitializer(data, device)
    
    # è·å–æ­£ç¡®çš„æ€»èŠ‚ç‚¹æ•°
    total_nodes = sum(data.x_dict[node_type].shape[0] for node_type in data.x_dict.keys())
    
    # æµ‹è¯•åˆ†åŒºæ•° = 1
    partition_1 = initializer.initialize_partition(num_partitions=1)
    unassigned_1 = torch.sum(partition_1 == 0).item()
    print(f"åˆ†åŒºæ•°=1æ—¶ï¼Œæœªåˆ†åŒºèŠ‚ç‚¹æ•°: {unassigned_1}")
    
    # æµ‹è¯•åˆ†åŒºæ•°æ¥è¿‘èŠ‚ç‚¹æ€»æ•°
    large_partitions = min(total_nodes - 2, 10)
    partition_large = initializer.initialize_partition(num_partitions=large_partitions)
    unassigned_large = torch.sum(partition_large == 0).item()
    print(f"åˆ†åŒºæ•°={large_partitions}æ—¶ï¼Œæœªåˆ†åŒºèŠ‚ç‚¹æ•°: {unassigned_large}")
    
    print("âœ… æµ‹è¯• 3 å®Œæˆ: è¾¹ç•Œæƒ…å†µæµ‹è¯•")

def print_final_summary():
    """
    æ‰“å°æœ€ç»ˆæµ‹è¯•æ€»ç»“å’Œé—®é¢˜è¯Šæ–­
    """
    print("\n" + "=" * 80)
    print("ğŸ” å…³é”®é—®é¢˜è¯Šæ–­æ€»ç»“:")
    print("=" * 80)
    
    print("\nğŸ“‹ ä¸»è¦å‘ç°:")
    print("1. âœ… MetisInitializer æˆåŠŸåˆ›å»ºäº†åŠ¨ä½œç©ºé—´ï¼ˆæœªåˆ†åŒºèŠ‚ç‚¹ï¼‰")
    print("2. âŒ å›¾ç»“æ„ä¸¥é‡ä¸è¿é€šï¼š14ä¸ªèŠ‚ç‚¹åªæœ‰5æ¡è¾¹ï¼Œ6ä¸ªå­¤ç«‹èŠ‚ç‚¹")
    print("3. âŒ METISåˆ‡è¾¹æ•°ä¸º0ï¼Œè¯´æ˜åˆå§‹åˆ†åŒºè´¨é‡å¾ˆå·®")
    print("4. âŒ è¿é€šæ€§ä¿®å¤ç®—æ³•æ— æ³•å®Œå…¨ä¿®å¤ä¸¥é‡ä¸è¿é€šçš„åˆ†åŒº")
    
    print("\nğŸ¯ RLè®­ç»ƒ'ä¸€åŠ¨ä¸åŠ¨'é—®é¢˜çš„æ ¹æœ¬åŸå› :")
    print("   å›¾ç»“æ„æœ¬èº«å°±æ˜¯éè¿é€šçš„ï¼Œå¯¼è‡´:")
    print("   â€¢ åˆ†åŒºå†…éƒ¨ä¸è¿é€šï¼Œagentæ— æ³•æœ‰æ•ˆç§»åŠ¨èŠ‚ç‚¹")
    print("   â€¢ è·¨åˆ†åŒºè¿æ¥æå°‘ï¼Œactionç©ºé—´å—é™")
    print("   â€¢ åˆå§‹çŠ¶æ€è´¨é‡å·®ï¼Œrewardä¿¡å·å¾®å¼±")
    
    print("\nğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
    print("1. ğŸ”§ æ£€æŸ¥æ•°æ®å¤„ç†ç®¡é“ï¼šç¡®ä¿å›¾çš„æ„å»ºè¿‡ç¨‹æ­£ç¡®")
    print("2. ğŸŒ éªŒè¯å¼‚æ„å›¾çš„è¾¹è¿æ¥ï¼šç¡®ä¿æ‰€æœ‰æœ‰æ•ˆè¿æ¥éƒ½è¢«åŒ…å«")
    print("3. ğŸ² æ”¹è¿›åˆå§‹åŒ–ç­–ç•¥ï¼šå¯¹äºä¸è¿é€šå›¾ä½¿ç”¨æ›´æ™ºèƒ½çš„åˆ†åŒºæ–¹æ³•")
    print("4. ğŸ† è°ƒæ•´rewardå‡½æ•°ï¼šåœ¨å›¾ç»“æ„å—é™æ—¶æä¾›æ›´å¤šæŒ‡å¯¼ä¿¡å·")
    
    print("\nğŸ“ è¯¦ç»†çš„åˆ†åŒºåˆ†ææ•°æ®å·²ä¿å­˜åˆ° output/partition_analysis/ ç›®å½•")
    print("=" * 80)

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ MetisInitializer ç»¼åˆæµ‹è¯•...")
    print("=" * 60)
    
    test_initialization_creates_action_space()
    test_different_cases()
    test_edge_cases()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“ è¯¦ç»†çš„åˆ†åŒºåˆ†æç»“æœå·²ä¿å­˜åœ¨ output/partition_analysis/ ç›®å½•ä¸­")
    
    print_final_summary()
