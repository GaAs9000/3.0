#!/usr/bin/env python3
"""
ç»“æœåˆ†æå·¥å…·å‡½æ•°
æä¾›é€šç”¨çš„è¾…åŠ©åŠŸèƒ½
"""

import numpy as np
import torch
from typing import Dict, List, Tuple, Optional, Any
import json
from pathlib import Path


def load_model_checkpoint(model_path: str, device: torch.device) -> Dict[str, Any]:
    """
    åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        æ£€æŸ¥ç‚¹å­—å…¸
    """
    checkpoint = torch.load(model_path, map_location=device)
    
    # éªŒè¯å¿…è¦å­—æ®µ
    required_fields = ['actor_state_dict', 'critic_state_dict', 'model_info']
    for field in required_fields:
        if field not in checkpoint:
            raise ValueError(f"æ¨¡å‹æ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
    
    return checkpoint


def calculate_improvement_metrics(baseline_metrics: Dict[str, float],
                                agent_metrics: Dict[str, float]) -> Dict[str, float]:
    """
    è®¡ç®—æ”¹è¿›æŒ‡æ ‡
    
    Args:
        baseline_metrics: åŸºå‡†æ–¹æ³•æŒ‡æ ‡
        agent_metrics: AgentæŒ‡æ ‡
        
    Returns:
        æ”¹è¿›ç™¾åˆ†æ¯”å­—å…¸
    """
    improvements = {}
    
    # CVæ”¹è¿›ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    if baseline_metrics.get('cv', 0) > 0:
        improvements['cv'] = (baseline_metrics['cv'] - agent_metrics['cv']) / baseline_metrics['cv'] * 100
    else:
        improvements['cv'] = 0
    
    # è€¦åˆåº¦æ”¹è¿›ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    if baseline_metrics.get('coupling', 0) > 0:
        improvements['coupling'] = (baseline_metrics['coupling'] - agent_metrics['coupling']) / baseline_metrics['coupling'] * 100
    else:
        improvements['coupling'] = 0
    
    # æˆåŠŸç‡æ”¹è¿›ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
    baseline_success = 1.0 if baseline_metrics.get('success', False) else 0.0
    agent_success = 1.0 if agent_metrics.get('success', False) else 0.0
    improvements['success'] = (agent_success - baseline_success) * 100
    
    return improvements


def format_metrics_table(metrics: Dict[str, float]) -> str:
    """
    æ ¼å¼åŒ–æŒ‡æ ‡è¡¨æ ¼
    
    Args:
        metrics: æŒ‡æ ‡å­—å…¸
        
    Returns:
        æ ¼å¼åŒ–çš„è¡¨æ ¼å­—ç¬¦ä¸²
    """
    table = "| æŒ‡æ ‡ | æ•°å€¼ |\n"
    table += "|------|------|\n"
    
    for key, value in metrics.items():
        if isinstance(value, bool):
            table += f"| {key} | {'âœ“' if value else 'âœ—'} |\n"
        elif isinstance(value, float):
            table += f"| {key} | {value:.4f} |\n"
        else:
            table += f"| {key} | {value} |\n"
    
    return table


def save_results_summary(results: Dict[str, Any], output_path: str):
    """
    ä¿å­˜ç»“æœæ‘˜è¦
    
    Args:
        results: ç»“æœå­—å…¸
        output_path: è¾“å‡ºè·¯å¾„
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜JSONæ ¼å¼
    json_path = output_path.with_suffix('.json')
    with open(json_path, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    # ä¿å­˜æ–‡æœ¬æ‘˜è¦
    txt_path = output_path.with_suffix('.txt')
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write("ç”µåŠ›ç½‘ç»œåˆ†åŒºç»“æœæ‘˜è¦\n")
        f.write("=" * 50 + "\n\n")
        
        # å†™å…¥å„åœºæ™¯ç»“æœ
        if 'scenarios' in results:
            for scenario, data in results['scenarios'].items():
                f.write(f"\nåœºæ™¯: {scenario}\n")
                f.write("-" * 30 + "\n")
                
                if 'agent' in data:
                    f.write("\nAgentæŒ‡æ ‡:\n")
                    f.write(format_metrics_table(data['agent']))
                
                if 'baseline' in data:
                    f.write("\nBaselineæŒ‡æ ‡:\n")
                    f.write(format_metrics_table(data['baseline']))
                
                if 'improvement' in data:
                    f.write("\næ”¹è¿›ç™¾åˆ†æ¯”:\n")
                    f.write(format_metrics_table(data['improvement']))
    
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜:")
    print(f"   JSON: {json_path}")
    print(f"   æ–‡æœ¬: {txt_path}")


def get_network_statistics(case_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    è·å–ç½‘ç»œç»Ÿè®¡ä¿¡æ¯
    
    Args:
        case_data: ç”µç½‘æ¡ˆä¾‹æ•°æ®
        
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    stats = {
        'num_buses': len(case_data['bus']),
        'num_branches': len(case_data['branch']),
        'num_generators': len(case_data['gen']) if 'gen' in case_data else 0,
        'total_load': float(np.sum(case_data['bus'][:, 2])),  # PDåˆ—
        'total_generation': float(np.sum(case_data['gen'][:, 1])) if 'gen' in case_data else 0
    }
    
    # è®¡ç®—ç½‘ç»œå¯†åº¦
    max_edges = stats['num_buses'] * (stats['num_buses'] - 1) / 2
    stats['density'] = stats['num_branches'] / max_edges if max_edges > 0 else 0
    
    return stats


def setup_output_directory(base_dir: str = 'evaluation') -> Path:
    """
    è®¾ç½®è¾“å‡ºç›®å½•
    
    Args:
        base_dir: åŸºç¡€ç›®å½•å
        
    Returns:
        æ—¶é—´æˆ³ç›®å½•è·¯å¾„
    """
    from datetime import datetime
    
    base_path = Path(base_dir)
    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
    output_dir = base_path / timestamp
    
    # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„å­ç›®å½•
    subdirs = ['comparisons', 'visualizations', 'reports', 'cache']
    for subdir in subdirs:
        (output_dir / subdir).mkdir(parents=True, exist_ok=True)
    
    return output_dir


def validate_partition(partition: np.ndarray, num_partitions: int) -> Tuple[bool, List[str]]:
    """
    éªŒè¯åˆ†åŒºç»“æœçš„æœ‰æ•ˆæ€§
    
    Args:
        partition: åˆ†åŒºæ•°ç»„
        num_partitions: æœŸæœ›çš„åˆ†åŒºæ•°
        
    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
    """
    errors = []
    
    # æ£€æŸ¥åˆ†åŒºç¼–å·èŒƒå›´
    unique_partitions = np.unique(partition[partition > 0])
    if len(unique_partitions) != num_partitions:
        errors.append(f"åˆ†åŒºæ•°ä¸åŒ¹é…: æœŸæœ›{num_partitions}, å®é™…{len(unique_partitions)}")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ†åŒºéƒ½è¢«ä½¿ç”¨
    for p in range(1, num_partitions + 1):
        if p not in partition:
            errors.append(f"åˆ†åŒº{p}æœªè¢«ä½¿ç”¨")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœªåˆ†é…çš„èŠ‚ç‚¹
    unassigned = np.sum(partition == 0)
    if unassigned > 0:
        errors.append(f"æœ‰{unassigned}ä¸ªèŠ‚ç‚¹æœªåˆ†é…")
    
    is_valid = len(errors) == 0
    return is_valid, errors