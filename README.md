# ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

ä¸€ä¸ªåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ (PPO)å’Œå¼‚æ„å›¾ç¥ç»ç½‘ç»œ(GAT)çš„ç”µåŠ›ç½‘ç»œåˆ†åŒºä¼˜åŒ–ç³»ç»Ÿï¼Œä¸“ä¸ºç”µåŠ›ç³»ç»Ÿè¿è¡Œåˆ†æå’Œä¼˜åŒ–è€Œè®¾è®¡ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„ç”µåŠ›ç½‘ç»œåˆ†åŒºè§£å†³æ–¹æ¡ˆï¼Œå°†ç”µåŠ›ç½‘ç»œåˆ†åŒºé—®é¢˜å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDP)ï¼Œä½¿ç”¨PPOç®—æ³•å’Œç‰©ç†å¢å¼ºçš„å¼‚æ„å›¾ç¥ç»ç½‘ç»œè¿›è¡Œä¼˜åŒ–ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **ğŸ§  å¼‚æ„å›¾ç¥ç»ç½‘ç»œ**: åŸºäºGATv2çš„ç‰©ç†å¢å¼ºå›¾ç¼–ç å™¨ï¼Œèå…¥ç”µæ°”é˜»æŠ—å…ˆéªŒ
- **ğŸ® å¼ºåŒ–å­¦ä¹ **: PPOç®—æ³•å®ç°çš„ä¸¤é˜¶æ®µåŠ¨ä½œç©ºé—´(èŠ‚ç‚¹é€‰æ‹©+åˆ†åŒºé€‰æ‹©)
- **ğŸ¯ ä¸‰é˜¶æ®µå¢å¼ºå¥–åŠ±**: ç¨ å¯†å¥–åŠ±ã€æ™ºèƒ½æ¢ç´¢ã€è‡ªé€‚åº”ç‰©ç†çº¦æŸçš„æ¸è¿›å¼ä¼˜åŒ–
- **âš¡ ç‰©ç†çº¦æŸ**: é›†æˆç”µåŠ›ç³»ç»Ÿç‰©ç†çº¦æŸå’Œæ‹“æ‰‘ä¼˜åŒ–
- **ğŸ“Š å¤šç§åŸºçº¿**: è°±èšç±»ã€K-meansã€éšæœºåˆ†åŒºç­‰åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ğŸ”„ åœºæ™¯ç”Ÿæˆ**: N-1æ•…éšœå’Œè´Ÿè·æ³¢åŠ¨æ¨¡æ‹Ÿ
- **ğŸƒâ€â™‚ï¸ å¹¶è¡Œè®­ç»ƒ**: å¤šè¿›ç¨‹è®­ç»ƒåŠ é€Ÿ
- **ğŸ“ˆ å®Œæ•´ç›‘æ§**: TensorBoardé›†æˆã€å®æ—¶å¯è§†åŒ–ã€è®­ç»ƒç»Ÿè®¡

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.12+
- CUDA 11.0+ (å¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿ)

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone <your-repo-url>
cd 2.0
```

2. **å®‰è£…ä¾èµ–**

```bash
pip install -r requirements.txt
```

1. **éªŒè¯å®‰è£…**
```bash
python main.py --check-deps
```

### ç«‹å³å¼€å§‹è®­ç»ƒ

```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰
python main.py --mode quick

# æ ‡å‡†è®­ç»ƒï¼ˆ30åˆ†é’Ÿï¼‰
python main.py --mode standard

# å¢å¼ºå¥–åŠ±è®­ç»ƒï¼ˆæ¨èï¼‰
python main.py --config enhanced_rewards_training

# å®Œæ•´è®­ç»ƒï¼ˆ2-4å°æ—¶ï¼‰
python main.py --mode full

# IEEE 118èŠ‚ç‚¹å¤§è§„æ¨¡è®­ç»ƒ
python main.py --mode ieee118
```

## ğŸ“‹ è®­ç»ƒæ¨¡å¼è¯¦è§£

### è®­ç»ƒæ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | è®­ç»ƒæ—¶é—´ | å›åˆæ•° | é€‚ç”¨åœºæ™¯ | ç‰¹è‰²åŠŸèƒ½ |
|------|----------|--------|----------|----------|
| `quick` | 5åˆ†é’Ÿ | 100 | åŠŸèƒ½éªŒè¯ã€å¿«é€Ÿæµ‹è¯• | è½»é‡åŒ–é…ç½® |
| `standard` | 30åˆ†é’Ÿ | 1000 | æ—¥å¸¸ç ”ç©¶ã€ç®—æ³•éªŒè¯ | å¹³è¡¡æ€§èƒ½ä¸æ—¶é—´ |
| `enhanced_rewards_training` | 45åˆ†é’Ÿ | 1500 | **æ¨èæ¨¡å¼**ã€é«˜è´¨é‡è®­ç»ƒ | ä¸‰é˜¶æ®µå¢å¼ºå¥–åŠ± |
| `full` | 2-4å°æ—¶ | 5000 | é«˜è´¨é‡ç»“æœã€è®ºæ–‡å®éªŒ | å®Œæ•´è®­ç»ƒæµç¨‹ |
| `ieee118` | 4-8å°æ—¶ | 3000 | å¤§è§„æ¨¡ç³»ç»Ÿæµ‹è¯• | å¹¶è¡Œ+åœºæ™¯ç”Ÿæˆ |
| `parallel` | å¯é…ç½® | å¯é…ç½® | å¤šæ ¸åŠ é€Ÿè®­ç»ƒ | å¤šè¿›ç¨‹å¹¶è¡Œ |
| `curriculum` | å¯é…ç½® | å¯é…ç½® | æ¸è¿›å¼å­¦ä¹  | éš¾åº¦é€’å¢è®­ç»ƒ |

### ä¸‰é˜¶æ®µå¢å¼ºå¥–åŠ±ç³»ç»Ÿ

æœ¬é¡¹ç›®å®ç°äº†åˆ›æ–°çš„ä¸‰é˜¶æ®µå¢å¼ºå¥–åŠ±ç³»ç»Ÿï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆæœï¼š

```bash
# ç¬¬ä¸€é˜¶æ®µï¼šç¨ å¯†å¥–åŠ±ï¼ˆè§£å†³ç¨€ç–å¥–åŠ±é—®é¢˜ï¼‰
python main.py --config stage1_dense_rewards

# ç¬¬äºŒé˜¶æ®µï¼šæ™ºèƒ½æ¢ç´¢ï¼ˆå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼‰
python main.py --config stage2_smart_exploration

# ç¬¬ä¸‰é˜¶æ®µï¼šè‡ªé€‚åº”ç‰©ç†çº¦æŸï¼ˆèå…¥é¢†åŸŸçŸ¥è¯†ï¼‰
python main.py --config stage3_adaptive_physics

# å®Œæ•´ä¸‰é˜¶æ®µè®­ç»ƒï¼ˆæ¨èï¼‰
python main.py --config enhanced_rewards_training
```

#### ğŸ¯ ä¸‰é˜¶æ®µè®¾è®¡ç†å¿µ

1. **ç¬¬ä¸€é˜¶æ®µ - ç¨ å¯†å¥–åŠ±**
   - **å±€éƒ¨è¿é€šæ€§å¥–åŠ±**: æä¾›å³æ—¶æ‹“æ‰‘åé¦ˆï¼Œå¼•å¯¼æ™ºèƒ½ä½“æ„å»ºè¿é€šåˆ†åŒº
   - **å¢é‡å¹³è¡¡å¥–åŠ±**: å®æ—¶ç›‘æ§è´Ÿè½½å¹³è¡¡æ”¹å–„ï¼Œé¿å…ç¨€ç–å¥–åŠ±é—®é¢˜
   - **è¾¹ç•Œå‹ç¼©å¥–åŠ±**: æ¿€åŠ±å‡å°‘åˆ†åŒºé—´è€¦åˆï¼Œæä¾›æ˜ç¡®çš„è¿›åº¦ä¿¡å·

2. **ç¬¬äºŒé˜¶æ®µ - æ™ºèƒ½æ¢ç´¢**
   - **æ¢ç´¢å¥–åŠ±**: é¼“åŠ±è®¿é—®æœªæ¢ç´¢çš„çŠ¶æ€ç©ºé—´ï¼Œé˜²æ­¢è¿‡æ—©æ”¶æ•›
   - **åŠ¿å‡½æ•°å¡‘é€ **: åŸºäºç”µåŠ›ç³»ç»Ÿæ‹“æ‰‘çš„é•¿æœŸå¼•å¯¼ä¿¡å·
   - **å¹³è¡¡æœºåˆ¶**: åŠ¨æ€è°ƒèŠ‚æ¢ç´¢ä¸åˆ©ç”¨çš„æƒé‡

3. **ç¬¬ä¸‰é˜¶æ®µ - è‡ªé€‚åº”ç‰©ç†çº¦æŸ**
   - **é‚»å±…ä¸€è‡´æ€§**: èå…¥ç”µåŠ›ç³»ç»Ÿçš„ç‰©ç†çº¦æŸçŸ¥è¯†
   - **è‡ªé€‚åº”æƒé‡**: æ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´å¥–åŠ±ç»„ä»¶æƒé‡
   - **é¢†åŸŸçŸ¥è¯†**: é›†æˆç”µåŠ›ç³»ç»Ÿä¸“å®¶ç»éªŒ

### è‡ªå®šä¹‰è®­ç»ƒå‚æ•°

```bash
# æŒ‡å®šç”µåŠ›ç³»ç»Ÿç®—ä¾‹
python main.py --mode standard --case ieee30 --partitions 5

# è°ƒæ•´è®­ç»ƒå‚æ•°
python main.py --mode standard --episodes 2000 --lr 0.001

# å¯ç”¨å¹¶è¡Œè®­ç»ƒ
python main.py --mode parallel --workers 8

# ä¿å­˜è®­ç»ƒç»“æœ
python main.py --mode standard --save-results --output-dir my_experiment
```

## ğŸ”§ ä¸»è¦å‚æ•°é…ç½®

### è®­ç»ƒå‚æ•°

```python
# åœ¨main.pyä¸­çš„é…ç½®ç¤ºä¾‹
training_config = {
    'episodes': 1000,           # è®­ç»ƒå›åˆæ•°
    'max_steps': 200,          # æ¯å›åˆæœ€å¤§æ­¥æ•°
    'learning_rate': 3e-4,     # å­¦ä¹ ç‡
    'batch_size': 32,          # æ‰¹å¤§å°
    'update_interval': 10,     # æ›´æ–°é—´éš”
    'gamma': 0.99,             # æŠ˜æ‰£å› å­
    'eps_clip': 0.2,           # PPOè£å‰ªå‚æ•°
    'entropy_coef': 0.01,      # ç†µç³»æ•°
}
```

### ç½‘ç»œå‚æ•°

```python
model_config = {
    'hidden_channels': 64,     # éšè—å±‚ç»´åº¦
    'gnn_layers': 3,          # GNNå±‚æ•°
    'heads': 4,               # æ³¨æ„åŠ›å¤´æ•°
    'dropout': 0.3,           # Dropoutç‡
    'output_dim': 64,         # è¾“å‡ºåµŒå…¥ç»´åº¦
}
```

### ç¯å¢ƒå‚æ•°

```python
env_config = {
    'case_name': 'ieee30',     # ç”µåŠ›ç³»ç»Ÿç®—ä¾‹
    'num_partitions': 4,       # ç›®æ ‡åˆ†åŒºæ•°
    'reward_weights': {        # åŸºç¡€å¥–åŠ±æƒé‡
        'load_balance': 0.4,
        'electrical_decoupling': 0.4,
        'power_balance': 0.2,

        # å¢å¼ºå¥–åŠ±ç³»ç»Ÿé…ç½®
        'use_enhanced_rewards': True,
        'enhanced_config': {
            'enable_dense_rewards': True,      # å¯ç”¨ç¨ å¯†å¥–åŠ±
            'enable_exploration_bonus': True,  # å¯ç”¨æ¢ç´¢å¥–åŠ±
            'enable_potential_shaping': True,  # å¯ç”¨åŠ¿å‡½æ•°å¡‘é€ 
            'enable_adaptive_weights': True,   # å¯ç”¨è‡ªé€‚åº”æƒé‡
        },

        # ç¨ å¯†å¥–åŠ±æƒé‡
        'local_connectivity': 0.4,     # å±€éƒ¨è¿é€šæ€§
        'incremental_balance': 0.3,    # å¢é‡å¹³è¡¡
        'boundary_compression': 0.3,   # è¾¹ç•Œå‹ç¼©

        # æ¢ç´¢ä¸å¡‘é€ æƒé‡
        'exploration_bonus': 0.1,      # æ¢ç´¢å¥–åŠ±
        'potential_shaping': 0.2,      # åŠ¿å‡½æ•°å¡‘é€ 

        # ç‰©ç†çº¦æŸæƒé‡
        'neighbor_consistency': 0.15,  # é‚»å±…ä¸€è‡´æ€§
    }
}
```

## ğŸ“Š è®­ç»ƒç›‘æ§

### å¯åŠ¨è®­ç»ƒç›‘æ§

```bash
# å¯åŠ¨è®­ç»ƒï¼ˆè‡ªåŠ¨å¼€å¯ç›‘æ§ï¼‰
python main.py --mode standard --save-results

# å®æ—¶ç›‘æ§è®­ç»ƒè¿›å±•ï¼ˆTensorBoardï¼‰
tensorboard --logdir=logs
# è®¿é—® http://localhost:6006

# å¯é€‰ï¼šä½¿ç”¨Weights & Biases (W&B)
# 1. ç™»å½•W&B
wandb login

# 2. å¯åŠ¨è®­ç»ƒæ—¶å¯ç”¨W&B
python main.py --mode standard --use-wandb
```

### ç›‘æ§æŒ‡æ ‡

- **è®­ç»ƒæŒ‡æ ‡**: å¥–åŠ±æ›²çº¿ã€å›åˆé•¿åº¦ã€æˆåŠŸç‡
- **æ€§èƒ½æŒ‡æ ‡**: è´Ÿè½½å˜å¼‚ç³»æ•°ã€ç”µæ°”è€¦åˆåº¦ã€è¿é€šæ€§
- **ç½‘ç»œæŒ‡æ ‡**: Actor/CriticæŸå¤±ã€ç­–ç•¥ç†µã€æ¢¯åº¦èŒƒæ•°
- **ç³»ç»ŸæŒ‡æ ‡**: å†…å­˜ä½¿ç”¨ã€GPUåˆ©ç”¨ç‡ã€è®­ç»ƒé€Ÿåº¦
- **å¢å¼ºå¥–åŠ±æŒ‡æ ‡**: å¥–åŠ±ç»„ä»¶åˆ†è§£ã€å±€éƒ¨è¿é€šæ€§ã€å¢é‡å¹³è¡¡ã€è¾¹ç•Œå‹ç¼©

## ğŸ¯ å¢å¼ºå¥–åŠ±ç³»ç»Ÿè¯¦è§£

### ç³»ç»Ÿæ¶æ„

å¢å¼ºå¥–åŠ±ç³»ç»Ÿé‡‡ç”¨ä¸‰é˜¶æ®µæ¸è¿›å¼è®¾è®¡ï¼Œè§£å†³ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ åœ¨ç”µåŠ›ç½‘ç»œåˆ†åŒºä¸­çš„å…³é”®é—®é¢˜ï¼š

#### ğŸ” é—®é¢˜åˆ†æ
- **ç¨€ç–å¥–åŠ±**: ä¼ ç»Ÿæ–¹æ³•åªåœ¨åˆ†åŒºå®Œæˆæ—¶ç»™äºˆå¥–åŠ±ï¼Œè®­ç»ƒæ•ˆç‡ä½
- **æ¢ç´¢å›°éš¾**: åŠ¨ä½œç©ºé—´å¤§ï¼Œæ™ºèƒ½ä½“éš¾ä»¥æœ‰æ•ˆæ¢ç´¢
- **é¢†åŸŸçŸ¥è¯†ç¼ºå¤±**: ç¼ºä¹ç”µåŠ›ç³»ç»Ÿä¸“ä¸šçŸ¥è¯†çš„èå…¥

#### ğŸ’¡ è§£å†³æ–¹æ¡ˆ

**ç¬¬ä¸€é˜¶æ®µ - ç¨ å¯†å¥–åŠ± (Dense Rewards)**
```python
# å±€éƒ¨è¿é€šæ€§å¥–åŠ±ï¼šå³æ—¶æ‹“æ‰‘åé¦ˆ
local_connectivity_reward = connectivity_improvement * 0.4

# å¢é‡å¹³è¡¡å¥–åŠ±ï¼šå®æ—¶è´Ÿè½½å¹³è¡¡ç›‘æ§
incremental_balance_reward = balance_improvement * 0.3

# è¾¹ç•Œå‹ç¼©å¥–åŠ±ï¼šå‡å°‘åˆ†åŒºé—´è€¦åˆ
boundary_compression_reward = coupling_reduction * 0.3
```

**ç¬¬äºŒé˜¶æ®µ - æ™ºèƒ½æ¢ç´¢ (Smart Exploration)**
```python
# æ¢ç´¢å¥–åŠ±ï¼šé¼“åŠ±çŠ¶æ€ç©ºé—´æ¢ç´¢
exploration_bonus = novelty_score * 0.1

# åŠ¿å‡½æ•°å¡‘é€ ï¼šåŸºäºæ‹“æ‰‘çš„é•¿æœŸå¼•å¯¼
potential_shaping = topology_potential_diff * 0.2
```

**ç¬¬ä¸‰é˜¶æ®µ - è‡ªé€‚åº”ç‰©ç†çº¦æŸ (Adaptive Physics)**
```python
# é‚»å±…ä¸€è‡´æ€§ï¼šèå…¥ç”µåŠ›ç³»ç»Ÿç‰©ç†çº¦æŸ
neighbor_consistency = physical_constraint_satisfaction * 0.15

# è‡ªé€‚åº”æƒé‡ï¼šæ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´
adaptive_weights = adjust_weights_by_episode(episode_count)
```

### é…ç½®ä¸ä½¿ç”¨

```yaml
# config.yamlä¸­çš„å¢å¼ºå¥–åŠ±é…ç½®
environment:
  reward_weights:
    use_enhanced_rewards: true
    enhanced_config:
      enable_dense_rewards: true      # ç¬¬ä¸€é˜¶æ®µ
      enable_exploration_bonus: true  # ç¬¬äºŒé˜¶æ®µ
      enable_potential_shaping: true  # ç¬¬äºŒé˜¶æ®µ
      enable_adaptive_weights: true   # ç¬¬ä¸‰é˜¶æ®µ
```

## ğŸ”¬ åŸºçº¿æ–¹æ³•å¯¹æ¯”

é¡¹ç›®å†…ç½®å¤šç§åŸºçº¿æ–¹æ³•ç”¨äºæ€§èƒ½å¯¹æ¯”ï¼š

```bash
# è®­ç»ƒå®Œæˆåè‡ªåŠ¨è¿è¡ŒåŸºçº¿å¯¹æ¯”
python main.py --mode standard --save-results

# æ‰‹åŠ¨è¿è¡ŒåŸºçº¿å¯¹æ¯”
from code.baseline import run_baseline_comparison
comparison_results = run_baseline_comparison(env, agent)
```

### æ”¯æŒçš„åŸºçº¿æ–¹æ³•

- **è°±èšç±»**: åŸºäºå›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„èšç±»
- **K-means**: åŸºäºèŠ‚ç‚¹åµŒå…¥çš„K-meansèšç±»
- **éšæœºåˆ†åŒº**: éšæœºåˆ†é…åŸºå‡†
- **METIS**: å›¾åˆ†åŒºä¼˜åŒ–ç®—æ³•(å¯é€‰)

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

```
â”œâ”€â”€ main.py                   # ä¸»è®­ç»ƒå…¥å£ï¼ˆç»Ÿä¸€æ‰€æœ‰è®­ç»ƒæ¨¡å¼ï¼‰
â”œâ”€â”€ config.yaml              # ç»Ÿä¸€é…ç½®æ–‡ä»¶ï¼ˆåŒ…å«å¢å¼ºå¥–åŠ±é…ç½®ï¼‰
â”œâ”€â”€ code/                     # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ src/                  # æºä»£ç 
â”‚   â”‚   â”œâ”€â”€ data_processing.py    # æ•°æ®å¤„ç†
â”‚   â”‚   â”œâ”€â”€ gat.py               # GATç¼–ç å™¨
â”‚   â”‚   â”œâ”€â”€ visualization.py     # å¯è§†åŒ–
â”‚   â”‚   â””â”€â”€ rl/                  # å¼ºåŒ–å­¦ä¹ æ¨¡å—
â”‚   â”‚       â”œâ”€â”€ environment.py       # ç¯å¢ƒå®šä¹‰
â”‚   â”‚       â”œâ”€â”€ agent.py             # PPOæ™ºèƒ½ä½“
â”‚   â”‚       â”œâ”€â”€ action_space.py      # åŠ¨ä½œç©ºé—´
â”‚   â”‚       â”œâ”€â”€ state.py             # çŠ¶æ€ç®¡ç†
â”‚   â”‚       â”œâ”€â”€ reward.py            # å¥–åŠ±å‡½æ•°ï¼ˆå«å¢å¼ºå¥–åŠ±ç³»ç»Ÿï¼‰
â”‚   â”‚       â”œâ”€â”€ reward_analyzer.py   # å¥–åŠ±åˆ†æå·¥å…·
â”‚   â”‚       â”œâ”€â”€ gym_wrapper.py       # Gymç¯å¢ƒåŒ…è£…å™¨
â”‚   â”‚       â”œâ”€â”€ ppo_trainer.py       # PPOè®­ç»ƒå™¨
â”‚   â”‚       â””â”€â”€ utils.py             # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ baseline/             # åŸºçº¿æ–¹æ³•
â”‚   â”‚   â”œâ”€â”€ spectral_clustering.py
â”‚   â”‚   â”œâ”€â”€ kmeans_clustering.py
â”‚   â”‚   â”œâ”€â”€ evaluator.py
â”‚   â”‚   â””â”€â”€ comparison.py
â”‚   â””â”€â”€ clean.py              # ç¼“å­˜æ¸…ç†å·¥å…·
â”œâ”€â”€ cache/                    # ç¼“å­˜æ–‡ä»¶
â”œâ”€â”€ logs/                     # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ checkpoints/              # æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ models/                   # ä¿å­˜çš„æ¨¡å‹
â”œâ”€â”€ experiments/              # å®éªŒç»“æœ
â””â”€â”€ output/                   # è¾“å‡ºæ–‡ä»¶
    â””â”€â”€ figures/              # ç”Ÿæˆçš„å›¾è¡¨
```

## ğŸ“ˆ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è®­ç»ƒæµç¨‹

```python
# 1. åˆ›å»ºè®­ç»ƒç³»ç»Ÿ
from main import UnifiedTrainingSystem
trainer = UnifiedTrainingSystem()

# 2. è¿è¡Œè®­ç»ƒ
results = trainer.run_training(mode='standard')

# 3. æŸ¥çœ‹ç»“æœ
print(f"æœ€ç»ˆå¥–åŠ±: {results['final_reward']}")
print(f"è®­ç»ƒæ—¶é—´: {results['training_time']}")
```

### å¢å¼ºå¥–åŠ±è®­ç»ƒ

```python
# ä½¿ç”¨å¢å¼ºå¥–åŠ±ç³»ç»Ÿè®­ç»ƒ
from main import UnifiedTrainingSystem
trainer = UnifiedTrainingSystem()

# ç¬¬ä¸€é˜¶æ®µï¼šç¨ å¯†å¥–åŠ±è®­ç»ƒ
stage1_results = trainer.run_training(config='stage1_dense_rewards')

# ç¬¬äºŒé˜¶æ®µï¼šæ™ºèƒ½æ¢ç´¢è®­ç»ƒ
stage2_results = trainer.run_training(config='stage2_smart_exploration')

# ç¬¬ä¸‰é˜¶æ®µï¼šè‡ªé€‚åº”ç‰©ç†çº¦æŸè®­ç»ƒ
stage3_results = trainer.run_training(config='stage3_adaptive_physics')

# å®Œæ•´å¢å¼ºå¥–åŠ±è®­ç»ƒ
enhanced_results = trainer.run_training(config='enhanced_rewards_training')
```

### è‡ªå®šä¹‰è®­ç»ƒ

```python
# è‡ªå®šä¹‰é…ç½®
custom_config = {
    'environment': {
        'case_name': 'ieee57',
        'num_partitions': 6,
        'max_steps': 300,
        'reward_weights': {
            'use_enhanced_rewards': True,
            'enhanced_config': {
                'enable_dense_rewards': True,
                'enable_exploration_bonus': False,
                'enable_potential_shaping': False,
                'enable_adaptive_weights': False,
            }
        }
    },
    'training': {
        'episodes': 2000,
        'learning_rate': 1e-3,
        'batch_size': 64
    }
}

# è¿è¡Œè‡ªå®šä¹‰è®­ç»ƒ
results = trainer.run_training(mode='custom', config=custom_config)
```

### W&B (Weights & Biases) é›†æˆ

é™¤äº†TensorBoardï¼Œæœ¬é¡¹ç›®ä¹Ÿæ”¯æŒä½¿ç”¨[Weights & Biases](https://wandb.ai)è¿›è¡Œæ›´å¼ºå¤§çš„å®éªŒè·Ÿè¸ªå’Œå¯è§†åŒ–ã€‚

#### å¯ç”¨W&B

1.  **å®‰è£…W&B**
    
    `wandb`å·²åœ¨`requirements.txt`ä¸­åˆ—ä¸ºå¯é€‰ä¾èµ–ã€‚å¦‚æœå°šæœªå®‰è£…ï¼Œè¯·è¿è¡Œï¼š
    ```bash
    pip install wandb
    ```

2.  **ç™»å½•è´¦æˆ·**

    åœ¨æ‚¨çš„ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå¹¶æ ¹æ®æç¤ºè¾“å…¥æ‚¨çš„APIå¯†é’¥ï¼ˆå¯åœ¨W&Bå®˜ç½‘çš„ç”¨æˆ·è®¾ç½®ä¸­æ‰¾åˆ°ï¼‰ã€‚
    ```bash
    wandb login
    ```

3.  **å¯åŠ¨è®­ç»ƒ**

    åœ¨è¿è¡Œ`main.py`æ—¶ï¼Œæ·»åŠ `--use-wandb`æ ‡å¿—ä»¥å¯ç”¨W&Bæ—¥å¿—è®°å½•ã€‚
    ```bash
    python main.py --mode standard --use-wandb
    ```
    æ‚¨ä¹Ÿå¯ä»¥åœ¨`config.yaml`ä¸­å°†å…¶è®¾ç½®ä¸ºé»˜è®¤å¯ç”¨ï¼š
    ```yaml
    # config.yaml
    training:
      use_wandb: true
    ```

#### W&Bç‰¹æ€§

å¯ç”¨åï¼ŒW&Bå°†è‡ªåŠ¨è®°å½•ï¼š
-   æ‰€æœ‰TensorBoardä¸­çš„æŒ‡æ ‡ï¼ˆå¥–åŠ±ã€æŸå¤±ã€æ€§èƒ½ç­‰ï¼‰ã€‚
-   è¶…å‚æ•°é…ç½®ï¼Œæ–¹ä¾¿å¯¹æ¯”ä¸åŒå®éªŒã€‚
-   ç³»ç»Ÿç¡¬ä»¶æŒ‡æ ‡ï¼ˆGPU/CPUåˆ©ç”¨ç‡ã€æ¸©åº¦ç­‰ï¼‰ã€‚
-   ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶å’Œä»£ç ç‰ˆæœ¬ã€‚

æ‚¨å¯ä»¥åœ¨W&Bçš„Webç•Œé¢ä¸ŠæŸ¥çœ‹å’Œæ¯”è¾ƒæ‰€æœ‰å®éªŒè¿è¡Œï¼Œç”Ÿæˆæ›´ä¸°å¯Œçš„å›¾è¡¨ã€‚

### ç»“æœåˆ†æ

```python
# åŠ è½½è®­ç»ƒç»“æœ
import pickle
with open('experiments/results.pkl', 'rb') as f:
    results = pickle.load(f)

# åˆ†æè®­ç»ƒæ›²çº¿
import matplotlib.pyplot as plt
plt.plot(results['reward_history'])
plt.title('Training Reward Curve')
plt.show()

# å¢å¼ºå¥–åŠ±ç»„ä»¶åˆ†æ
if 'reward_components' in results:
    components = results['reward_components']

    # ç»˜åˆ¶å¥–åŠ±ç»„ä»¶æ¼”åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    axes[0,0].plot(components['local_connectivity'])
    axes[0,0].set_title('Local Connectivity Rewards')

    axes[0,1].plot(components['incremental_balance'])
    axes[0,1].set_title('Incremental Balance Rewards')

    axes[1,0].plot(components['boundary_compression'])
    axes[1,0].set_title('Boundary Compression Rewards')

    axes[1,1].plot(components['total_reward'])
    axes[1,1].set_title('Total Reward')

    plt.tight_layout()
    plt.show()

# åŸºçº¿æ–¹æ³•å¯¹æ¯”
comparison_df = results['baseline_comparison']
print(comparison_df)
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
```bash
# å‡å°‘æ‰¹å¤§å°æˆ–ä½¿ç”¨CPU
python main.py --mode quick --device cpu
```

2. **ä¾èµ–å®‰è£…é—®é¢˜**
```bash
# å‡çº§pipå’Œsetuptools
pip install --upgrade pip setuptools
pip install -r requirements.txt
```

3. **è®­ç»ƒè¿‡ç¨‹ä¸­æ–­**
```bash
# ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
python main.py --mode standard --resume --checkpoint checkpoints/latest.pt
```

### æ€§èƒ½ä¼˜åŒ–

- **GPUåŠ é€Ÿ**: ç¡®ä¿å®‰è£…æ­£ç¡®çš„CUDAå’ŒPyTorchç‰ˆæœ¬
- **å¹¶è¡Œè®­ç»ƒ**: ä½¿ç”¨`--mode parallel`å¯ç”¨å¤šè¿›ç¨‹è®­ç»ƒ
- **å†…å­˜ä¼˜åŒ–**: è°ƒæ•´æ‰¹å¤§å°å’Œç¼“å­˜è®¾ç½®
- **æ•°æ®é¢„å¤„ç†**: é¢„è®¡ç®—ç‰¹å¾å’Œç¼“å­˜ç½‘ç»œç»“æ„

## ğŸ“š è¿›é˜¶ä½¿ç”¨

### æ·»åŠ æ–°çš„ç”µåŠ›ç³»ç»Ÿç®—ä¾‹

1. å‡†å¤‡MATPOWERæ ¼å¼çš„.mæ–‡ä»¶
2. æ”¾ç½®åœ¨é€‚å½“çš„æ•°æ®ç›®å½•
3. åœ¨é…ç½®ä¸­æŒ‡å®šæ–°ç®—ä¾‹åç§°

### è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°

```python
# åœ¨code/src/rl/reward.pyä¸­ä¿®æ”¹
class CustomRewardFunction(RewardFunction):
    def compute_reward(self, current_partition, boundary_nodes, action):
        # è‡ªå®šä¹‰å¥–åŠ±é€»è¾‘
        pass

# ä½¿ç”¨å¢å¼ºå¥–åŠ±å‡½æ•°
class MyEnhancedRewardFunction(EnhancedRewardFunction):
    def compute_custom_component(self, current_partition, boundary_nodes, action):
        # æ·»åŠ è‡ªå®šä¹‰å¥–åŠ±ç»„ä»¶
        custom_reward = 0.0
        # å®ç°è‡ªå®šä¹‰é€»è¾‘
        return custom_reward

    def compute_reward(self, current_partition, boundary_nodes, action):
        # è°ƒç”¨åŸºç¡€å¢å¼ºå¥–åŠ±
        base_reward = super().compute_reward(current_partition, boundary_nodes, action)

        # æ·»åŠ è‡ªå®šä¹‰ç»„ä»¶
        custom_component = self.compute_custom_component(current_partition, boundary_nodes, action)

        return base_reward + 0.1 * custom_component  # è‡ªå®šä¹‰æƒé‡
```

### æ‰©å±•åŸºçº¿æ–¹æ³•

```python
# åœ¨code/baseline/ä¸­æ·»åŠ æ–°æ–¹æ³•
class MyPartitioner(BasePartitioner):
    def partition(self, env):
        # å®ç°è‡ªå®šä¹‰åˆ†åŒºç®—æ³•
        pass
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤Issue: [GitHub Issues](https://github.com/yourrepo/issues)
- é‚®ç®±: your.email@example.com

## ğŸ™ è‡´è°¢

- PyTorchå›¢é˜Ÿæä¾›çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- PyTorch Geometricå›¢é˜Ÿæä¾›çš„å›¾ç¥ç»ç½‘ç»œåº“
- MATPOWERå›¢é˜Ÿæä¾›çš„ç”µåŠ›ç³»ç»Ÿæ•°æ®æ ¼å¼
- å¼€æºç¤¾åŒºçš„è´¡çŒ®å’Œæ”¯æŒ

---

**å¼€å§‹æ‚¨çš„ç”µåŠ›ç½‘ç»œåˆ†åŒºä¼˜åŒ–ä¹‹æ—…å§ï¼** ğŸš€ 