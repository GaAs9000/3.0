# åŠ¿å‡½æ•°å¥–åŠ±ç³»ç»Ÿ

## ğŸ¯ æ ¸å¿ƒé—®é¢˜

ç”µåŠ›ç½‘ç»œåˆ†åŒºçš„è¯„ä»·æŒ‡æ ‡å¤æ‚ä¸”ç›¸äº’è€¦åˆï¼Œä¼ ç»Ÿç¨€ç–å¥–åŠ±éš¾ä»¥æœ‰æ•ˆæŒ‡å¯¼è®­ç»ƒã€‚ä¸åŒåœºæ™¯ï¼ˆæ­£å¸¸è¿è¡Œvsæ•…éšœçŠ¶æ€ï¼‰çš„éš¾åº¦å·®å¼‚å¯¼è‡´è®­ç»ƒåå‘é—®é¢˜ã€‚

## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ï¼šè‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±

### è®¾è®¡ç†å¿µ

1. **åŠ¿å‡½æ•°ç†è®º**: ä¿æŒæœ€ä¼˜ç­–ç•¥ä¸å˜çš„å¯†é›†å¥–åŠ±
2. **ç›¸å¯¹æ”¹è¿›**: è§£å†³è·¨åœºæ™¯è®­ç»ƒåå‘é—®é¢˜
3. **å¹³å°æœŸæ£€æµ‹**: æ™ºèƒ½æ•ˆç‡æ¿€åŠ±æœºåˆ¶
4. **å®Œå…¨è‡ªé€‚åº”**: é›¶å›ºå®šé˜ˆå€¼ï¼Œè‡ªåŠ¨é€‚åº”ä¸åŒç½‘ç»œè§„æ¨¡

## ğŸ“Š æ•°å­¦æ¡†æ¶

### è´¨é‡åˆ†æ•°è®¡ç®—

**ç»¼åˆè´¨é‡å‡½æ•°:**
```
Q(s) = wâ‚Â·R_balance(CV) + wâ‚‚Â·R_decoupling + wâ‚ƒÂ·R_power

å…¶ä¸­:
R_balance = exp(-2.0 Â· CV)
R_decoupling = 0.5Â·Ïƒ(5(r_edge-0.5)) + 0.5Â·Ïƒ(5(r_admittance-0.5))
R_power = exp(-3.0 Â· I_normalized)

CV = std(partition_sizes) / mean(partition_sizes)
Ïƒ(x) = sigmoidå‡½æ•°
```

### åŠ¿å‡½æ•°ä¸»å¥–åŠ±

**ç›¸å¯¹æ”¹è¿›å¥–åŠ±:**
```
R_potential = (Q(s_{t+1}) - Q(s_t)) / Q(s_t)

æ•°å€¼ç¨³å®šæ€§å¤„ç†:
- å½“ Q(s_t) > 0.01: ä½¿ç”¨ç›¸å¯¹æ”¹è¿›å…¬å¼
- å½“ Q(s_t) â‰¤ 0.01: ä½¿ç”¨ç»å¯¹æ”¹è¿› Q(s_{t+1}) - Q(s_t)
- ç»“æœè£å‰ª: R_potential âˆˆ [-2.0, 2.0]
```

### å®Œæ•´å¥–åŠ±ç»“æ„

**æ€»å¥–åŠ±ç»„æˆ:**
```
R_total = R_potential + Î»Â·Î·_efficiency(t)

å…¶ä¸­:
R_potential: åŠ¿å‡½æ•°ä¸»å¥–åŠ±ï¼ˆå§‹ç»ˆæ¿€æ´»ï¼‰
Î·_efficiency: æ•ˆç‡å¥–åŠ±ï¼ˆä»…åœ¨å¹³å°æœŸæ¿€æ´»ï¼‰
Î»: æ•ˆç‡å¥–åŠ±æƒé‡
```

**æ•ˆç‡å¥–åŠ±è®¾è®¡:**
```
Î·_efficiency(t) = {
    0,                           if not in_plateau
    (max_steps - t) / max_steps, if in_plateau
}

ç›®çš„: åœ¨è´¨é‡å¹³å°æœŸé¼“åŠ±å¿«é€Ÿæ”¶æ•›
```

## ğŸ¯ è·¨åœºæ™¯è®­ç»ƒåå‘é—®é¢˜

### é—®é¢˜åˆ†æ

**åœºæ™¯éš¾åº¦å·®å¼‚:**
```
æ­£å¸¸åœºæ™¯: 0.70â†’0.72 (æ”¹è¿›0.02) â†’ å®½æ¾æ¡ä»¶ï¼Œå®¹æ˜“å®ç°
æ•…éšœåœºæ™¯: 0.40â†’0.42 (æ”¹è¿›0.02) â†’ N-1çº¦æŸï¼Œå›°éš¾å®ç°

ä¼ ç»Ÿç»å¯¹å¥–åŠ±ç¼ºé™·:
- ç®—æ³•åå‘ç®€å•åœºæ™¯
- å¿½ç•¥å›°éš¾åœºæ™¯å­¦ä¹ 
- å…³é”®åœºæ™¯æ³›åŒ–èƒ½åŠ›å·®
```

### ç›¸å¯¹æ”¹è¿›è§£å†³æ–¹æ¡ˆ

**å…¬å¹³æ¿€åŠ±æœºåˆ¶:**
```
æ•…éšœåœºæ™¯: (0.42-0.40)/0.40 = 5%æ”¹è¿› â†’ å¥–åŠ±+0.05
æ­£å¸¸åœºæ™¯: (0.714-0.68)/0.68 = 5%æ”¹è¿› â†’ å¥–åŠ±+0.05

ç»“æœ: ç›¸åŒç›¸å¯¹åŠªåŠ›è·å¾—ç›¸åŒå¥–åŠ±
```

## ğŸ”§ å®ç°ç»†èŠ‚

### æ ¸å¿ƒå¥–åŠ±è®¡ç®—

<augment_code_snippet path="code/src/rl/reward.py" mode="EXCERPT">
````python
def _compute_simple_relative_reward(self, prev_quality: float, curr_quality: float) -> float:
    """è®¡ç®—ç›¸å¯¹æ”¹è¿›å¥–åŠ±"""
    if prev_quality > 0.01:
        # ä½¿ç”¨ç›¸å¯¹æ”¹è¿›
        relative_improvement = (curr_quality - prev_quality) / prev_quality
    else:
        # ä½¿ç”¨ç»å¯¹æ”¹è¿›ï¼ˆé¿å…é™¤é›¶ï¼‰
        relative_improvement = curr_quality - prev_quality

    # æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
    return np.clip(relative_improvement, -2.0, 2.0)
````
</augment_code_snippet>

### è´¨é‡åˆ†æ•°è®¡ç®—

<augment_code_snippet path="code/src/rl/reward.py" mode="EXCERPT">
````python
def _compute_balance_reward(self, cv: float) -> float:
    """å¹³è¡¡æ€§å¥–åŠ±: R_balance = exp(-2.0 * CV)"""
    cv = max(0.0, min(cv, 10.0))  # é˜²æ­¢æå€¼
    exp_arg = np.clip(-2.0 * cv, -500, 0)  # é˜²æ­¢expæº¢å‡º
    return np.clip(np.exp(exp_arg), 0.0, 1.0)

def _compute_decoupling_reward(self, edge_ratio: float, coupling_ratio: float) -> float:
    """è§£è€¦å¥–åŠ±: åŸºäºè¾¹ç•Œæ¯”ä¾‹å’Œè€¦åˆå¼ºåº¦"""
    edge_score = self._sigmoid_transform(edge_ratio, center=0.5, steepness=5)
    coupling_score = self._sigmoid_transform(coupling_ratio, center=0.5, steepness=5)
    return 0.5 * edge_score + 0.5 * coupling_score
````
</augment_code_snippet>

## ğŸ“ˆ å¹³å°æœŸæ£€æµ‹ç®—æ³•

### æ£€æµ‹é€»è¾‘

```
ALGORITHM: QualityPlateauDetection
INPUT: recent_scores[window_size], all_history_scores
OUTPUT: plateau_detected, confidence

1. æ”¹å–„ç‡æ£€æµ‹:
   slope = linear_regression_slope(recent_scores)
   improvement_rate = |slope|

2. ç¨³å®šæ€§æ£€æµ‹:
   variance = var(recent_scores)
   stability_score = 1 / (1 + variance)

3. ç»¼åˆåˆ¤æ–­:
   plateau_detected = (
       improvement_rate < threshold AND
       stability_score > min_stability
   )
### å¹³å°æœŸæ£€æµ‹å®ç°

<augment_code_snippet path="code/src/rl/reward.py" mode="EXCERPT">
````python
def detect_plateau(self, current_score: float, scenario_context=None):
    """æ£€æµ‹è´¨é‡å¹³å°æœŸ"""
    # æ›´æ–°å†å²è®°å½•
    self.quality_history.append(current_score)

    # è®¡ç®—æ”¹å–„ç‡
    recent_scores = self.quality_history[-self.window_size:]
    improvement_rate = self._calculate_improvement_rate(recent_scores)

    # è®¡ç®—ç¨³å®šæ€§
    stability_score = self._calculate_stability(recent_scores)

    # ç»¼åˆåˆ¤æ–­
    plateau_detected = (
        improvement_rate < self.min_improvement_threshold and
        stability_score > self.stability_threshold
    )

    return PlateauResult(
        is_plateau=plateau_detected,
        confidence=stability_score,
        improvement_rate=improvement_rate
    )
````
</augment_code_snippet>

## ğŸ› ï¸ æ•°å€¼ç¨³å®šæ€§å¤„ç†

### é˜²æ­¢æ•°å€¼å¼‚å¸¸

```python
def _safe_divide(self, numerator: float, denominator: float, fallback: float = 0.0) -> float:
    """å®‰å…¨é™¤æ³•ï¼Œé˜²æ­¢é™¤é›¶å’Œæ•°å€¼æº¢å‡º"""
    if abs(denominator) < 1e-8:
        return fallback
    result = numerator / denominator
    return np.clip(result, -1e6, 1e6)

def _safe_exp(self, x: float) -> float:
    """å®‰å…¨æŒ‡æ•°å‡½æ•°ï¼Œé˜²æ­¢æº¢å‡º"""
    x = np.clip(x, -500, 500)
    return np.exp(x)
```

## ğŸ“Š ç†è®ºä¿è¯

### åŠ¿å‡½æ•°ç†è®ºåŸºç¡€

åŸºäºNgç­‰äººçš„åŠ¿å‡½æ•°ç†è®ºï¼š
- **æœ€ä¼˜ç­–ç•¥ä¿æŒä¸å˜**: Ï€*(åŸç¯å¢ƒ) = Ï€*(å¢å¼ºç¯å¢ƒ)
- **æ”¶æ•›æ€§ä¿è¯**: Qå­¦ä¹ ç®—æ³•ä»ç„¶æ”¶æ•›åˆ°æœ€ä¼˜Qå‡½æ•°
- **è®­ç»ƒåŠ é€Ÿ**: æä¾›å¯†é›†çš„ä¸­é—´æŒ‡å¯¼ä¿¡å·

### ç›¸å¯¹å¥–åŠ±ä¼˜åŠ¿

1. **è·¨åœºæ™¯å…¬å¹³æ€§**: ç›¸åŒåŠªåŠ›è·å¾—ç›¸åŒå¥–åŠ±
2. **è‡ªåŠ¨é€‚åº”æ€§**: æ— éœ€é’ˆå¯¹ä¸åŒç½‘ç»œè°ƒå‚
3. **è®­ç»ƒç¨³å®šæ€§**: é¿å…å¥–åŠ±å°ºåº¦å·®å¼‚å¯¼è‡´çš„ä¸ç¨³å®š
2. **_compute_quality_score()**: ç»Ÿä¸€è´¨é‡åˆ†æ•°è®¡ç®—ï¼Œæ”¯æŒè·¨ç½‘ç»œé€‚åº”æ€§
3. **plateau_detector**: å¹³å°æœŸæ£€æµ‹å™¨å®ä¾‹ï¼Œç®¡ç†æ£€æµ‹çŠ¶æ€
4. **adaptive_quality_config**: è‡ªé€‚åº”è´¨é‡é…ç½®ï¼Œæ§åˆ¶æ£€æµ‹å‚æ•°

## âš™ï¸ é…ç½®å‚æ•°è®¾è®¡

### æ–°å¢é…ç½®èŠ‚

```yaml
adaptive_quality:
  enabled: true

  # å¹³å°æœŸæ£€æµ‹å‚æ•°
  plateau_detection:
    window_size: 15                    # è§‚å¯Ÿçª—å£å¤§å°
    min_improvement_rate: 0.005        # æœ€å°æ”¹å–„ç‡é˜ˆå€¼
    stability_threshold: 0.8           # ç¨³å®šæ€§è¦æ±‚
    min_percentile: 0.7                # å†å²è¡¨ç°è¦æ±‚(å‰70%)
    confidence_threshold: 0.8          # æ—©åœç½®ä¿¡åº¦è¦æ±‚

  # æ•ˆç‡å¥–åŠ±å‚æ•°
  efficiency_reward:
    lambda: 0.5                        # æ•ˆç‡å¥–åŠ±æƒé‡
    early_stop_confidence: 0.85        # æ—©åœç½®ä¿¡åº¦é˜ˆå€¼

  # è´¨é‡åˆ†æ•°æƒé‡(æ›¿ä»£åŸæœ‰å›ºå®šé˜ˆå€¼)
  quality_weights:
    cv_weight: 0.4
    coupling_weight: 0.3
    power_weight: 0.3
```

### ç§»é™¤çš„é…ç½®

```yaml
# åˆ é™¤è¿™äº›å›ºå®šé˜ˆå€¼é…ç½®
thresholds:
  excellent_cv: 0.1          # âŒ åˆ é™¤
  good_cv: 0.2               # âŒ åˆ é™¤
  excellent_coupling: 0.3    # âŒ åˆ é™¤
  good_coupling: 0.5         # âŒ åˆ é™¤
  excellent_power: 10.0      # âŒ åˆ é™¤
  good_power: 50.0           # âŒ åˆ é™¤
## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºæœ¬é…ç½®

```python
# åœ¨config.yamlä¸­å¯ç”¨è‡ªé€‚åº”è´¨é‡ç³»ç»Ÿ
adaptive_quality:
  enabled: true
  plateau_detection:
    window_size: 15
    min_improvement_rate: 0.005
    stability_threshold: 0.8
    min_percentile: 0.7
    confidence_threshold: 0.8
  efficiency_reward:
    lambda: 0.5
    early_stop_confidence: 0.85
  quality_weights:
    cv_weight: 0.4
    coupling_weight: 0.3
    power_weight: 0.3
```

### 2. ç¯å¢ƒé›†æˆ

```python
# åˆ›å»ºæ”¯æŒè‡ªé€‚åº”è´¨é‡çš„ç¯å¢ƒ
env = PowerGridPartitioningEnv(
    hetero_data=hetero_data,
    node_embeddings=node_embeddings,
    num_partitions=3,
    reward_weights={},  # ç»Ÿä¸€ä½¿ç”¨è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±ç³»ç»Ÿ
    max_steps=200,
    device=device,
    config=config  # åŒ…å«adaptive_qualityé…ç½®
)

# è®­ç»ƒå¾ªç¯
obs, info = env.reset()
for step in range(max_steps):
    action = agent.select_action(obs)
    obs, reward, terminated, truncated, info = env.step(action)

    # æ£€æŸ¥æ—©åœ
    if info.get('early_termination', False):
        print(f"æ—©åœè§¦å‘äºç¬¬{step}æ­¥ï¼Œç½®ä¿¡åº¦={info['plateau_confidence']:.3f}")
        break
```

### 3. å¥–åŠ±å‡½æ•°ç›´æ¥ä½¿ç”¨

```python
# åˆ›å»ºå¥–åŠ±å‡½æ•°
reward_function = RewardFunction(
    hetero_data,
    config={'adaptive_quality': adaptive_config},
    device=device
)

# è®¡ç®—å¥–åŠ±
reward, plateau_result = reward_function.compute_incremental_reward(
    current_partition, action
)

# æ£€æŸ¥å¹³å°æœŸ
if plateau_result and plateau_result.plateau_detected:
    print(f"æ£€æµ‹åˆ°å¹³å°æœŸï¼Œç½®ä¿¡åº¦: {plateau_result.confidence:.3f}")
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœä¸éªŒè¯

### 1. è®­ç»ƒæ•ˆæœæ”¹å–„

**æŒ‡æ ‡ç›‘æ§**:
- `average_episode_length`: åº”è¯¥éšè®­ç»ƒä¸‹é™ï¼ˆæ›´å¿«æ”¶æ•›ï¼‰
- `early_termination_rate`: åº”è¯¥éšè®­ç»ƒä¸Šå‡ï¼ˆæ›´å¤šæ—©åœæˆåŠŸï¼‰
- `plateau_confidence_mean`: æ£€æµ‹å™¨çš„å¹³å‡ç½®ä¿¡åº¦
- `quality_score_final`: æœ€ç»ˆè´¨é‡åˆ†æ•°åˆ†å¸ƒ

### 2. è·¨ç½‘ç»œé€‚åº”æ€§éªŒè¯

**æµ‹è¯•æ–¹æ¡ˆ**:
```
FOR each_network IN [IEEE14, IEEE30, IEEE57, IEEE118]:
    ä½¿ç”¨å®Œå…¨ç›¸åŒçš„é…ç½®å‚æ•°è®­ç»ƒ

    è®°å½•ï¼š
    - æ”¶æ•›çš„quality_scoreèŒƒå›´
    - å¹³å°æœŸæ£€æµ‹çš„è§¦å‘æ—¶æœº
    - æ—©åœæˆåŠŸç‡

    éªŒè¯ï¼š
    - ä¸åŒç½‘ç»œéƒ½èƒ½ç¨³å®šè®­ç»ƒ
    - è´¨é‡æ”¹å–„æ›²çº¿å½¢çŠ¶ç›¸ä¼¼
    - æ— éœ€é’ˆå¯¹æ€§è°ƒå‚
```

### 3. æ¶ˆèå®éªŒ

```
å®éªŒç»„A: ä»…ä¸»å¥–åŠ±(åŠ¿å‡½æ•°)
å®éªŒç»„B: ä¸»å¥–åŠ± + å›ºå®šé˜ˆå€¼æ—©åœ
å®éªŒç»„C: ä¸»å¥–åŠ± + è‡ªé€‚åº”å¹³å°æœŸæ£€æµ‹ (å®Œæ•´æ–¹æ¡ˆ)

å¯¹æ¯”ç»´åº¦:
- è®­ç»ƒç¨³å®šæ€§
- æœ€ç»ˆè´¨é‡
- æ”¶æ•›é€Ÿåº¦
- è·¨ç½‘ç»œæ³›åŒ–æ€§
```

## ğŸ”§ å®æ–½ä¼˜å…ˆçº§

### Phase 1: æ ¸å¿ƒç®—æ³• (å¿…é¡»)
1. âœ… å®ç° `compute_quality_score()` å‡½æ•°
2. âœ… ä¿®æ”¹ä¸»å¥–åŠ±ä¸ºåŠ¿å‡½æ•°å½¢å¼
3. âœ… åŸºç¡€çš„å¹³å°æœŸæ£€æµ‹é€»è¾‘

### Phase 2: é›†æˆä¸è°ƒä¼˜ (é‡è¦)
1. âœ… ç¯å¢ƒå±‚é›†æˆæ—©åœé€»è¾‘
2. âœ… æ•ˆç‡å¥–åŠ±æœºåˆ¶
3. âœ… é…ç½®æ–‡ä»¶é‡æ„

### Phase 3: ç›‘æ§ä¸éªŒè¯ (å»ºè®®)
1. âœ… è¯¦ç»†çš„æ—¥å¿—å’Œå¯è§†åŒ–
2. ğŸ”„ è·¨ç½‘ç»œæµ‹è¯•
3. ğŸ”„ è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ

## ğŸ’¡ å…³é”®æˆåŠŸå› ç´ 

1. **å½’ä¸€åŒ–å‡½æ•°è®¾è®¡**: ç¡®ä¿è´¨é‡åˆ†æ•°åœ¨ä¸åŒç½‘ç»œä¸Šå¯æ¯”
2. **çª—å£å¤§å°è°ƒä¼˜**: å¹³è¡¡æ£€æµ‹æ•æ„Ÿæ€§å’Œç¨³å®šæ€§
3. **æƒé‡é…ç½®**: ä¸»å¥–åŠ±vsæ•ˆç‡å¥–åŠ±çš„å¹³è¡¡
4. **æ¸è¿›å¼éƒ¨ç½²**: å…ˆåœ¨å•ä¸€ç½‘ç»œéªŒè¯ï¼Œå†æ¨å¹¿åˆ°å¤šç½‘ç»œ

## ğŸ§ª æµ‹è¯•éªŒè¯

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯ç³»ç»ŸåŠŸèƒ½ï¼š

```bash
python test_adaptive_quality.py
```

æµ‹è¯•å†…å®¹ï¼š
- âœ… å¹³å°æœŸæ£€æµ‹ç®—æ³•çš„æ­£ç¡®æ€§
- âœ… è´¨é‡åˆ†æ•°è®¡ç®—çš„è·¨ç½‘ç»œé€‚åº”æ€§
- âœ… æ—©åœæœºåˆ¶çš„è§¦å‘æ¡ä»¶
- âœ… ç³»ç»Ÿé›†æˆçš„å®Œæ•´æ€§

## ğŸ“š ç†è®ºåŸºç¡€

### åŠ¿å‡½æ•°å¥–åŠ±å¡‘é€ ç†è®º

åŸºäºNg et al. (1999)çš„åŠ¿å‡½æ•°å¥–åŠ±å¡‘é€ ç†è®ºï¼š
```
R'(s,a,s') = R(s,a,s') + Î³Î¦(s') - Î¦(s)
```

åœ¨æˆ‘ä»¬çš„ç³»ç»Ÿä¸­ï¼š
- **Î¦(s) = Q(s)**ï¼šåŠ¿å‡½æ•°ç›´æ¥ä½¿ç”¨è´¨é‡åˆ†æ•°
- **R(s,a,s') = 0**ï¼šåŸå§‹ç¯å¢ƒå¥–åŠ±ä¸º0
- **R'(s,a,s') = Î³Q(s') - Q(s)**ï¼šå¡‘å½¢åçš„å¥–åŠ±

**ç†è®ºä¿è¯**ï¼šåŠ¿å‡½æ•°å¥–åŠ±å¡‘é€ ä¸æ”¹å˜æœ€ä¼˜ç­–ç•¥ï¼Œåªæ”¹å˜å­¦ä¹ é€Ÿåº¦ã€‚

### å¹³å°æœŸæ£€æµ‹çš„æ•°å­¦åŸºç¡€

#### 1. æ”¹å–„ç‡æ£€æµ‹
ä½¿ç”¨çº¿æ€§å›å½’åˆ†æè´¨é‡åˆ†æ•°åºåˆ—çš„è¶‹åŠ¿ï¼š
```
slope = argmin_Î² Î£(Q_i - (Î± + Î²Â·i))Â²
improvement_rate = |slope|
```

#### 2. ç¨³å®šæ€§æ£€æµ‹
åŸºäºæ–¹å·®çš„ç¨³å®šæ€§åº¦é‡ï¼š
```
stability_score = 1 / (1 + Var(Q_recent))
```

#### 3. å†å²ç™¾åˆ†ä½æ•°
è¯„ä¼°å½“å‰è¡¨ç°åœ¨å†å²ä¸­çš„ç›¸å¯¹ä½ç½®ï¼š
```
percentile = |{Q_hist â‰¤ Q_current}| / |Q_hist|
```

### è·¨ç½‘ç»œé€‚åº”æ€§çš„æ•°å­¦åŸç†

é€šè¿‡å½’ä¸€åŒ–ç¡®ä¿è´¨é‡åˆ†æ•°çš„å¯æ¯”æ€§ï¼š
```
normalized_cv = CV / (1 + CV)           âˆˆ [0, 1)
normalized_coupling = coupling_ratio     âˆˆ [0, 1]
normalized_power = power_imb / (1 + power_imb) âˆˆ [0, 1)

Q(s) = 1 - (wâ‚Â·norm_cv + wâ‚‚Â·norm_coupling + wâ‚ƒÂ·norm_power) / (wâ‚ + wâ‚‚ + wâ‚ƒ)
```

è¿™ç§è®¾è®¡ç¡®ä¿ï¼š
- ä¸åŒç½‘ç»œè§„æ¨¡çš„è´¨é‡åˆ†æ•°å…·æœ‰å¯æ¯”æ€§
- æƒé‡é…ç½®åœ¨æ‰€æœ‰ç½‘ç»œä¸Šä¿æŒä¸€è‡´çš„è¯­ä¹‰
- æ— éœ€é’ˆå¯¹ç‰¹å®šç½‘ç»œè°ƒæ•´é˜ˆå€¼å‚æ•°

---

**æ€»ç»“**: è¿™å¥—è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±ç³»ç»Ÿå½»åº•ç§»é™¤äº†å›ºå®šé˜ˆå€¼ä¾èµ–ï¼Œé€šè¿‡åŠ¿å‡½æ•°+å¹³å°æœŸæ£€æµ‹å®ç°çœŸæ­£çš„è‡ªé€‚åº”è´¨é‡å¯¼å‘è®­ç»ƒã€‚åŒä¸€å¥—é…ç½®å¯ä»¥é€‚ç”¨äºä»»æ„è§„æ¨¡çš„ç”µç½‘ï¼Œæ—¢ä¿è¯è´¨é‡æ”¹å–„åˆé¼“åŠ±è®­ç»ƒæ•ˆç‡ã€‚
