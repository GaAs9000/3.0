# ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ - æŠ€æœ¯æŒ‡å¯¼æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿçš„æŠ€æœ¯å®ç°ã€å‚æ•°é…ç½®ã€æ¨¡å—è®¾è®¡å’Œæ‰©å±•æ–¹æ³•ã€‚

## ğŸ“‹ ç›®å½•

- [1. ç³»ç»Ÿæ¶æ„](#1-ç³»ç»Ÿæ¶æ„)
- [2. æ ¸å¿ƒæ¨¡å—è¯¦è§£](#2-æ ¸å¿ƒæ¨¡å—è¯¦è§£)
- [3. å‚æ•°é…ç½®æŒ‡å—](#3-å‚æ•°é…ç½®æŒ‡å—)
- [4. è®­ç»ƒæµç¨‹è¯¦è§£](#4-è®­ç»ƒæµç¨‹è¯¦è§£)
- [5. æ€§èƒ½ä¼˜åŒ–](#5-æ€§èƒ½ä¼˜åŒ–)
- [6. æ‰©å±•å¼€å‘](#6-æ‰©å±•å¼€å‘)
- [7. è°ƒè¯•å’Œæ•…éšœæ’é™¤](#7-è°ƒè¯•å’Œæ•…éšœæ’é™¤)

## 1. ç³»ç»Ÿæ¶æ„

### 1.1 æ•´ä½“è®¾è®¡

ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªå±‚æ¬¡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ä¸»è®­ç»ƒç³»ç»Ÿ                    â”‚
â”‚            (main.py)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             é…ç½®ç®¡ç†å±‚                       â”‚
â”‚    (config.yaml + åŠ¨æ€é…ç½®)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              ç®—æ³•å®ç°å±‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  æ•°æ®å¤„ç†   â”‚   å›¾ç¼–ç å™¨   â”‚   RLæ™ºèƒ½ä½“   â”‚ â”‚
â”‚  â”‚ data_proc.. â”‚    gat.py   â”‚   agent.py  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  
â”‚              ç¯å¢ƒä»¿çœŸå±‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ç¯å¢ƒ   â”‚  çŠ¶æ€   â”‚  åŠ¨ä½œ   â”‚  å¥–åŠ±   â”‚   â”‚
â”‚  â”‚ env.py  â”‚state.py â”‚action.. â”‚reward.. â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              åŸºçº¿å¯¹æ¯”å±‚                      â”‚
â”‚  (baseline/ - å¤šç§ä¼ ç»Ÿç®—æ³•)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              ç›‘æ§å¯è§†åŒ–å±‚                    â”‚
â”‚  (visualization.py + TensorBoard)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ•°æ®æµ

```
MATPOWERæ•°æ® â†’ å¼‚æ„å›¾æ„å»º â†’ å›¾åµŒå…¥ç”Ÿæˆ â†’ çŠ¶æ€è¡¨ç¤º 
     â†“
ç¯å¢ƒåˆå§‹åŒ– â†’ çŠ¶æ€è§‚å¯Ÿ â†’ æ™ºèƒ½ä½“å†³ç­– â†’ åŠ¨ä½œæ‰§è¡Œ â†’ å¥–åŠ±è®¡ç®—
     â†“                     â†‘
   ç¯å¢ƒæ›´æ–° â† åˆ†åŒºæ›´æ–° â† åŠ¨ä½œåº”ç”¨   â†“
     â†“                          â†“
   ç»ˆæ­¢æ£€æŸ¥ â†’ ç»éªŒå­˜å‚¨ â†’ PPOæ›´æ–° â†’ ç­–ç•¥æ”¹è¿›
```

## 2. æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 2.1 æ•°æ®å¤„ç†æ¨¡å— (`code/src/data_processing.py`)

#### åŠŸèƒ½æ¦‚è¿°
- å¤„ç†MATPOWERæ ¼å¼ç”µåŠ›ç³»ç»Ÿæ•°æ®
- æ„å»ºå¼‚æ„å›¾æ•°æ®ç»“æ„
- ç‰¹å¾æå–å’Œé¢„å¤„ç†
- æ•°æ®ç¼“å­˜æœºåˆ¶

#### å…³é”®ç±»ï¼š`PowerGridDataProcessor`

```python
class PowerGridDataProcessor:
    def __init__(self, normalize: bool = True, cache_dir: str = 'cache')
    
    # ä¸»è¦æ–¹æ³•
    def graph_from_mpc(self, mpc: Dict) -> HeteroData
    def _process_matpower_data(self, mpc: Dict)
    def _create_simplified_hetero_data(self, df_nodes, df_edges, df_edge_features)
```

#### æŠ€æœ¯ç»†èŠ‚

**å¼‚æ„å›¾è®¾è®¡**ï¼š
- ç»Ÿä¸€èŠ‚ç‚¹ç±»å‹ä¸º'bus'ï¼Œå°†ç‰©ç†ç±»å‹(PQ/PV/Slack)è½¬ä¸ºç‹¬çƒ­ç¼–ç ç‰¹å¾
- ç»Ÿä¸€è¾¹å…³ç³»ä¸º('bus', 'connects', 'bus')ï¼Œä¿ç•™ç‰©ç†ç±»å‹ä½œä¸ºè¾¹ç‰¹å¾
- æ”¯æŒGNNæƒé‡å…±äº«å’Œé«˜æ•ˆå­¦ä¹ 

**ç‰¹å¾å·¥ç¨‹**ï¼š
```python
# èŠ‚ç‚¹ç‰¹å¾ (9ç»´åŸºç¡€ + 5ç»´å‘ç”µæœº + 3ç»´ç±»å‹ç‹¬çƒ­ç¼–ç )
èŠ‚ç‚¹ç‰¹å¾ = [Pd, Qd, Gs, Bs, Vm, Va, Vmax, Vmin, degree, 
          Pg, Qg, Pg_max, Pg_min, is_gen,
          type_1, type_2, type_3]

# è¾¹ç‰¹å¾ (9ç»´)
è¾¹ç‰¹å¾ = [r, x, b, |z|, y, rateA, angle_diff, is_transformer, status]
```

#### å‚æ•°é…ç½®
```python
# åœ¨main.pyä¸­é…ç½®
data_config = {
    'normalize': True,           # æ˜¯å¦æ ‡å‡†åŒ–ç‰¹å¾
    'cache_dir': 'cache',       # ç¼“å­˜ç›®å½•
    'use_cache': True,          # æ˜¯å¦ä½¿ç”¨ç¼“å­˜
}
```

### 2.2 å›¾ç¥ç»ç½‘ç»œæ¨¡å— (`code/src/gat.py`)

#### åŠŸèƒ½æ¦‚è¿°
- ç‰©ç†å¢å¼ºçš„GATv2ç¼–ç å™¨
- å¼‚æ„å›¾å¤„ç†
- æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–
- èŠ‚ç‚¹å’Œå›¾çº§åˆ«åµŒå…¥ç”Ÿæˆ

#### å…³é”®ç±»

**PhysicsGATv2Conv**ï¼š
```python
class PhysicsGATv2Conv(GATv2Conv):
    def __init__(self, in_channels, out_channels, heads=8, 
                 temperature=1.0, z_index=3, physics_weight=1.0)
    
    # ç‰©ç†å…ˆéªŒèå…¥
    def physics_enhanced_edge_attr(self, edge_attr: torch.Tensor)
```

**HeteroGraphEncoder**ï¼š
```python
class HeteroGraphEncoder(nn.Module):
    def __init__(self, node_feature_dims, edge_feature_dims, metadata,
                 hidden_channels=64, gnn_layers=3, heads=4, dropout=0.3)
    
    # ä¸»è¦æ–¹æ³•
    def forward(self, data, return_attention_weights=False, return_graph_embedding=False)
    def encode_nodes(self, data)
    def encode_graph(self, data)
```

#### æŠ€æœ¯ç‰¹ç‚¹

**ç‰©ç†å…ˆéªŒèå…¥**ï¼š
```python
# æ ‡å‡†GATv2: Î±_ij = softmax(W_a^T LeakyReLU(W_l[W_r h_i || W_r h_j] + b))
# ç‰©ç†GATv2: Î±_ij = softmax(...... + Ï„/|Z_ij|)
# å…¶ä¸­|Z_ij|æ˜¯çº¿è·¯é˜»æŠ—æ¨¡é•¿ï¼ŒÏ„æ˜¯å¯å­¦ä¹ çš„æ¸©åº¦å‚æ•°
```

**æ³¨æ„åŠ›æƒé‡æå–**ï¼š
- è‡ªåŠ¨æ”¶é›†æ‰€æœ‰GATv2å±‚çš„æ³¨æ„åŠ›æƒé‡
- æŒ‰è¾¹ç±»å‹ç»„ç»‡æ³¨æ„åŠ›ä¿¡æ¯
- æ”¯æŒå¯è§†åŒ–åˆ†æ

#### å‚æ•°é…ç½®
```python
gnn_config = {
    'hidden_channels': 64,      # éšè—å±‚ç»´åº¦
    'gnn_layers': 3,           # GNNå±‚æ•°
    'heads': 4,                # æ³¨æ„åŠ›å¤´æ•°
    'dropout': 0.3,            # Dropoutæ¦‚ç‡
    'output_dim': 64,          # è¾“å‡ºåµŒå…¥ç»´åº¦
    'temperature': 1.0,        # ç‰©ç†å…ˆéªŒæ¸©åº¦å‚æ•°
    'physics_weight': 1.0,     # ç‰©ç†æƒé‡ç³»æ•°
}
```

### 2.3 å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ (`code/src/rl/agent.py`)

#### åŠŸèƒ½æ¦‚è¿°
- PPOç®—æ³•å®ç°
- ä¸¤é˜¶æ®µåŠ¨ä½œé€‰æ‹©
- åŠ¨ä½œæ©ç å¤„ç†
- æ•°å€¼ç¨³å®šæ€§ä¿è¯

#### å…³é”®ç±»

**PPOAgent**ï¼š
```python
class PPOAgent:
    def __init__(self, node_embedding_dim, region_embedding_dim, num_partitions,
                 lr_actor=3e-4, lr_critic=1e-3, gamma=0.99, eps_clip=0.2,
                 k_epochs=4, entropy_coef=0.01, value_coef=0.5)
    
    # ä¸»è¦æ–¹æ³•
    def select_action(self, state, training=True)
    def store_experience(self, state, action, reward, log_prob, value, done)
    def update(self)
```

**ActorNetwork & CriticNetwork**ï¼š
```python
class ActorNetwork(nn.Module):
    # ä¸¤é˜¶æ®µè¾“å‡ºï¼šèŠ‚ç‚¹é€‰æ‹© + åˆ†åŒºé€‰æ‹©
    def forward(self, node_embeddings, region_embeddings, boundary_nodes, action_mask)
    
class CriticNetwork(nn.Module):
    # çŠ¶æ€ä»·å€¼ä¼°è®¡
    def forward(self, node_embeddings, region_embeddings, boundary_nodes)
```

#### æŠ€æœ¯ç‰¹ç‚¹

**ä¸¤é˜¶æ®µåŠ¨ä½œç©ºé—´**ï¼š
1. é˜¶æ®µ1ï¼šä»è¾¹ç•ŒèŠ‚ç‚¹ä¸­é€‰æ‹©è¦ç§»åŠ¨çš„èŠ‚ç‚¹
2. é˜¶æ®µ2ï¼šä¸ºé€‰ä¸­èŠ‚ç‚¹é€‰æ‹©ç›®æ ‡åˆ†åŒº

**æ•°å€¼ç¨³å®šæ€§**ï¼š
```python
# å®‰å…¨çš„æ©ç softmax
def masked_softmax(logits, mask, dim=-1, epsilon=1e-12):
    masked_logits = logits.masked_fill(~mask, -1e9)  # é¿å…-inf
    probs = torch.softmax(masked_logits, dim=dim)
    probs = probs * mask.float()
    probs_sum = probs.sum(dim=dim, keepdim=True).clamp(min=epsilon)
    return probs / probs_sum

# å®‰å…¨çš„å¯¹æ•°æ¦‚ç‡
def safe_log_prob(probs, epsilon=1e-12):
    return torch.log(probs.clamp(min=epsilon))
```

#### å‚æ•°é…ç½®
```python
ppo_config = {
    'lr_actor': 3e-4,          # Actorå­¦ä¹ ç‡
    'lr_critic': 1e-3,         # Criticå­¦ä¹ ç‡  
    'gamma': 0.99,             # æŠ˜æ‰£å› å­
    'eps_clip': 0.2,           # PPOè£å‰ªå‚æ•°
    'k_epochs': 4,             # PPOè®­ç»ƒè½®æ•°
    'entropy_coef': 0.01,      # ç†µç³»æ•°
    'value_coef': 0.5,         # ä»·å€¼æŸå¤±ç³»æ•°
    'max_grad_norm': 0.5,      # æ¢¯åº¦è£å‰ª
}
```

### 2.4 ç¯å¢ƒæ¨¡å— (`code/src/rl/environment.py`)

#### åŠŸèƒ½æ¦‚è¿°
- MDPç¯å¢ƒå®šä¹‰
- çŠ¶æ€è½¬ç§»é€»è¾‘
- ç»ˆæ­¢æ¡ä»¶æ£€æŸ¥
- è§‚å¯Ÿç©ºé—´ç”Ÿæˆ

#### å…³é”®ç±»ï¼š`PowerGridPartitioningEnv`

```python
class PowerGridPartitioningEnv:
    def __init__(self, hetero_data, node_embeddings, num_partitions,
                 reward_weights=None, max_steps=200, device=None)
    
    # ä¸»è¦æ–¹æ³•
    def reset(self, seed=None)
    def step(self, action)
    def _check_termination(self)
    def get_action_mask(self)
```

#### çŠ¶æ€ç©ºé—´è®¾è®¡

```python
observation = {
    'node_embeddings': torch.Tensor,      # èŠ‚ç‚¹åµŒå…¥ [N, D_node]
    'region_embeddings': torch.Tensor,    # åŒºåŸŸåµŒå…¥ [K, D_region]  
    'boundary_nodes': torch.Tensor,       # è¾¹ç•ŒèŠ‚ç‚¹ç´¢å¼• [N_boundary]
    'current_partition': torch.Tensor,    # å½“å‰åˆ†åŒºåˆ†é… [N]
    'partition_sizes': torch.Tensor,      # å„åˆ†åŒºå¤§å° [K]
    'step_count': int,                    # å½“å‰æ­¥æ•°
}
```

#### åŠ¨ä½œç©ºé—´è®¾è®¡

```python
# åŠ¨ä½œè¡¨ç¤ºï¼š(node_idx, target_partition)
action = (int, int)  # (è¦ç§»åŠ¨çš„èŠ‚ç‚¹, ç›®æ ‡åˆ†åŒº)

# åŠ¨ä½œæ©ç ï¼š[N, K] å¸ƒå°”å¼ é‡
action_mask[i, j] = True   # èŠ‚ç‚¹iå¯ä»¥ç§»åŠ¨åˆ°åˆ†åŒºj+1
```

#### å‚æ•°é…ç½®
```python
env_config = {
    'num_partitions': 4,       # ç›®æ ‡åˆ†åŒºæ•°
    'max_steps': 200,          # æœ€å¤§æ­¥æ•°
    'reward_weights': {        # å¥–åŠ±æƒé‡
        'load_balance': 0.4,
        'electrical_decoupling': 0.4,
        'power_balance': 0.2
    },
    'early_termination': True, # æ—©åœæœºåˆ¶
    'convergence_window': 10,  # æ”¶æ•›çª—å£
    'convergence_threshold': 0.01, # æ”¶æ•›é˜ˆå€¼
}
```

### 2.5 å¥–åŠ±å‡½æ•° (`code/src/rl/reward.py`)

#### åŠŸèƒ½æ¦‚è¿°
- å¤šç›®æ ‡å¥–åŠ±è®¾è®¡
- è´Ÿè½½å¹³è¡¡è¯„ä¼°
- ç”µæ°”è§£è€¦è¯„ä¼°
- åŠŸç‡å¹³è¡¡è¯„ä¼°

#### å…³é”®ç±»ï¼š`RewardFunction`

```python
class RewardFunction:
    def __init__(self, hetero_data, reward_weights=None, device=None)
    
    def compute_reward(self, current_partition, boundary_nodes, action,
                      return_components=False)
    
    # å­å¥–åŠ±è®¡ç®—
    def _compute_load_balance_reward(self, current_partition)
    def _compute_electrical_decoupling_reward(self, current_partition)  
    def _compute_power_balance_reward(self, current_partition)
```

#### å¥–åŠ±è®¾è®¡

**è´Ÿè½½å¹³è¡¡å¥–åŠ±**ï¼š
```python
# åŸºäºå˜å¼‚ç³»æ•°
load_cv = std(partition_loads) / mean(partition_loads)
load_balance_reward = -load_cv  # è¶Šå°å¥–åŠ±è¶Šé«˜
```

**ç”µæ°”è§£è€¦å¥–åŠ±**ï¼š
```python
# åŸºäºè·¨åˆ†åŒºçº¿è·¯æ•°é‡
inter_partition_lines = count_inter_partition_connections()
coupling_reward = -inter_partition_lines / total_lines
```

**åŠŸç‡å¹³è¡¡å¥–åŠ±**ï¼š
```python
# å„åˆ†åŒºåŠŸç‡ä¸å¹³è¡¡åº¦
power_imbalance = |generation - load| for each partition
balance_reward = -mean(power_imbalance)
```

#### å‚æ•°é…ç½®
```python
reward_config = {
    'weights': {
        'load_balance': 0.4,           # è´Ÿè½½å¹³è¡¡æƒé‡
        'electrical_decoupling': 0.4,  # ç”µæ°”è§£è€¦æƒé‡
        'power_balance': 0.2,          # åŠŸç‡å¹³è¡¡æƒé‡
    },
    'normalization': True,             # æ˜¯å¦å½’ä¸€åŒ–å¥–åŠ±
    'debug_mode': False,               # è°ƒè¯•æ¨¡å¼
}
```

## 3. å‚æ•°é…ç½®æŒ‡å—

### 3.1 é…ç½®æ–‡ä»¶ç»“æ„

ä¸»é…ç½®æ–‡ä»¶ `config.yaml` çš„ç»“æ„ï¼š

```yaml
# ç¯å¢ƒé…ç½®
environment:
  case_name: "ieee30"
  num_partitions: 4
  max_steps: 200
  reward_weights:
    load_balance: 0.4
    electrical_decoupling: 0.4
    power_balance: 0.2

# æ¨¡å‹é…ç½®  
model:
  hidden_channels: 64
  gnn_layers: 3
  heads: 4
  dropout: 0.3
  output_dim: 64

# è®­ç»ƒé…ç½®
training:
  episodes: 1000
  learning_rate: 0.0003
  batch_size: 32
  update_interval: 10
  gamma: 0.99
  eps_clip: 0.2
  entropy_coef: 0.01

# ç³»ç»Ÿé…ç½®
system:
  device: "auto"
  num_workers: 4
  seed: 42
  use_tensorboard: true
  save_interval: 100
```

### 3.2 å…³é”®å‚æ•°è°ƒä¼˜

#### å­¦ä¹ ç‡è°ƒæ•´

```python
# ä¸åŒç½‘ç»œç»„ä»¶çš„å­¦ä¹ ç‡
lr_config = {
    'lr_actor': 3e-4,      # Actorç½‘ç»œå­¦ä¹ ç‡
    'lr_critic': 1e-3,     # Criticç½‘ç»œå­¦ä¹ ç‡ï¼ˆé€šå¸¸æ›´å¤§ï¼‰
    'lr_scheduler': {      # å­¦ä¹ ç‡è°ƒåº¦
        'type': 'cosine',
        'T_max': 1000,
        'eta_min': 1e-5
    }
}
```

#### ç½‘ç»œæ¶æ„è°ƒæ•´

```python
# GNNæ¶æ„å‚æ•°
gnn_params = {
    'hidden_channels': [32, 64, 128],  # å¯é€‰ç»´åº¦
    'gnn_layers': [2, 3, 4, 5],       # æ¨è3-4å±‚
    'heads': [2, 4, 8],               # æ³¨æ„åŠ›å¤´æ•°
    'dropout': [0.1, 0.3, 0.5],      # Dropoutç‡
}

# é€‰æ‹©åŸåˆ™ï¼š
# - å°ç½‘ç»œ(IEEE14/30): hidden_channels=32, layers=2-3
# - ä¸­ç­‰ç½‘ç»œ(IEEE57): hidden_channels=64, layers=3-4  
# - å¤§ç½‘ç»œ(IEEE118+): hidden_channels=128, layers=4-5
```

#### PPOè¶…å‚æ•°

```python
# PPOå…³é”®å‚æ•°è°ƒä¼˜
ppo_params = {
    'gamma': [0.95, 0.99, 0.995],     # æŠ˜æ‰£å› å­
    'eps_clip': [0.1, 0.2, 0.3],      # è£å‰ªå‚æ•°
    'k_epochs': [3, 4, 5, 8],         # æ›´æ–°è½®æ•°
    'entropy_coef': [0.001, 0.01, 0.1], # ç†µç³»æ•°
}

# è°ƒä¼˜å»ºè®®ï¼š
# - gamma: é•¿æœŸä»»åŠ¡ç”¨0.99ï¼ŒçŸ­æœŸä»»åŠ¡ç”¨0.95
# - eps_clip: å¤æ‚ç¯å¢ƒç”¨0.1-0.2ï¼Œç®€å•ç¯å¢ƒç”¨0.2-0.3
# - entropy_coef: åˆæœŸç”¨0.01-0.1ï¼ŒåæœŸå¯é™ä½
```

### 3.3 å¤šç›®æ ‡æƒé‡è°ƒæ•´

```python
# å¥–åŠ±æƒé‡çš„è°ƒæ•´ç­–ç•¥
reward_weight_strategies = {
    # å¹³è¡¡ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰
    'balanced': {
        'load_balance': 0.4,
        'electrical_decoupling': 0.4, 
        'power_balance': 0.2
    },
    
    # è´Ÿè½½ä¼˜å…ˆç­–ç•¥
    'load_focused': {
        'load_balance': 0.6,
        'electrical_decoupling': 0.3,
        'power_balance': 0.1
    },
    
    # æ‹“æ‰‘ä¼˜å…ˆç­–ç•¥
    'topology_focused': {
        'load_balance': 0.2,
        'electrical_decoupling': 0.6,
        'power_balance': 0.2
    },
    
    # åŠŸç‡å¹³è¡¡ä¼˜å…ˆç­–ç•¥
    'power_focused': {
        'load_balance': 0.3,
        'electrical_decoupling': 0.3,
        'power_balance': 0.4
    }
}
```

## 4. è®­ç»ƒæµç¨‹è¯¦è§£

### 4.1 è®­ç»ƒç®¡é“

```python
# å®Œæ•´è®­ç»ƒæµç¨‹
def training_pipeline():
    # 1. ç¯å¢ƒåˆå§‹åŒ–
    env = setup_environment(config)
    
    # 2. æ¨¡å‹åˆ›å»º
    encoder = create_hetero_graph_encoder(data, **model_config)
    agent = PPOAgent(**agent_config)
    
    # 3. è®­ç»ƒå¾ªç¯
    for episode in range(num_episodes):
        # ç¯å¢ƒé‡ç½®
        obs, info = env.reset()
        done = False
        episode_reward = 0
        
        # å•å›åˆäº¤äº’
        while not done:
            # æ™ºèƒ½ä½“å†³ç­–
            action, log_prob, value = agent.select_action(obs)
            
            # ç¯å¢ƒæ­¥è¿›
            next_obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
            
            # ç»éªŒå­˜å‚¨
            agent.store_experience(obs, action, reward, log_prob, value, done)
            
            obs = next_obs
            episode_reward += reward
        
        # PPOæ›´æ–°
        if episode % update_interval == 0:
            agent.update()
        
        # æ—¥å¿—è®°å½•
        logger.log_episode(episode, episode_reward, info)
    
    # 4. ç»“æœè¯„ä¼°
    evaluate_and_compare(env, agent)
```

### 4.2 è®­ç»ƒæ¨¡å¼å®ç°

#### Quickæ¨¡å¼ï¼ˆå¿«é€ŸéªŒè¯ï¼‰
```python
quick_config = {
    'episodes': 100,
    'max_steps': 50,
    'hidden_channels': 32,
    'gnn_layers': 2,
    'update_interval': 5,
    'save_interval': 50,
}
```

#### Standardæ¨¡å¼ï¼ˆæ ‡å‡†è®­ç»ƒï¼‰  
```python
standard_config = {
    'episodes': 1000,
    'max_steps': 200,
    'hidden_channels': 64,
    'gnn_layers': 3,
    'update_interval': 10,
    'save_interval': 100,
}
```

#### Fullæ¨¡å¼ï¼ˆå®Œæ•´è®­ç»ƒï¼‰
```python
full_config = {
    'episodes': 5000,
    'max_steps': 300,
    'hidden_channels': 128,
    'gnn_layers': 4,
    'update_interval': 20,
    'save_interval': 200,
    'curriculum_learning': True,
    'early_stopping': True,
}
```

#### Parallelæ¨¡å¼ï¼ˆå¹¶è¡Œè®­ç»ƒï¼‰
```python
parallel_config = {
    'num_workers': 8,
    'episodes_per_worker': 125,  # æ€»episodes = 8 * 125 = 1000
    'sync_interval': 50,
    'shared_memory': True,
}
```

### 4.3 è®­ç»ƒç›‘æ§å’Œè°ƒè¯•

#### TensorBoardé›†æˆ
```python
# æ—¥å¿—è®°å½•ç±»åˆ«
tensorboard_logs = {
    'scalars': {
        'reward/episode_reward',
        'reward/mean_reward',
        'loss/actor_loss',
        'loss/critic_loss',
        'metrics/entropy',
        'metrics/load_cv',
        'metrics/coupling_degree',
    },
    'histograms': {
        'gradients/actor_gradients',
        'gradients/critic_gradients', 
        'weights/actor_weights',
        'weights/critic_weights',
    },
    'images': {
        'partition/current_partition',
        'attention/attention_weights',
    }
}
```

#### æ£€æŸ¥ç‚¹ä¿å­˜
```python
checkpoint_config = {
    'save_best': True,          # ä¿å­˜æœ€ä½³æ¨¡å‹
    'save_latest': True,        # ä¿å­˜æœ€æ–°æ¨¡å‹
    'save_interval': 100,       # å®šæœŸä¿å­˜é—´éš”
    'max_checkpoints': 5,       # æœ€å¤§ä¿å­˜æ•°é‡
    'resume_training': True,    # æ”¯æŒæ¢å¤è®­ç»ƒ
}
```

## 5. æ€§èƒ½ä¼˜åŒ–

### 5.1 è®¡ç®—ä¼˜åŒ–

#### GPUå†…å­˜ä¼˜åŒ–
```python
# å†…å­˜ä¼˜åŒ–ç­–ç•¥
memory_optimization = {
    'gradient_checkpointing': True,    # æ¢¯åº¦æ£€æŸ¥ç‚¹
    'mixed_precision': True,           # æ··åˆç²¾åº¦è®­ç»ƒ
    'batch_size_scaling': 'auto',      # è‡ªåŠ¨æ‰¹é‡å¤§å°
    'cache_management': 'smart',       # æ™ºèƒ½ç¼“å­˜ç®¡ç†
}

# å®ç°ç¤ºä¾‹
def optimize_gpu_memory():
    # å¯ç”¨æ··åˆç²¾åº¦
    scaler = torch.cuda.amp.GradScaler()
    
    # åŠ¨æ€æ‰¹é‡å¤§å°è°ƒæ•´
    try:
        batch_size = initial_batch_size
        while True:
            try:
                # å°è¯•å½“å‰æ‰¹é‡å¤§å°
                train_batch(batch_size)
                break
            except torch.cuda.OutOfMemoryError:
                batch_size //= 2
                torch.cuda.empty_cache()
    except:
        raise RuntimeError("GPUå†…å­˜ä¸è¶³")
```

#### å¹¶è¡Œè®¡ç®—ä¼˜åŒ–
```python
# å¤šè¿›ç¨‹è®­ç»ƒé…ç½®
multiprocessing_config = {
    'method': 'spawn',              # è¿›ç¨‹å¯åŠ¨æ–¹æ³•
    'shared_model': True,           # å…±äº«æ¨¡å‹æƒé‡
    'async_update': True,           # å¼‚æ­¥å‚æ•°æ›´æ–°
    'gradient_averaging': True,     # æ¢¯åº¦å¹³å‡
}

# æ•°æ®å¹¶è¡Œ
def setup_data_parallel():
    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)
        print(f"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPUè¿›è¡Œæ•°æ®å¹¶è¡Œ")
```

### 5.2 ç®—æ³•ä¼˜åŒ–

#### ç»éªŒå›æ”¾ä¼˜åŒ–
```python
# ä¼˜å…ˆç»éªŒå›æ”¾
class PrioritizedExperienceReplay:
    def __init__(self, capacity, alpha=0.6, beta=0.4):
        self.capacity = capacity
        self.alpha = alpha  # ä¼˜å…ˆçº§æŒ‡æ•°
        self.beta = beta    # é‡è¦æ€§é‡‡æ ·æŒ‡æ•°
        
    def add(self, state, action, reward, next_state, done, td_error):
        priority = (abs(td_error) + 1e-6) ** self.alpha
        # å­˜å‚¨ç»éªŒå’Œä¼˜å…ˆçº§
        
    def sample(self, batch_size):
        # åŸºäºä¼˜å…ˆçº§é‡‡æ ·
        pass
```

#### è¯¾ç¨‹å­¦ä¹ 
```python
# è¯¾ç¨‹å­¦ä¹ ç­–ç•¥
curriculum_config = {
    'stages': [
        {'episodes': 200, 'case': 'ieee14', 'partitions': 3},
        {'episodes': 300, 'case': 'ieee30', 'partitions': 4}, 
        {'episodes': 500, 'case': 'ieee57', 'partitions': 5},
    ],
    'transition_criterion': 'reward_threshold',
    'reward_thresholds': [-0.5, -0.3, -0.1],
}
```

### 5.3 ç³»ç»Ÿä¼˜åŒ–

#### ç¼“å­˜ç­–ç•¥
```python
# å¤šçº§ç¼“å­˜ç³»ç»Ÿ
cache_config = {
    'levels': {
        'memory': {
            'size': '2GB',
            'eviction': 'LRU',
        },
        'disk': {
            'size': '10GB', 
            'format': 'compressed',
        },
        'network': {
            'enabled': False,
            'backend': 'redis',
        }
    }
}
```

#### I/Oä¼˜åŒ–
```python
# å¼‚æ­¥I/Oé…ç½®
async_io_config = {
    'data_loading': {
        'num_workers': 4,
        'prefetch_factor': 2,
        'persistent_workers': True,
    },
    'logging': {
        'buffer_size': 1024,
        'flush_interval': 10,
        'async_write': True,
    }
}
```

## 6. æ‰©å±•å¼€å‘

### 6.1 æ·»åŠ æ–°çš„åŸºçº¿ç®—æ³•

```python
# 1. åˆ›å»ºæ–°çš„åˆ†åŒºå™¨ç±»
class MyCustomPartitioner(BasePartitioner):
    def __init__(self, seed=42, **kwargs):
        super().__init__(seed)
        self.custom_params = kwargs
    
    def partition(self, env):
        """å®ç°è‡ªå®šä¹‰åˆ†åŒºç®—æ³•"""
        # è·å–ç½‘ç»œä¿¡æ¯
        adjacency_matrix = self._build_adjacency(env)
        node_features = self._extract_features(env)
        
        # å®ç°åˆ†åŒºé€»è¾‘
        labels = self._my_partition_algorithm(
            adjacency_matrix, node_features, env.num_partitions
        )
        
        return labels + 1  # è½¬æ¢ä¸º1-basedæ ‡ç­¾

# 2. æ³¨å†Œåˆ°åŸºçº¿ç³»ç»Ÿ
def register_custom_partitioner():
    from code.baseline import baseline_registry
    baseline_registry['my_method'] = MyCustomPartitioner

# 3. åœ¨æ¯”è¾ƒä¸­ä½¿ç”¨
comparison_methods = ['spectral', 'kmeans', 'random', 'my_method']
```

### 6.2 è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°

```python
# æ‰©å±•å¥–åŠ±å‡½æ•°
class ExtendedRewardFunction(RewardFunction):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.custom_weights = kwargs.get('custom_weights', {})
    
    def compute_reward(self, current_partition, boundary_nodes, action,
                      return_components=False):
        # è°ƒç”¨åŸºç¡€å¥–åŠ±
        base_reward = super().compute_reward(
            current_partition, boundary_nodes, action, return_components=True
        )
        
        # æ·»åŠ è‡ªå®šä¹‰ç»„ä»¶
        custom_components = self._compute_custom_rewards(current_partition)
        
        # åˆå¹¶å¥–åŠ±
        total_reward = self._combine_rewards(base_reward, custom_components)
        
        return total_reward if not return_components else (total_reward, base_reward, custom_components)
    
    def _compute_custom_rewards(self, partition):
        """å®ç°è‡ªå®šä¹‰å¥–åŠ±ç»„ä»¶"""
        rewards = {}
        
        # ç¤ºä¾‹ï¼šè¿é€šæ€§å¥–åŠ±
        rewards['connectivity'] = self._compute_connectivity_reward(partition)
        
        # ç¤ºä¾‹ï¼šç´§å¯†æ€§å¥–åŠ±
        rewards['compactness'] = self._compute_compactness_reward(partition)
        
        return rewards
```

### 6.3 ç½‘ç»œæ¶æ„æ‰©å±•

```python
# è‡ªå®šä¹‰GNNå±‚
class CustomGNNLayer(nn.Module):
    def __init__(self, in_channels, out_channels, **kwargs):
        super().__init__()
        # å®ç°è‡ªå®šä¹‰å›¾å·ç§¯å±‚
        
    def forward(self, x, edge_index, edge_attr=None):
        # è‡ªå®šä¹‰å‰å‘ä¼ æ’­é€»è¾‘
        pass

# é›†æˆåˆ°ç¼–ç å™¨
class ExtendedHeteroGraphEncoder(HeteroGraphEncoder):
    def __init__(self, *args, custom_layer_type='default', **kwargs):
        super().__init__(*args, **kwargs)
        
        if custom_layer_type == 'custom':
            self._replace_gnn_layers()
    
    def _replace_gnn_layers(self):
        """æ›¿æ¢é»˜è®¤GNNå±‚ä¸ºè‡ªå®šä¹‰å±‚"""
        # å®ç°å±‚æ›¿æ¢é€»è¾‘
        pass
```

### 6.4 ç¯å¢ƒæ‰©å±•

```python
# è‡ªå®šä¹‰ç¯å¢ƒå˜ä½“
class MultiObjectivePartitionEnv(PowerGridPartitioningEnv):
    """å¤šç›®æ ‡åˆ†åŒºç¯å¢ƒ"""
    
    def __init__(self, *args, objectives=['load', 'topology', 'stability'], **kwargs):
        super().__init__(*args, **kwargs)
        self.objectives = objectives
        self.pareto_front = []
    
    def step(self, action):
        obs, reward, terminated, truncated, info = super().step(action)
        
        # è®¡ç®—å¤šç›®æ ‡æŒ‡æ ‡
        objective_values = self._compute_objectives()
        info['objectives'] = objective_values
        
        # æ›´æ–°å¸•ç´¯æ‰˜å‰æ²¿
        self._update_pareto_front(objective_values)
        
        return obs, reward, terminated, truncated, info
    
    def _compute_objectives(self):
        """è®¡ç®—å¤šä¸ªç›®æ ‡å‡½æ•°å€¼"""
        objectives = {}
        for obj in self.objectives:
            objectives[obj] = getattr(self, f'_compute_{obj}_objective')()
        return objectives
```

## 7. è°ƒè¯•å’Œæ•…éšœæ’é™¤

### 7.1 å¸¸è§é”™è¯¯è¯Šæ–­

#### æ•°å€¼ä¸ç¨³å®šé—®é¢˜
```python
# æ£€æŸ¥ç‚¹åˆ—è¡¨
numerical_stability_checklist = {
    'gradients': {
        'nan_check': 'torch.isnan(gradients).any()',
        'inf_check': 'torch.isinf(gradients).any()',
        'magnitude_check': 'gradients.norm() > 1000',
    },
    'losses': {
        'nan_loss': 'torch.isnan(loss)',
        'negative_loss': 'loss < 0 (for non-adversarial)',
        'exploding_loss': 'loss > 1e6',
    },
    'probabilities': {
        'sum_check': 'probs.sum() != 1.0',
        'negative_prob': '(probs < 0).any()',
        'zero_prob': '(probs == 0).all()',
    }
}

# è‡ªåŠ¨è¯Šæ–­å‡½æ•°
def diagnose_numerical_issues(model, loss, gradients, probs):
    issues = []
    
    # æ£€æŸ¥æ¢¯åº¦
    if torch.isnan(gradients).any():
        issues.append("NaNæ¢¯åº¦æ£€æµ‹")
    
    # æ£€æŸ¥æŸå¤±
    if torch.isnan(loss):
        issues.append("NaNæŸå¤±æ£€æµ‹")
        
    # æ£€æŸ¥æ¦‚ç‡
    if (probs < 0).any() or not torch.allclose(probs.sum(), torch.tensor(1.0)):
        issues.append("æ— æ•ˆæ¦‚ç‡åˆ†å¸ƒ")
    
    return issues
```

#### å†…å­˜æ³„æ¼è¯Šæ–­
```python
# å†…å­˜ç›‘æ§
import psutil
import gc

class MemoryMonitor:
    def __init__(self):
        self.initial_memory = psutil.virtual_memory().used
        
    def check_memory_usage(self, step):
        current_memory = psutil.virtual_memory().used
        memory_increase = current_memory - self.initial_memory
        
        if memory_increase > 1e9:  # 1GB
            print(f"æ­¥éª¤ {step}: å†…å­˜ä½¿ç”¨å¢åŠ  {memory_increase/1e6:.1f}MB")
            self._suggest_cleanup()
    
    def _suggest_cleanup(self):
        gc.collect()
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
```

### 7.2 æ€§èƒ½åˆ†æå·¥å…·

#### è®­ç»ƒæ€§èƒ½åˆ†æ
```python
# æ€§èƒ½åˆ†æå™¨
class TrainingProfiler:
    def __init__(self):
        self.timers = {}
        self.counters = {}
    
    def start_timer(self, name):
        self.timers[name] = time.time()
    
    def end_timer(self, name):
        if name in self.timers:
            elapsed = time.time() - self.timers[name]
            self.counters[name] = self.counters.get(name, []) + [elapsed]
    
    def report(self):
        for name, times in self.counters.items():
            avg_time = sum(times) / len(times)
            print(f"{name}: å¹³å‡ {avg_time:.4f}s, æ€»è®¡ {sum(times):.2f}s")

# ä½¿ç”¨ç¤ºä¾‹
profiler = TrainingProfiler()

# åœ¨è®­ç»ƒå¾ªç¯ä¸­
profiler.start_timer('forward_pass')
output = model(input)
profiler.end_timer('forward_pass')

profiler.start_timer('backward_pass') 
loss.backward()
profiler.end_timer('backward_pass')
```

### 7.3 è°ƒè¯•é…ç½®

```python
# è°ƒè¯•æ¨¡å¼é…ç½®
debug_config = {
    'verbose': True,               # è¯¦ç»†è¾“å‡º
    'check_gradients': True,       # æ¢¯åº¦æ£€æŸ¥
    'profile_memory': True,        # å†…å­˜åˆ†æ
    'save_intermediate': True,     # ä¿å­˜ä¸­é—´ç»“æœ
    'visualize_attention': True,   # å¯è§†åŒ–æ³¨æ„åŠ›
    'log_rewards': True,          # è®°å½•å¥–åŠ±ç»„ä»¶
}

# è°ƒè¯•è¾“å‡ºç¤ºä¾‹
def debug_training_step(episode, step, reward_components, attention_weights):
    if debug_config['verbose']:
        print(f"å›åˆ {episode}, æ­¥éª¤ {step}:")
        print(f"  å¥–åŠ±ç»„ä»¶: {reward_components}")
        print(f"  æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {[w.shape for w in attention_weights]}")
        
    if debug_config['save_intermediate']:
        torch.save({
            'episode': episode,
            'step': step,
            'reward_components': reward_components,
            'attention_weights': attention_weights,
        }, f'debug/step_{episode}_{step}.pt')
```

---

æœ¬æ–‡æ¡£æ¶µç›–äº†ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿçš„ä¸»è¦æŠ€æœ¯ç»†èŠ‚ã€‚å¯¹äºç‰¹å®šé—®é¢˜æˆ–é«˜çº§å®šåˆ¶éœ€æ±‚ï¼Œå»ºè®®æŸ¥é˜…æºä»£ç ä¸­çš„è¯¦ç»†æ³¨é‡Šæˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚ 