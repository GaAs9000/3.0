import numpy as np
import torch
from sklearn.cluster import SpectralClustering, KMeans
from sklearn.metrics import normalized_mutual_info_score
from typing import Dict, List, Optional
import pandas as pd
import gc
import random
import os

# Import types that will be defined in other modules
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from env import PowerGridPartitionEnv

def set_baseline_seed(seed: int = 42):
    """ä¸ºåŸºçº¿æ–¹æ³•è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

class BaselinePartitioner:
    """
    åŸºçº¿åˆ†åŒºæ–¹æ³•ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    """
    
    def __init__(self, method: str = 'spectral', seed: int = 42):
        self.method = method
        self.seed = seed
    
    def partition(self, env: 'PowerGridPartitionEnv') -> np.ndarray:
        """æ‰§è¡Œåˆ†åŒº"""
        # æ¯æ¬¡æ‰§è¡Œå‰è®¾ç½®éšæœºç§å­
        set_baseline_seed(self.seed)
        
        if self.method == 'spectral':
            return self._spectral_partition(env)
        elif self.method == 'kmeans':
            return self._kmeans_partition(env)
        elif self.method == 'random':
            return self._random_partition(env)
        else:
            raise ValueError(f"Unknown method: {self.method}")
    
    def _spectral_partition(self, env: 'PowerGridPartitionEnv') -> np.ndarray:
        """è°±èšç±»åˆ†åŒº"""
        # å†æ¬¡ç¡®ä¿ç§å­è®¾ç½®
        set_baseline_seed(self.seed)
        
        # æ„å»ºé‚»æ¥çŸ©é˜µ
        adj_matrix = np.zeros((env.N, env.N))
        edge_array = env.edge_index.cpu().numpy()
        
        for i in range(edge_array.shape[1]):
            u, v = edge_array[0, i], edge_array[1, i]
            # ä½¿ç”¨å¯¼çº³ä½œä¸ºæƒé‡
            weight = env.admittance[i].item()
            
            # æ£€æŸ¥æƒé‡æ˜¯å¦ä¸ºNaNæˆ–æ— ç©·å¤§
            if np.isnan(weight) or np.isinf(weight):
                weight = 1e-10  # ä½¿ç”¨æå°çš„æ­£å€¼ä»£æ›¿
            
            adj_matrix[u, v] = weight
            adj_matrix[v, u] = weight
        
        # å…¨é¢çš„NaNå’Œinfå¤„ç†
        adj_matrix = np.nan_to_num(adj_matrix, nan=1e-10, posinf=1.0, neginf=0.0)
        
        # ç¡®ä¿çŸ©é˜µæ˜¯å¯¹ç§°çš„
        adj_matrix = (adj_matrix + adj_matrix.T) / 2
        
        # ç¡®ä¿æ‰€æœ‰å€¼ä¸ºéè´Ÿï¼ˆè°±èšç±»è¦æ±‚éè´Ÿæƒé‡ï¼‰
        adj_matrix = np.abs(adj_matrix)
        
        # ç¡®ä¿å¯¹è§’çº¿ä¸Šè‡³å°‘æœ‰ä¸€ä¸ªå°çš„æ­£å€¼ï¼ˆé¿å…å¥‡å¼‚çŸ©é˜µï¼‰
        np.fill_diagonal(adj_matrix, np.maximum(adj_matrix.diagonal(), 1e-10))
        
        # æœ€ç»ˆéªŒè¯çŸ©é˜µçš„æœ‰æ•ˆæ€§
        if np.any(np.isnan(adj_matrix)) or np.any(np.isinf(adj_matrix)):
            print("âš ï¸ è­¦å‘Šï¼šé‚»æ¥çŸ©é˜µä»æœ‰å¼‚å¸¸å€¼ï¼Œä½¿ç”¨å•ä½çŸ©é˜µä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ...")
            adj_matrix = np.eye(env.N) * 1e-10 + np.ones((env.N, env.N)) * 1e-12
        
        # è°±èšç±»
        clustering = SpectralClustering(
            n_clusters=env.K,
            affinity='precomputed',
            n_init=10,
            random_state=self.seed,  # ä½¿ç”¨å®ä¾‹çš„ç§å­
            assign_labels='discretize'  # ä½¿ç”¨æ›´ç¨³å®šçš„æ ‡ç­¾åˆ†é…æ–¹æ³•
        )
        
        labels = clustering.fit_predict(adj_matrix)
        
        return labels + 1  # è½¬æ¢ä¸º1-based
    
    def _kmeans_partition(self, env: 'PowerGridPartitionEnv') -> np.ndarray:
        """K-meansåˆ†åŒºï¼ˆåŸºäºèŠ‚ç‚¹åµŒå…¥ï¼‰"""
        import gc
        import os
        
        # å†æ¬¡ç¡®ä¿ç§å­è®¾ç½®
        set_baseline_seed(self.seed)
        
        # å¼ºåˆ¶è®¾ç½®å•çº¿ç¨‹ç¯å¢ƒå˜é‡ï¼Œé¿å…å¤šçº¿ç¨‹å†²çª
        os.environ['OMP_NUM_THREADS'] = '1'
        os.environ['MKL_NUM_THREADS'] = '1'
        os.environ['OPENBLAS_NUM_THREADS'] = '1'
        
        try:
            # ç¡®ä¿ä½¿ç”¨CPUç‰ˆæœ¬çš„åµŒå…¥ï¼Œé¿å…CUDAå†…å­˜é—®é¢˜
            embeddings = env.embeddings.detach().cpu().numpy().copy()
            
            # æ£€æŸ¥å’Œæ¸…ç†æ•°æ®
            if np.any(np.isnan(embeddings)) or np.any(np.isinf(embeddings)):
                print("âš ï¸ è­¦å‘Šï¼šåµŒå…¥ä¸­å­˜åœ¨å¼‚å¸¸å€¼ï¼Œè¿›è¡Œæ¸…ç†...")
                embeddings = np.nan_to_num(embeddings, nan=0.0, posinf=1.0, neginf=-1.0)
            
            # ç®€åŒ–çš„K-meanså®ç°ï¼Œé¿å…æ®µé”™è¯¯
            from sklearn.cluster import MiniBatchKMeans
            
            # ä½¿ç”¨MiniBatchKMeansï¼Œå®ƒæ›´ç¨³å®šä¸”å†…å­˜å‹å¥½
            kmeans = MiniBatchKMeans(
                n_clusters=env.K,
                n_init=3,
                max_iter=50,
                random_state=self.seed,  # ä½¿ç”¨å®ä¾‹çš„ç§å­
                batch_size=min(100, len(embeddings))
            )
            
            labels = kmeans.fit_predict(embeddings)
            
            # æ¸…ç†å†…å­˜
            del embeddings, kmeans
            gc.collect()
            
            return labels + 1
            
        except Exception as e:
            print(f"âš ï¸ K-meansèšç±»å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨éšæœºåˆ†åŒº...")
            # é™çº§åˆ°éšæœºåˆ†åŒº
            return self._random_partition(env)
    
    def _random_partition(self, env: 'PowerGridPartitionEnv') -> np.ndarray:
        """éšæœºåˆ†åŒº"""
        # ç¡®ä¿ä½¿ç”¨å›ºå®šç§å­
        set_baseline_seed(self.seed)
        labels = np.random.randint(1, env.K + 1, size=env.N)
        return labels


def evaluate_partition_method(env: 'PowerGridPartitionEnv', partition: np.ndarray) -> Dict[str, float]:
    """
    è¯„ä¼°åˆ†åŒºæ–¹æ¡ˆ
    
    å‚æ•°:
        env: ç¯å¢ƒå®ä¾‹
        partition: åˆ†åŒºç»“æœ
        
    è¿”å›:
        è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    # åº”ç”¨åˆ†åŒº
    env.z = torch.tensor(partition, dtype=torch.long, device=env.device)
    env._update_state()
    
    # è·å–æŒ‡æ ‡
    metrics = env._compute_metrics()
    
    return {
        'load_cv': metrics.load_cv,
        'load_gini': metrics.load_gini,
        'total_coupling': metrics.total_coupling,
        'inter_region_lines': metrics.inter_region_lines,
        'connectivity': metrics.connectivity,
        'power_balance': metrics.power_balance,
        'modularity': metrics.modularity
    }


def compare_methods(env: 'PowerGridPartitionEnv', agent, seed: int = 42) -> pd.DataFrame:
    """
    æ¯”è¾ƒä¸åŒåˆ†åŒºæ–¹æ³•
    """
    import gc
    import torch
    
    # åœ¨å¯¹æ¯”å¼€å§‹å‰è®¾ç½®å…¨å±€éšæœºç§å­
    set_baseline_seed(seed)
    
    results = []
    
    try:
        # 1. RLæ–¹æ³•
        print("\nğŸ¤– è¯„ä¼°RLæ–¹æ³•...")
        env.reset()
        
        # ä½¿ç”¨è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“è¿›è¡Œåˆ†åŒº
        state = env.get_state()
        done = False
        
        while not done:
            valid_actions = env.get_valid_actions()
            if not valid_actions:
                break
            
            action_value = agent.select_action(state, valid_actions, training=False)
            if action_value is None:
                break
            
            action, _ = action_value
            state, _, done, _ = env.step(action)
        
        rl_metrics = evaluate_partition_method(env, env.z.cpu().numpy())
        rl_metrics['method'] = 'RL (PPO)'
        results.append(rl_metrics)
        
        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        print(f"âš ï¸ RLæ–¹æ³•è¯„ä¼°å¤±è´¥: {str(e)}")
        results.append({'method': 'RL (PPO)', 'load_cv': 999, 'total_coupling': 999, 
                       'connectivity': 0, 'modularity': 0})

    try:
        # 2. è°±èšç±»
        print("ğŸ“Š è¯„ä¼°è°±èšç±»...")
        spectral = BaselinePartitioner('spectral', seed=seed)
        spectral_partition = spectral.partition(env)
        spectral_metrics = evaluate_partition_method(env, spectral_partition)
        spectral_metrics['method'] = 'Spectral Clustering'
        results.append(spectral_metrics)
        gc.collect()

    except Exception as e:
        print(f"âš ï¸ è°±èšç±»è¯„ä¼°å¤±è´¥: {str(e)}")
        results.append({'method': 'Spectral Clustering', 'load_cv': 999, 'total_coupling': 999,
                       'connectivity': 0, 'modularity': 0})

    try:
        # 3. K-means
        print("ğŸ“Š è¯„ä¼°K-means...")
        kmeans = BaselinePartitioner('kmeans', seed=seed)
        kmeans_partition = kmeans.partition(env)
        kmeans_metrics = evaluate_partition_method(env, kmeans_partition)
        kmeans_metrics['method'] = 'K-means'
        results.append(kmeans_metrics)
        gc.collect()

    except Exception as e:
        print(f"âš ï¸ K-meansè¯„ä¼°å¤±è´¥: {str(e)}")
        results.append({'method': 'K-means', 'load_cv': 999, 'total_coupling': 999,
                       'connectivity': 0, 'modularity': 0})

    try:
        # 4. éšæœºåˆ†åŒº
        print("ğŸ² è¯„ä¼°éšæœºåˆ†åŒº...")
        random_partitioner = BaselinePartitioner('random', seed=seed)
        random_partition = random_partitioner.partition(env)
        random_metrics = evaluate_partition_method(env, random_partition)
        random_metrics['method'] = 'Random'
        results.append(random_metrics)
        gc.collect()

    except Exception as e:
        print(f"âš ï¸ éšæœºåˆ†åŒºè¯„ä¼°å¤±è´¥: {str(e)}")
        results.append({'method': 'Random', 'load_cv': 999, 'total_coupling': 999,
                       'connectivity': 0, 'modularity': 0})
    
    # åˆ›å»ºç»“æœDataFrameï¼Œç¡®ä¿è‡³å°‘æœ‰ä¸€äº›ç»“æœ
    if not results:
        results = [{'method': 'No Method Succeeded', 'load_cv': 999, 'total_coupling': 999,
                   'connectivity': 0, 'modularity': 0}]
    
    df = pd.DataFrame(results)
    df = df.set_index('method')
    
    return df


def run_baseline_comparison(env, agent, seed: int = 42):
    """Test function for baseline methods comparison"""
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    set_baseline_seed(seed)
    
    # æ‰§è¡Œå¯¹æ¯”
    print(f"\nğŸ“Š æ‰§è¡Œæ–¹æ³•å¯¹æ¯”ï¼ˆéšæœºç§å­ï¼š{seed}ï¼‰...")
    comparison_df = compare_methods(env, agent, seed=seed)

    # æ˜¾ç¤ºç»“æœ
    print("\nğŸ“‹ åˆ†åŒºæ–¹æ³•å¯¹æ¯”ç»“æœ:")
    print(comparison_df.round(4))

    # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆè¶Šå°è¶Šå¥½çš„æŒ‡æ ‡å–è´Ÿå€¼ï¼‰
    weights = {
        'load_cv': -0.3,
        'total_coupling': -0.25,
        'connectivity': 0.2,
        'modularity': 0.15,
        'power_balance': -0.1
    }

    scores = []
    for method in comparison_df.index:
        score = sum(comparison_df.loc[method, metric] * weight 
                   for metric, weight in weights.items() 
                   if metric in comparison_df.columns)
        scores.append(score)

    comparison_df['overall_score'] = scores
    comparison_df = comparison_df.sort_values('overall_score', ascending=False)

    print("\nğŸ† ç»¼åˆè¯„åˆ†æ’å:")
    print(comparison_df[['overall_score']].round(4))
    
    return comparison_df

