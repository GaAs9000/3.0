"""
Tensorä¸€è‡´æ€§æµ‹è¯•

éªŒè¯v3.0æ¶æ„ä¿®å¤äº†åŸå§‹çš„tensorå †å é”™è¯¯ï¼Œç¡®ä¿ï¼š
1. DecisionContextæ‰¹é‡å¤„ç†çš„ä¸€è‡´æ€§
2. PPOè®­ç»ƒä¸­çš„tensorå †å ä¸ä¼šå‡ºé”™
3. ç´¢å¼•æ˜ å°„çš„æ­£ç¡®æ€§
4. æ‰¹é‡log_probè®¡ç®—çš„ç¨³å®šæ€§
"""

import pytest
import torch
import numpy as np
from typing import List, Dict, Any
import sys
import os

# æ·»åŠ srcè·¯å¾„ä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from rl.decision_context import AbstractDecisionContext, DecisionContextBatch, create_decision_context
from rl.fast_memory import FastPPOMemory
from rl.agent import PPOAgent
from rl.compatibility import CompatibilityManager, CompatibilityConfig

class TestTensorConsistency:
    """Tensorä¸€è‡´æ€§æµ‹è¯•ç±»"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.device = torch.device('cpu')  # ä½¿ç”¨CPUä»¥ä¾¿è°ƒè¯•
        self.embedding_dim = 64
        self.strategy_dim = 32
        self.partition_dim = 32  # ç­–ç•¥å‘é‡å’Œåˆ†åŒºåµŒå…¥åº”è¯¥åŒç»´åº¦
        
    def create_mock_decision_context(self, num_candidates: int = 3) -> AbstractDecisionContext:
        """åˆ›å»ºæ¨¡æ‹Ÿçš„å†³ç­–ä¸Šä¸‹æ–‡"""
        # åˆ›å»ºä¸€è‡´çš„æµ‹è¯•æ•°æ®
        strategy_vector = torch.randn(self.strategy_dim)
        candidate_embeddings = torch.randn(num_candidates, self.partition_dim)
        
        # è®¡ç®—çœŸå®çš„ç›¸ä¼¼åº¦
        similarities = torch.cosine_similarity(
            strategy_vector.unsqueeze(0), 
            candidate_embeddings, 
            dim=1
        )
        
        # é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„ä½œä¸ºç›®æ ‡
        selected_idx = torch.argmax(similarities).item()
        target_partition_embedding = candidate_embeddings[selected_idx].clone()
        
        # è®¡ç®—æ’åï¼šåœ¨é™åºæ’åºä¸­çš„ä½ç½®
        sorted_indices = torch.argsort(similarities, descending=True)
        selected_rank = (sorted_indices == selected_idx).nonzero(as_tuple=True)[0].item()
        
        return AbstractDecisionContext(
            node_embedding=torch.randn(self.embedding_dim),
            strategy_vector=strategy_vector,
            target_partition_embedding=target_partition_embedding,
            candidate_embeddings=candidate_embeddings,
            selection_similarities=similarities,
            selected_rank=selected_rank,
            decision_timestamp=1642345678.0,
            num_candidates=num_candidates,
            node_context={'node_id': 0, 'available_partitions': list(range(num_candidates))}
        )
    
    def test_decision_context_consistency(self):
        """æµ‹è¯•å•ä¸ªDecisionContextçš„å†…éƒ¨ä¸€è‡´æ€§"""
        print("\n=== æµ‹è¯•DecisionContextå†…éƒ¨ä¸€è‡´æ€§ ===")
        
        # åˆ›å»ºæµ‹è¯•ä¸Šä¸‹æ–‡
        ctx = self.create_mock_decision_context(num_candidates=5)
        
        # éªŒè¯åŸºæœ¬å±æ€§
        assert ctx.node_embedding.size(0) == self.embedding_dim
        assert ctx.strategy_vector.size(0) == self.strategy_dim
        assert ctx.candidate_embeddings.size() == (5, self.partition_dim)
        assert ctx.selection_similarities.size(0) == 5
        assert ctx.num_candidates == 5
        
        # éªŒè¯å†…éƒ¨ä¸€è‡´æ€§
        assert ctx.validate_consistency(), "DecisionContextå†…éƒ¨ä¸€è‡´æ€§éªŒè¯å¤±è´¥"
        
        print("âœ… DecisionContextå†…éƒ¨ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_decision_context_batch_consistency(self):
        """æµ‹è¯•DecisionContextBatchçš„æ‰¹é‡å¤„ç†ä¸€è‡´æ€§"""
        print("\n=== æµ‹è¯•DecisionContextBatchæ‰¹é‡å¤„ç†ä¸€è‡´æ€§ ===")
        
        # åˆ›å»ºä¸åŒå€™é€‰æ•°é‡çš„ä¸Šä¸‹æ–‡ï¼ˆæ¨¡æ‹Ÿç°å®åœºæ™¯ï¼‰
        contexts = [
            self.create_mock_decision_context(num_candidates=3),
            self.create_mock_decision_context(num_candidates=4),
            self.create_mock_decision_context(num_candidates=2),
            self.create_mock_decision_context(num_candidates=5),
        ]
        
        batch = DecisionContextBatch(contexts=contexts, batch_size=4)
        
        # æµ‹è¯•æ‰¹é‡log_probè®¡ç®—
        try:
            log_probs = batch.compute_batch_log_probs(temperature=1.0)
            assert log_probs.size(0) == 4, f"æœŸæœ›4ä¸ªlog_probï¼Œå®é™…å¾—åˆ°{log_probs.size(0)}"
            assert torch.all(torch.isfinite(log_probs)), "log_probåŒ…å«æ— æ•ˆå€¼"
            print(f"âœ… æ‰¹é‡log_probè®¡ç®—æˆåŠŸï¼š{log_probs}")
            
        except Exception as e:
            pytest.fail(f"æ‰¹é‡log_probè®¡ç®—å¤±è´¥ï¼š{e}")
        
        # æµ‹è¯•æ‰¹é‡ä¸€è‡´æ€§éªŒè¯
        consistency_results = batch.validate_batch_consistency()
        assert all(consistency_results), f"æ‰¹é‡ä¸€è‡´æ€§éªŒè¯å¤±è´¥ï¼š{consistency_results}"
        
        print("âœ… DecisionContextBatchæ‰¹é‡å¤„ç†ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_memory_storage_consistency(self):
        """æµ‹è¯•å†…å­˜å­˜å‚¨çš„ä¸€è‡´æ€§"""
        print("\n=== æµ‹è¯•å†…å­˜å­˜å‚¨ä¸€è‡´æ€§ ===")
        
        memory = FastPPOMemory(capacity=100, device=self.device)
        
        # å­˜å‚¨æ··åˆæ ¼å¼æ•°æ®ï¼ˆv3.0å’Œä¼ ç»Ÿï¼‰
        contexts_data = []
        
        for i in range(10):
            state = {'x': torch.randn(14, 32), 'current_partition': torch.randint(1, 4, (14,))}
            
            if i % 2 == 0:
                # å­˜å‚¨v3.0æ ¼å¼
                ctx = self.create_mock_decision_context(num_candidates=3)
                memory.store(
                    state=state,
                    decision_context=ctx,
                    reward=float(i),
                    value=float(i * 2),
                    done=(i == 9)
                )
                contexts_data.append(('v3', ctx))
            else:
                # å­˜å‚¨ä¼ ç»Ÿæ ¼å¼
                action = (i % 14, (i % 3) + 1)
                memory.store(
                    state=state,
                    action=action,
                    reward=float(i),
                    log_prob=0.1,
                    value=float(i * 2),
                    done=(i == 9)
                )
                contexts_data.append(('legacy', action))
        
        # éªŒè¯å­˜å‚¨
        assert memory.size == 10, f"æœŸæœ›å­˜å‚¨10ä¸ªæ ·æœ¬ï¼Œå®é™…{memory.size}"
        assert memory.has_decision_contexts(), "åº”è¯¥åŒ…å«å†³ç­–ä¸Šä¸‹æ–‡"
        
        # è·å–v3.0æ ¼å¼çš„æ‰¹æ¬¡
        states, decision_contexts, rewards, values, dones = memory.get_decision_contexts_batch()
        
        # éªŒè¯v3.0æ‰¹æ¬¡çš„ä¸€è‡´æ€§
        assert len(decision_contexts) == 5, f"æœŸæœ›5ä¸ªå†³ç­–ä¸Šä¸‹æ–‡ï¼Œå®é™…{len(decision_contexts)}"
        assert len(states) == 5, f"æœŸæœ›5ä¸ªçŠ¶æ€ï¼Œå®é™…{len(states)}"
        
        print(f"âœ… v3.0æ ¼å¼å­˜å‚¨äº†{len(decision_contexts)}ä¸ªä¸Šä¸‹æ–‡")
        print(f"âœ… ä¼ ç»Ÿæ ¼å¼å­˜å‚¨äº†{memory.size - len(decision_contexts)}ä¸ªåŠ¨ä½œ")
        
        print("âœ… å†…å­˜å­˜å‚¨ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_ppo_batch_processing(self):
        """æµ‹è¯•PPOæ‰¹é‡å¤„ç†çš„tensorä¸€è‡´æ€§"""
        print("\n=== æµ‹è¯•PPOæ‰¹é‡å¤„ç†tensorä¸€è‡´æ€§ ===")
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„PPOè®­ç»ƒæ•°æ®
        batch_size = 8
        contexts = []
        
        for i in range(batch_size):
            # å˜åŒ–çš„å€™é€‰æ•°é‡ï¼Œæ¨¡æ‹Ÿå®é™…è®­ç»ƒä¸­çš„æƒ…å†µ
            num_candidates = np.random.randint(2, 6)
            ctx = self.create_mock_decision_context(num_candidates=num_candidates)
            contexts.append(ctx)
        
        # åˆ›å»ºDecisionContextBatch
        batch = DecisionContextBatch(contexts=contexts, batch_size=batch_size)
        
        # æµ‹è¯•æ‰¹é‡log_probè®¡ç®—ï¼ˆè¿™æ˜¯åŸæ¥å®¹æ˜“å‡ºé”™çš„åœ°æ–¹ï¼‰
        try:
            # å¤šæ¬¡è®¡ç®—ä»¥æµ‹è¯•ç¨³å®šæ€§
            for temp in [0.5, 1.0, 1.5, 2.0]:
                log_probs = batch.compute_batch_log_probs(temperature=temp)
                
                # éªŒè¯è¾“å‡ºå½¢çŠ¶
                assert log_probs.shape == (batch_size,), f"æ¸©åº¦{temp}æ—¶å½¢çŠ¶é”™è¯¯ï¼š{log_probs.shape}"
                
                # éªŒè¯æ•°å€¼æœ‰æ•ˆæ€§
                assert torch.all(torch.isfinite(log_probs)), f"æ¸©åº¦{temp}æ—¶åŒ…å«æ— æ•ˆå€¼"
                
                print(f"âœ… æ¸©åº¦{temp}ï¼šlog_probså½¢çŠ¶{log_probs.shape}ï¼ŒèŒƒå›´[{log_probs.min():.3f}, {log_probs.max():.3f}]")
        
        except Exception as e:
            pytest.fail(f"PPOæ‰¹é‡å¤„ç†å¤±è´¥ï¼š{e}")
        
        print("âœ… PPOæ‰¹é‡å¤„ç†tensorä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_original_tensor_stacking_error_scenario(self):
        """æµ‹è¯•åŸå§‹tensorå †å é”™è¯¯çš„åœºæ™¯"""
        print("\n=== æµ‹è¯•åŸå§‹tensorå †å é”™è¯¯åœºæ™¯çš„ä¿®å¤ ===")
        
        # æ¨¡æ‹ŸåŸå§‹é”™è¯¯åœºæ™¯ï¼šä¸åŒå¤§å°çš„tensoråˆ—è¡¨
        # åœ¨v3.0æ¶æ„ä¸­ï¼Œè¿™åº”è¯¥è¢«å®Œå…¨é¿å…
        
        irregular_contexts = []
        
        # åˆ›å»ºä¸€äº›"æ­£å¸¸"çš„ä¸Šä¸‹æ–‡
        for i in range(5):
            ctx = self.create_mock_decision_context(num_candidates=3)
            irregular_contexts.append(ctx)
        
        # åˆ›å»ºä¸€äº›"å¼‚å¸¸"çš„ä¸Šä¸‹æ–‡ï¼ˆä¸åŒå€™é€‰æ•°é‡ï¼‰
        for candidates in [1, 2, 4, 6]:
            ctx = self.create_mock_decision_context(num_candidates=candidates)
            irregular_contexts.append(ctx)
        
        # åœ¨åŸæ¥çš„ç³»ç»Ÿä¸­ï¼Œè¿™ç§æƒ…å†µå¯èƒ½å¯¼è‡´å †å é”™è¯¯
        # åœ¨v3.0ä¸­ï¼Œåº”è¯¥èƒ½å¤Ÿæ­£ç¡®å¤„ç†
        try:
            batch = DecisionContextBatch(contexts=irregular_contexts, batch_size=len(irregular_contexts))
            
            # å…³é”®æµ‹è¯•ï¼šæ‰¹é‡è®¡ç®—ä¸åº”è¯¥å¤±è´¥
            log_probs = batch.compute_batch_log_probs()
            
            assert log_probs.shape == (len(irregular_contexts),), f"ä¸è§„åˆ™æ‰¹æ¬¡å½¢çŠ¶é”™è¯¯ï¼š{log_probs.shape}"
            assert torch.all(torch.isfinite(log_probs)), "ä¸è§„åˆ™æ‰¹æ¬¡åŒ…å«æ— æ•ˆå€¼"
            
            print(f"âœ… ä¸è§„åˆ™æ‰¹æ¬¡å¤„ç†æˆåŠŸï¼š{len(irregular_contexts)}ä¸ªä¸Šä¸‹æ–‡ï¼Œå€™é€‰æ•°é‡èŒƒå›´1-6")
            print(f"âœ… log_probs: {log_probs}")
            
        except Exception as e:
            pytest.fail(f"ä¸è§„åˆ™æ‰¹æ¬¡å¤„ç†å¤±è´¥ï¼ˆåŸå§‹é”™è¯¯åœºæ™¯ï¼‰ï¼š{e}")
        
        print("âœ… åŸå§‹tensorå †å é”™è¯¯åœºæ™¯ä¿®å¤éªŒè¯é€šè¿‡")
    
    def test_backward_compatibility_tensor_consistency(self):
        """æµ‹è¯•å‘åå…¼å®¹æ€§ä¸­çš„tensorä¸€è‡´æ€§"""
        print("\n=== æµ‹è¯•å‘åå…¼å®¹æ€§tensorä¸€è‡´æ€§ ===")
        
        compat_mgr = CompatibilityManager()
        
        # æµ‹è¯•æ··åˆæ ¼å¼çš„å¤„ç†
        mixed_actions = [
            (1, 2),  # ä¼ ç»Ÿaction tuple
            self.create_mock_decision_context(3),  # v3.0 context
            (3, 1),  # å¦ä¸€ä¸ªä¼ ç»Ÿaction
            self.create_mock_decision_context(4),  # å¦ä¸€ä¸ªv3.0 context
        ]
        
        # æµ‹è¯•æ ¼å¼æ£€æµ‹çš„ä¸€è‡´æ€§
        for i, action in enumerate(mixed_actions):
            format_type = compat_mgr.detect_action_format(action)
            
            if i % 2 == 0:
                assert format_type == 'legacy_tuple', f"ç´¢å¼•{i}åº”è¯¥æ˜¯legacy_tupleï¼Œå®é™…æ˜¯{format_type}"
            else:
                assert format_type == 'v3_context', f"ç´¢å¼•{i}åº”è¯¥æ˜¯v3_contextï¼Œå®é™…æ˜¯{format_type}"
        
        print("âœ… æ··åˆæ ¼å¼æ£€æµ‹ä¸€è‡´æ€§é€šè¿‡")
        
        # æµ‹è¯•å…·ä½“åŠ¨ä½œç¡®ä¿çš„ä¸€è‡´æ€§
        concrete_actions = []
        for action in mixed_actions:
            concrete = compat_mgr.ensure_concrete_action(action)
            concrete_actions.append(concrete)
        
        # æ‰€æœ‰å…·ä½“åŠ¨ä½œéƒ½åº”è¯¥æ˜¯æœ‰æ•ˆçš„tuple
        for i, concrete in enumerate(concrete_actions):
            assert isinstance(concrete, tuple), f"ç´¢å¼•{i}çš„å…·ä½“åŠ¨ä½œä¸æ˜¯tupleï¼š{type(concrete)}"
            assert len(concrete) == 2, f"ç´¢å¼•{i}çš„å…·ä½“åŠ¨ä½œé•¿åº¦ä¸æ˜¯2ï¼š{len(concrete)}"
            assert isinstance(concrete[0], int), f"ç´¢å¼•{i}çš„node_idä¸æ˜¯intï¼š{type(concrete[0])}"
            assert isinstance(concrete[1], int), f"ç´¢å¼•{i}çš„partition_idä¸æ˜¯intï¼š{type(concrete[1])}"
        
        print(f"âœ… å…·ä½“åŠ¨ä½œç¡®ä¿ä¸€è‡´æ€§é€šè¿‡ï¼š{concrete_actions}")
        print("âœ… å‘åå…¼å®¹æ€§tensorä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_end_to_end_consistency(self):
        """ç«¯åˆ°ç«¯ä¸€è‡´æ€§æµ‹è¯•"""
        print("\n=== ç«¯åˆ°ç«¯ä¸€è‡´æ€§æµ‹è¯• ===")
        
        # åˆ›å»ºå®Œæ•´çš„å·¥ä½œæµç¨‹
        memory = FastPPOMemory(capacity=50, device=self.device)
        
        # æ¨¡æ‹Ÿä¸€ä¸ªepisodeçš„æ•°æ®æ”¶é›†
        episode_contexts = []
        
        for step in range(20):
            state = {
                'x': torch.randn(14, 32),
                'current_partition': torch.randint(1, 4, (14,)),
                'boundary_nodes': torch.randint(0, 14, (np.random.randint(2, 6),))
            }
            
            # åˆ›å»ºå†³ç­–ä¸Šä¸‹æ–‡
            num_candidates = np.random.randint(2, 5)
            ctx = self.create_mock_decision_context(num_candidates=num_candidates)
            
            # å­˜å‚¨åˆ°å†…å­˜
            memory.store(
                state=state,
                decision_context=ctx,
                reward=np.random.random(),
                value=np.random.random(),
                done=(step == 19)
            )
            
            episode_contexts.append(ctx)
        
        # è·å–æ‰¹æ¬¡è¿›è¡Œ"è®­ç»ƒ"
        states, contexts, rewards, values, dones = memory.get_decision_contexts_batch()
        
        # éªŒè¯æ‰¹æ¬¡å®Œæ•´æ€§
        assert len(contexts) == 20, f"æœŸæœ›20ä¸ªä¸Šä¸‹æ–‡ï¼Œå®é™…{len(contexts)}"
        assert len(rewards) == 20, f"æœŸæœ›20ä¸ªå¥–åŠ±ï¼Œå®é™…{len(rewards)}"
        
        # åˆ›å»ºæ‰¹æ¬¡å¹¶è®¡ç®—log_probs
        batch = DecisionContextBatch(contexts=contexts, batch_size=len(contexts))
        log_probs = batch.compute_batch_log_probs()
        
        # éªŒè¯æœ€ç»ˆç»“æœ
        assert log_probs.shape == (20,), f"log_probså½¢çŠ¶é”™è¯¯ï¼š{log_probs.shape}"
        assert torch.all(torch.isfinite(log_probs)), "log_probsåŒ…å«æ— æ•ˆå€¼"
        
        # æ¨¡æ‹ŸPPOè®¡ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰
        old_log_probs = torch.randn(20)
        advantages = torch.randn(20)
        
        try:
            # è¿™æ˜¯åŸæ¥å®¹æ˜“å‡ºé”™çš„è®¡ç®—
            ratio = torch.exp(log_probs - old_log_probs)
            surr1 = ratio * advantages
            
            assert torch.all(torch.isfinite(ratio)), "ratioåŒ…å«æ— æ•ˆå€¼"
            assert torch.all(torch.isfinite(surr1)), "surr1åŒ…å«æ— æ•ˆå€¼"
            
            print(f"âœ… PPOè®¡ç®—æˆåŠŸï¼šratioèŒƒå›´[{ratio.min():.3f}, {ratio.max():.3f}]")
            
        except Exception as e:
            pytest.fail(f"ç«¯åˆ°ç«¯PPOè®¡ç®—å¤±è´¥ï¼š{e}")
        
        print("âœ… ç«¯åˆ°ç«¯ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")


def run_tensor_consistency_tests():
    """è¿è¡Œæ‰€æœ‰tensorä¸€è‡´æ€§æµ‹è¯•"""
    print("ğŸ”¬ å¼€å§‹Tensorä¸€è‡´æ€§æµ‹è¯•")
    print("=" * 60)
    
    test_suite = TestTensorConsistency()
    test_suite.setup_method()
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_suite.test_decision_context_consistency()
        test_suite.test_decision_context_batch_consistency()
        test_suite.test_memory_storage_consistency()
        test_suite.test_ppo_batch_processing()
        test_suite.test_original_tensor_stacking_error_scenario()
        test_suite.test_backward_compatibility_tensor_consistency()
        test_suite.test_end_to_end_consistency()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰Tensorä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… v3.0æ¶æ„æˆåŠŸä¿®å¤äº†åŸå§‹çš„tensorå †å é”™è¯¯")
        print("âœ… æ‰¹é‡å¤„ç†ç¨³å®šå¯é ")
        print("âœ… å‘åå…¼å®¹æ€§å®Œæ•´")
        print("âœ… ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_tensor_consistency_tests()
    exit(0 if success else 1) 