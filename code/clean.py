#!/usr/bin/env python3
"""
è®­ç»ƒç¼“å­˜æ¸…ç†å·¥å…·

è¿™ä¸ªè„šæœ¬ç”¨äºæ¸…ç†ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ é¡¹ç›®ä¸­çš„å„ç§ç¼“å­˜å’Œä¸´æ—¶æ–‡ä»¶ï¼Œ
åŒ…æ‹¬è®­ç»ƒæ—¥å¿—ã€æ£€æŸ¥ç‚¹ã€TensorBoardç¼“å­˜ã€æ¨¡å‹æ–‡ä»¶ç­‰ã€‚

ä½¿ç”¨æ–¹æ³•:
    python clean.py --all                    # æ¸…ç†æ‰€æœ‰ç¼“å­˜
    python clean.py --logs                   # åªæ¸…ç†æ—¥å¿—
    python clean.py --checkpoints            # åªæ¸…ç†æ£€æŸ¥ç‚¹
    python clean.py --tensorboard            # åªæ¸…ç†TensorBoardç¼“å­˜
    python clean.py --interactive            # äº¤äº’æ¨¡å¼
"""

import os
import shutil
import argparse
import time
from pathlib import Path
from typing import List, Dict
import subprocess
import psutil


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.total_size_cleaned = 0
        
        # å®šä¹‰éœ€è¦æ¸…ç†çš„ç›®å½•å’Œæ–‡ä»¶æ¨¡å¼
        self.cache_config = {
            'logs': {
                'paths': ['logs', 'runs'],
                'description': 'TensorBoardæ—¥å¿—å’Œè®­ç»ƒè®°å½•',
                'exclude': []  # å¯ä»¥æ’é™¤æŸäº›å­ç›®å½•
            },
            'checkpoints': {
                'paths': ['checkpoints', 'models'],
                'description': 'æ¨¡å‹æ£€æŸ¥ç‚¹å’Œä¿å­˜çš„æ¨¡å‹',
                'exclude': []
            },
            'cache': {
                'paths': ['cache'],
                'description': 'æ•°æ®ç¼“å­˜æ–‡ä»¶',
                'exclude': []
            },
            'pycache': {
                'paths': ['__pycache__'],
                'description': 'Pythonå­—èŠ‚ç ç¼“å­˜',
                'exclude': [],
                'recursive': True  # é€’å½’æŸ¥æ‰¾æ‰€æœ‰__pycache__ç›®å½•
            },
            'output': {
                'paths': ['output'],
                'description': 'è¾“å‡ºæ–‡ä»¶å’Œç»“æœ',
                'exclude': []
            },
            'figures': {
                'paths': ['figures'],
                'description': 'ç”Ÿæˆçš„å›¾è¡¨å’Œå¯è§†åŒ–æ–‡ä»¶ï¼ˆæ—§ç‰ˆæœ¬ï¼‰',
                'exclude': []
            },
            'temp': {
                'paths': ['.tmp', 'tmp', 'temp'],
                'description': 'ä¸´æ—¶æ–‡ä»¶',
                'exclude': []
            },
            'experiments': {
                'paths': ['experiments'],
                'description': 'å®éªŒæ•°æ®å’Œç»“æœ',
                'exclude': []
            }
        }
        
        # æ–‡ä»¶æ‰©å±•åæ¨¡å¼
        self.file_patterns = {
            'model_files': ['*.pt', '*.pth', '*.pkl', '*.pickle'],
            'log_files': ['*.log'],
            'temp_files': ['*.tmp', '*.temp', '*~'],
            'backup_files': ['*.bak', '*.backup'],
            'tensorboard_files': ['events.out.tfevents.*']
        }

    def get_directory_size(self, path: Path) -> int:
        """è®¡ç®—ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        if not path.exists():
            return 0
        
        total_size = 0
        try:
            if path.is_file():
                return path.stat().st_size
            
            for item in path.rglob('*'):
                if item.is_file():
                    try:
                        total_size += item.stat().st_size
                    except (OSError, FileNotFoundError):
                        continue
        except (OSError, PermissionError):
            pass
        
        return total_size

    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        if size_bytes == 0:
            return "0 B"
        
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} PB"

    def kill_tensorboard_processes(self):
        """ç»ˆæ­¢æ‰€æœ‰TensorBoardè¿›ç¨‹"""
        killed_processes = []
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if proc.info['name'] and 'tensorboard' in proc.info['name'].lower():
                    proc.kill()
                    killed_processes.append(proc.info['pid'])
                elif proc.info['cmdline']:
                    cmdline = ' '.join(proc.info['cmdline']).lower()
                    if 'tensorboard' in cmdline:
                        proc.kill()
                        killed_processes.append(proc.info['pid'])
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        
        if killed_processes:
            print(f"ğŸ”„ å·²ç»ˆæ­¢ {len(killed_processes)} ä¸ªTensorBoardè¿›ç¨‹")
            time.sleep(2)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢
        
        return killed_processes

    def scan_cache_usage(self) -> Dict[str, Dict]:
        """æ‰«ææ‰€æœ‰ç¼“å­˜ä½¿ç”¨æƒ…å†µ"""
        print("ğŸ” æ­£åœ¨æ‰«æç¼“å­˜ä½¿ç”¨æƒ…å†µ...")
        
        cache_info = {}
        
        for cache_type, config in self.cache_config.items():
            cache_info[cache_type] = {
                'paths': [],
                'total_size': 0,
                'file_count': 0,
                'description': config['description']
            }
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é€’å½’æŸ¥æ‰¾
            if config.get('recursive', False):
                # é€’å½’æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„ç›®å½•
                for path_pattern in config['paths']:
                    for found_path in self.project_root.rglob(path_pattern):
                        if found_path.is_dir():
                            size = self.get_directory_size(found_path)
                            file_count = len(list(found_path.rglob('*'))) if found_path.is_dir() else 1
                            
                            cache_info[cache_type]['paths'].append({
                                'path': found_path,
                                'size': size,
                                'file_count': file_count
                            })
                            cache_info[cache_type]['total_size'] += size
                            cache_info[cache_type]['file_count'] += file_count
            else:
                # åªæŸ¥æ‰¾ç›´æ¥è·¯å¾„
                for path_pattern in config['paths']:
                    full_path = self.project_root / path_pattern
                    if full_path.exists():
                        size = self.get_directory_size(full_path)
                        file_count = len(list(full_path.rglob('*'))) if full_path.is_dir() else 1
                        
                        cache_info[cache_type]['paths'].append({
                            'path': full_path,
                            'size': size,
                            'file_count': file_count
                        })
                        cache_info[cache_type]['total_size'] += size
                        cache_info[cache_type]['file_count'] += file_count
        
        # æ‰«æç‰¹å®šæ–‡ä»¶æ¨¡å¼
        for pattern_type, patterns in self.file_patterns.items():
            if pattern_type not in cache_info:
                cache_info[pattern_type] = {
                    'paths': [],
                    'total_size': 0,
                    'file_count': 0,
                    'description': f'{pattern_type.replace("_", " ").title()}'
                }
            
            for pattern in patterns:
                for file_path in self.project_root.rglob(pattern):
                    if file_path.is_file():
                        size = file_path.stat().st_size
                        cache_info[pattern_type]['paths'].append({
                            'path': file_path,
                            'size': size,
                            'file_count': 1
                        })
                        cache_info[pattern_type]['total_size'] += size
                        cache_info[pattern_type]['file_count'] += 1
        
        return cache_info

    def display_cache_summary(self, cache_info: Dict[str, Dict]):
        """æ˜¾ç¤ºç¼“å­˜ä½¿ç”¨æ‘˜è¦"""
        print("\nğŸ“Š ç¼“å­˜ä½¿ç”¨æƒ…å†µæ‘˜è¦:")
        print("=" * 80)
        
        total_size = 0
        total_files = 0
        
        for cache_type, info in cache_info.items():
            if info['total_size'] > 0:
                print(f"{cache_type.upper():15} | "
                      f"{self.format_size(info['total_size']):>10} | "
                      f"{info['file_count']:>8} æ–‡ä»¶ | "
                      f"{info['description']}")
                total_size += info['total_size']
                total_files += info['file_count']
        
        print("=" * 80)
        print(f"{'æ€»è®¡':15} | {self.format_size(total_size):>10} | {total_files:>8} æ–‡ä»¶")
        print()

    def clean_cache_type(self, cache_type: str, cache_info: Dict, confirm: bool = True) -> bool:
        """æ¸…ç†æŒ‡å®šç±»å‹çš„ç¼“å­˜"""
        if cache_type not in cache_info or cache_info[cache_type]['total_size'] == 0:
            print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ° {cache_type} ç±»å‹çš„ç¼“å­˜æ–‡ä»¶")
            return False
        
        info = cache_info[cache_type]
        size_to_clean = info['total_size']
        files_to_clean = info['file_count']
        
        if confirm:
            response = input(f"ğŸ—‘ï¸  ç¡®å®šè¦æ¸…ç† {cache_type} ({self.format_size(size_to_clean)}, {files_to_clean} æ–‡ä»¶)? [y/N]: ")
            if response.lower() not in ['y', 'yes', 'æ˜¯']:
                print("âŒ å–æ¶ˆæ¸…ç†")
                return False
        
        print(f"ğŸ§¹ æ­£åœ¨æ¸…ç† {cache_type}...")
        
        cleaned_size = 0
        cleaned_files = 0
        
        for path_info in info['paths']:
            path = path_info['path']
            try:
                if path.exists():
                    if path.is_dir():
                        shutil.rmtree(path)
                        print(f"   åˆ é™¤ç›®å½•: {path.relative_to(self.project_root)}")
                    else:
                        path.unlink()
                        print(f"   åˆ é™¤æ–‡ä»¶: {path.relative_to(self.project_root)}")
                    
                    cleaned_size += path_info['size']
                    cleaned_files += path_info['file_count']
            except Exception as e:
                print(f"   âš ï¸  æ— æ³•åˆ é™¤ {path}: {e}")
        
        self.total_size_cleaned += cleaned_size
        print(f"âœ… {cache_type} æ¸…ç†å®Œæˆ: {self.format_size(cleaned_size)}, {cleaned_files} æ–‡ä»¶")
        return True

    def clean_all_cache(self, confirm: bool = True):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        print("å¼€å§‹å…¨é¢æ¸…ç†ç¼“å­˜...")

        # é¦–å…ˆç»ˆæ­¢TensorBoardè¿›ç¨‹
        self.kill_tensorboard_processes()

        # æ‰«æç¼“å­˜
        cache_info = self.scan_cache_usage()

        if confirm:
            self.display_cache_summary(cache_info)
            response = input("ç¡®å®šè¦æ¸…ç†æ‰€æœ‰ç¼“å­˜å—? [y/N]: ")
            if response.lower() not in ['y', 'yes', 'æ˜¯']:
                print("å–æ¶ˆæ¸…ç†")
                return

        # æ¸…ç†æ¯ç§ç±»å‹çš„ç¼“å­˜
        for cache_type in cache_info.keys():
            if cache_info[cache_type]['total_size'] > 0:
                self.clean_cache_type(cache_type, cache_info, confirm=False)

        print(f"\næ¸…ç†å®Œæˆ! æ€»å…±é‡Šæ”¾äº† {self.format_size(self.total_size_cleaned)} çš„ç£ç›˜ç©ºé—´")

    def interactive_cleanup(self):
        """äº¤äº’å¼æ¸…ç†æ¨¡å¼"""
        print("è¿›å…¥äº¤äº’å¼æ¸…ç†æ¨¡å¼")
        print("æ‚¨å¯ä»¥é€‰æ‹©è¦æ¸…ç†çš„ç¼“å­˜ç±»å‹")
        
        # é¦–å…ˆç»ˆæ­¢TensorBoardè¿›ç¨‹
        self.kill_tensorboard_processes()
        
        while True:
            # æ‰«ææœ€æ–°çš„ç¼“å­˜ä¿¡æ¯
            cache_info = self.scan_cache_usage()
            self.display_cache_summary(cache_info)
            
            print("\nå¯ç”¨é€‰é¡¹:")
            print("1. æ¸…ç†è®­ç»ƒæ—¥å¿— (logs)")
            print("2. æ¸…ç†æ¨¡å‹æ£€æŸ¥ç‚¹ (checkpoints)")
            print("3. æ¸…ç†æ•°æ®ç¼“å­˜ (cache)")
            print("4. æ¸…ç†Pythonå­—èŠ‚ç  (pycache)")
            print("5. æ¸…ç†è¾“å‡ºæ–‡ä»¶ (output)")
            print("6. æ¸…ç†å›¾è¡¨æ–‡ä»¶ (figures)")
            print("7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (temp)")
            print("8. æ¸…ç†å®éªŒæ•°æ® (experiments)")
            print("9. æ¸…ç†æ‰€æœ‰ç¼“å­˜")
            print("r. é‡æ–°æ‰«æ")
            print("0. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ [0-9,r]: ").strip().lower()
            
            if choice == '0':
                break
            elif choice == '1':
                self.clean_cache_type('logs', cache_info)
            elif choice == '2':
                self.clean_cache_type('checkpoints', cache_info)
            elif choice == '3':
                self.clean_cache_type('cache', cache_info)
            elif choice == '4':
                self.clean_cache_type('pycache', cache_info)
            elif choice == '5':
                self.clean_cache_type('output', cache_info)
            elif choice == '6':
                self.clean_cache_type('figures', cache_info)
            elif choice == '7':
                self.clean_cache_type('temp', cache_info)
            elif choice == '8':
                self.clean_cache_type('experiments', cache_info)
            elif choice == '9':
                self.clean_all_cache()
                break
            elif choice == 'r':
                print("ğŸ”„ é‡æ–°æ‰«æä¸­...")
                continue
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
            
            print()

    def create_gitignore_backup(self):
        """åˆ›å»º.gitignoreå¤‡ä»½ä»¥é˜²æ­¢é‡è¦æ–‡ä»¶è¢«è¯¯åˆ """
        gitignore_path = self.project_root / '.gitignore'
        backup_path = self.project_root / '.gitignore.backup'
        
        if gitignore_path.exists() and not backup_path.exists():
            shutil.copy2(gitignore_path, backup_path)
            print("ğŸ“‹ å·²åˆ›å»º .gitignore å¤‡ä»½")

    def quick_clean_pycache(self):
        """å¿«é€Ÿæ¸…ç†æ‰€æœ‰__pycache__ç›®å½•"""
        print("ğŸš€ å¿«é€Ÿæ¸…ç†æ‰€æœ‰ __pycache__ ç›®å½•...")
        
        pycache_dirs = list(self.project_root.rglob('__pycache__'))
        if not pycache_dirs:
            print("âœ… æ²¡æœ‰æ‰¾åˆ° __pycache__ ç›®å½•")
            return
        
        total_size = 0
        for pycache_dir in pycache_dirs:
            if pycache_dir.is_dir():
                size = self.get_directory_size(pycache_dir)
                total_size += size
                try:
                    shutil.rmtree(pycache_dir)
                    print(f"   åˆ é™¤: {pycache_dir.relative_to(self.project_root)}")
                except Exception as e:
                    print(f"   âš ï¸  æ— æ³•åˆ é™¤ {pycache_dir}: {e}")
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼é‡Šæ”¾äº† {self.format_size(total_size)} çš„ç£ç›˜ç©ºé—´")
        self.total_size_cleaned += total_size


def main():
    parser = argparse.ArgumentParser(
        description="ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ é¡¹ç›®ç¼“å­˜æ¸…ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python cleanup_cache.py --all                    # æ¸…ç†æ‰€æœ‰ç¼“å­˜
  python cleanup_cache.py --logs                   # åªæ¸…ç†è®­ç»ƒæ—¥å¿—
  python cleanup_cache.py --checkpoints            # åªæ¸…ç†æ¨¡å‹æ£€æŸ¥ç‚¹
  python cleanup_cache.py --interactive            # äº¤äº’æ¨¡å¼é€‰æ‹©æ¸…ç†å†…å®¹
  python cleanup_cache.py --scan                   # åªæ‰«æä¸æ¸…ç†
        """
    )
    
    parser.add_argument('--all', action='store_true', help='æ¸…ç†æ‰€æœ‰ç¼“å­˜')
    parser.add_argument('--logs', action='store_true', help='æ¸…ç†è®­ç»ƒæ—¥å¿—')
    parser.add_argument('--checkpoints', action='store_true', help='æ¸…ç†æ¨¡å‹æ£€æŸ¥ç‚¹')
    parser.add_argument('--cache', action='store_true', help='æ¸…ç†æ•°æ®ç¼“å­˜')
    parser.add_argument('--pycache', action='store_true', help='æ¸…ç†Pythonå­—èŠ‚ç ç¼“å­˜')
    parser.add_argument('--output', action='store_true', help='æ¸…ç†è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--figures', action='store_true', help='æ¸…ç†å›¾è¡¨æ–‡ä»¶')
    parser.add_argument('--temp', action='store_true', help='æ¸…ç†ä¸´æ—¶æ–‡ä»¶')
    parser.add_argument('--experiments', action='store_true', help='æ¸…ç†å®éªŒæ•°æ®')
    parser.add_argument('--tensorboard', action='store_true', help='ç»ˆæ­¢TensorBoardè¿›ç¨‹å¹¶æ¸…ç†ç›¸å…³ç¼“å­˜')
    parser.add_argument('--interactive', action='store_true', help='äº¤äº’å¼æ¸…ç†æ¨¡å¼')
    parser.add_argument('--scan', action='store_true', help='åªæ‰«æç¼“å­˜ä½¿ç”¨æƒ…å†µï¼Œä¸è¿›è¡Œæ¸…ç†')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ¸…ç†ï¼Œä¸è¯¢é—®ç¡®è®¤')
    parser.add_argument('--quick-pycache', action='store_true', help='å¿«é€Ÿæ¸…ç†æ‰€æœ‰__pycache__ç›®å½•')
    parser.add_argument('--project-root', default='.', help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
    cache_manager = CacheManager(args.project_root)
    
    print("ğŸ§¹ ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ ç¼“å­˜æ¸…ç†å·¥å…·")
    print("=" * 50)
    
    # åˆ›å»ºå¤‡ä»½
    cache_manager.create_gitignore_backup()
    
    try:
        if args.interactive:
            cache_manager.interactive_cleanup()
        elif args.scan:
            cache_info = cache_manager.scan_cache_usage()
            cache_manager.display_cache_summary(cache_info)
        elif args.all:
            cache_manager.clean_all_cache(confirm=not args.force)
        elif args.tensorboard:
            cache_manager.kill_tensorboard_processes()
            cache_info = cache_manager.scan_cache_usage()
            cache_manager.clean_cache_type('logs', cache_info, confirm=not args.force)
        elif args.quick_pycache:
            cache_manager.quick_clean_pycache()
        else:
            # æ‰«æç¼“å­˜ä¿¡æ¯
            cache_info = cache_manager.scan_cache_usage()
            
            # æ ¹æ®å‚æ•°æ¸…ç†æŒ‡å®šç±»å‹
            cleaned_any = False
            for cache_type in ['logs', 'checkpoints', 'cache', 'pycache', 'output', 'figures', 'temp', 'experiments']:
                if getattr(args, cache_type):
                    cache_manager.clean_cache_type(cache_type, cache_info, confirm=not args.force)
                    cleaned_any = True
            
            if not cleaned_any:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ¸…ç†é€‰é¡¹ï¼Œæ˜¾ç¤ºå¸®åŠ©
                cache_manager.display_cache_summary(cache_info)
                print("\nä½¿ç”¨ --help æŸ¥çœ‹å¯ç”¨é€‰é¡¹ï¼Œæˆ–ä½¿ç”¨ --interactive è¿›å…¥äº¤äº’æ¨¡å¼")

    except KeyboardInterrupt:
        print("\n\næ¸…ç†æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nERROR: æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

    print("\næ¸…ç†å·¥å…·é€€å‡º")


if __name__ == "__main__":
    main() 