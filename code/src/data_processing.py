import numpy as np
import pandas as pd
import torch
from torch_geometric.data import HeteroData
from typing import Dict, Tuple, List, Optional
from sklearn.preprocessing import StandardScaler, RobustScaler
import hashlib
import pickle
import os
from pathlib import Path

class PowerGridDataProcessor:
    """
    ç”µç½‘æ•°æ®å¤„ç† - ç®€åŒ–å¼‚æ„å›¾ç‰ˆæœ¬
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. ç»Ÿä¸€èŠ‚ç‚¹ç±»å‹ä¸º'bus'ï¼Œå°†ç‰©ç†ç±»å‹(PQ/PV/Slack)è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç ç‰¹å¾
    2. ç»Ÿä¸€è¾¹å…³ç³»ä¸º('bus', 'connects', 'bus')ï¼Œå°†ç‰©ç†ç±»å‹(çº¿è·¯/å˜å‹å™¨)è½¬æ¢ä¸ºè¾¹ç‰¹å¾
    3. æ”¯æŒGNNæƒé‡å…±äº«å’Œé«˜æ•ˆå­¦ä¹ 
    4. ä¿æŒå“ˆå¸Œç¼“å­˜æœºåˆ¶
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. MATPOWERæ ¼å¼æ•°æ®æ¸…æ´—å’Œç‰¹å¾æå–
    2. æ„å»ºç®€åŒ–çš„PyTorch Geometricå¼‚æ„å›¾æ•°æ®
    3. å°†ç‰©ç†ç±»å‹ä¿¡æ¯ç‰¹å¾åŒ–è€Œéæ‹“æ‰‘åŒ–
    """
    
    def __init__(self, normalize: bool = True, cache_dir: str = 'cache'):
        self.normalize = normalize
        self.node_scaler = None
        self.edge_scaler = None
        self.cache_dir = cache_dir
        Path(cache_dir).mkdir(exist_ok=True, parents=True)
        
        # å®šä¹‰ç±»å‹æ˜ å°„å…³ç³»ï¼Œç”¨äºå°†MATPOWERä¸­çš„æ•°å­—ä»£ç è½¬æ¢ä¸ºæœ‰æ„ä¹‰çš„å­—ç¬¦ä¸²
        self.BUS_TYPE_MAP = {1: 'pq', 2: 'pv', 3: 'slack'}
        self.BRANCH_TYPE_MAP = {0: 'line', 1: 'transformer'}

    def graph_from_mpc(self, mpc: Dict) -> HeteroData:
        """
        å°†MATPOWERæ ¼å¼æ•°æ®è½¬æ¢ä¸ºç®€åŒ–çš„PyTorch Geometricå¼‚æ„å›¾æ•°æ® (HeteroData)
        
        å‚æ•°:
            mpc: MATPOWERæ ¼å¼çš„ç”µç½‘æ•°æ®å­—å…¸
            
        è¿”å›:
            data: ç®€åŒ–çš„PyTorch Geometric HeteroDataå¯¹è±¡
        """
        # 1. è®¡ç®—æ•°æ®å“ˆå¸Œç”¨äºç¼“å­˜ (æ–‡ä»¶åä¸­åŠ å…¥v3åç¼€ä»¥åŒºåˆ†æ–°ç‰ˆæœ¬)
        raw_bytes = pickle.dumps((mpc["bus"].tolist(), mpc["branch"].tolist()))
        case_hash = hashlib.md5(raw_bytes).hexdigest()[:8]
        cache_file = f"{self.cache_dir}/{case_hash}_hetero_v3.pt"
        
        # 2. å°è¯•ä»ç¼“å­˜åŠ è½½ï¼ˆå¸¦è¿›ç¨‹é”ä¿æŠ¤ï¼‰
        lock_file = cache_file + ".lock"
        if os.path.exists(cache_file):
            try:
                # ç­‰å¾…é”æ–‡ä»¶é‡Šæ”¾ï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
                wait_count = 0
                while os.path.exists(lock_file) and wait_count < 30:
                    import time
                    time.sleep(1)
                    wait_count += 1
                
                if os.path.exists(cache_file):
                    print(f"ğŸ“‚ ä»ç¼“å­˜åŠ è½½ç®€åŒ–å¼‚æ„å›¾: {cache_file}")
                    return torch.load(cache_file, map_location="cpu", weights_only=False)
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}ï¼Œé‡æ–°æ„å»º...")
        
        # 3. é¦–æ¬¡æ„å»ºç®€åŒ–å¼‚æ„å›¾æ•°æ®
        print(f"ğŸ”¨ é¦–æ¬¡æ„å»ºç®€åŒ–å¼‚æ„å›¾æ•°æ®...")
        baseMVA, df_nodes, df_edges, df_edge_features = self._process_matpower_data(mpc)
        data = self._create_simplified_hetero_data(df_nodes, df_edges, df_edge_features)
        
        # 4. ä¿å­˜åˆ°ç¼“å­˜ï¼ˆå¸¦è¿›ç¨‹é”ä¿æŠ¤ï¼‰
        try:
            # åˆ›å»ºé”æ–‡ä»¶
            with open(lock_file, 'w') as f:
                f.write(str(os.getpid()))
            
            torch.save(data, cache_file, pickle_protocol=pickle.DEFAULT_PROTOCOL)
            print(f"ğŸ’¾ å·²ç¼“å­˜ç®€åŒ–å¼‚æ„å›¾åˆ°: {cache_file}")
            
            # åˆ é™¤é”æ–‡ä»¶
            if os.path.exists(lock_file):
                os.remove(lock_file)
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
            if os.path.exists(lock_file):
                os.remove(lock_file)
        
        return data   
    
    def _process_matpower_data(self, mpc: Dict) -> Tuple[float, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """
        å¤„ç†MATPOWERæ ¼å¼æ•°æ®ï¼Œä¸ºæ„å»ºç®€åŒ–å¼‚æ„å›¾å‡†å¤‡åŒ…å«ç±»å‹ä¿¡æ¯çš„DataFrame
        
        å‚æ•°:
            mpc: MATPOWERæ ¼å¼çš„ç”µç½‘æ•°æ®å­—å…¸
            
        è¿”å›:
            baseMVA: åŸºå‡†åŠŸç‡(MVA)
            df_nodes: åŒ…å«bus_typeä¿¡æ¯çš„èŠ‚ç‚¹ç‰¹å¾DataFrame
            df_edges: è¾¹ç´¢å¼•DataFrame
            df_edge_features: åŒ…å«ç±»å‹ä¿¡æ¯çš„è¾¹ç‰¹å¾DataFrame
        """
        # 1. æå–åŸºå‡†åŠŸç‡å’ŒåŸºç¡€æ•°æ®
        baseMVA = float(mpc['baseMVA'])
        bus = np.asarray(mpc['bus']).copy()
        branch = np.asarray(mpc['branch']).copy()
        
        # 2. ä¿®å¤æ”¯è·¯è½½æµé™åˆ¶çš„ç¼ºå¤±å€¼
        for col in [5, 6, 7]:  # rateA, rateB, rateC
            mask = branch[:, col] == 0
            branch[mask, col] = baseMVA
        
        # 3. æå–åŸºç¡€ç‰¹å¾
        node_features = self._extract_node_features(bus, branch, baseMVA)
        edge_features, edge_index = self._extract_edge_features(branch, baseMVA)
        
        # 4. æ·»åŠ å‘ç”µæœºç‰¹å¾
        if 'gen' in mpc:
            gen_features = self._extract_generator_features(mpc['gen'], bus, baseMVA)
            node_features = np.hstack([node_features, gen_features])
        
        # 5. æ ‡å‡†åŒ–ç‰¹å¾ (åœ¨åˆ†å‰²æ•°æ®ç±»å‹å‰è¿›è¡Œï¼Œç¡®ä¿å°ºåº¦ä¸€è‡´)
        if self.normalize:
            node_features = self._normalize_features(node_features, 'node')
            edge_features = self._normalize_features(edge_features, 'edge')
            
        # 6. åˆ›å»ºåŒ…å«bus_typeä¿¡æ¯çš„DataFrameï¼Œä¿ç•™åŸå§‹æ•°å€¼ç±»å‹ç”¨äºç‹¬çƒ­ç¼–ç 
        # å®šä¹‰èŠ‚ç‚¹ç‰¹å¾åˆ—å
        node_columns = ['Pd', 'Qd', 'Gs', 'Bs', 'Vm', 'Va', 'Vmax', 'Vmin', 'degree']
        if 'gen' in mpc:
            node_columns.extend(['Pg', 'Qg', 'Pg_max', 'Pg_min', 'is_gen'])
            
        # ä½¿ç”¨0-basedçš„æ¯çº¿ç´¢å¼•ä½œä¸ºDataFrameçš„ç´¢å¼•
        df_nodes = pd.DataFrame(node_features, columns=node_columns, index=bus[:,0].astype(int)-1)
        
        # æ·»åŠ bus_typeåˆ—ï¼ˆä¿ç•™æ•°å€¼1,2,3ç”¨äºç‹¬çƒ­ç¼–ç ï¼‰
        bus_types_raw = bus[:, 1].astype(int)
        df_nodes['bus_type'] = bus_types_raw

        # å®šä¹‰è¾¹ç‰¹å¾åˆ—å
        df_edge_features = pd.DataFrame(
            edge_features,
            columns=['r', 'x', 'b', '|z|', 'y', 'rateA', 'angle_diff', 'is_transformer', 'status']
        )
        
        # åˆ›å»ºè¾¹ç´¢å¼•DataFrame
        df_edges = pd.DataFrame(edge_index, columns=['from_bus', 'to_bus'])
        
        return baseMVA, df_nodes, df_edges, df_edge_features

    def _create_simplified_hetero_data(self, df_nodes: pd.DataFrame, df_edges: pd.DataFrame, 
                                     df_edge_features: pd.DataFrame) -> HeteroData:
        """
        åˆ›å»ºç®€åŒ–çš„å¼‚æ„å›¾æ•°æ®ç»“æ„
        
        å…³é”®ç‰¹æ€§ï¼š
        1. ç»Ÿä¸€èŠ‚ç‚¹ç±»å‹ä¸º'bus'
        2. å°†bus_typeè½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç ç‰¹å¾
        3. ç»Ÿä¸€è¾¹å…³ç³»ä¸º('bus', 'connects', 'bus')
        4. å°†is_transformerä½œä¸ºè¾¹ç‰¹å¾ä¿ç•™
        
        å‚æ•°:
            df_nodes: åŒ…å«bus_typeä¿¡æ¯çš„èŠ‚ç‚¹ç‰¹å¾DataFrame
            df_edges: è¾¹ç´¢å¼•DataFrame
            df_edge_features: è¾¹ç‰¹å¾DataFrame
            
        è¿”å›:
            data: ç®€åŒ–çš„PyTorch Geometric HeteroDataå¯¹è±¡
        """
        data = HeteroData()
        
        # --- 1. å¤„ç†èŠ‚ç‚¹ï¼šç»Ÿä¸€ç±»å‹ + ç‹¬çƒ­ç¼–ç  ---
        print(f"ğŸ” èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ: {df_nodes['bus_type'].value_counts().to_dict()}")
        
        # åˆ›å»ºbus_typeçš„ç‹¬çƒ­ç¼–ç 
        bus_type_dummies = pd.get_dummies(df_nodes['bus_type'], prefix='type')
        
        # ç¡®ä¿åŒ…å«æ‰€æœ‰å¯èƒ½çš„ç±»å‹ï¼ˆtype_1, type_2, type_3ï¼‰
        for bus_type in [1, 2, 3]:
            col_name = f'type_{bus_type}'
            if col_name not in bus_type_dummies.columns:
                bus_type_dummies[col_name] = 0
        
        # æŒ‰ç…§åˆ—åæ’åºç¡®ä¿ä¸€è‡´æ€§
        bus_type_dummies = bus_type_dummies.reindex(sorted(bus_type_dummies.columns), axis=1)
        
        # è·å–åŸå§‹æ•°å€¼ç‰¹å¾ï¼ˆå»é™¤bus_typeåˆ—ï¼‰
        original_features = df_nodes.drop('bus_type', axis=1)
        
        # åˆå¹¶åŸå§‹ç‰¹å¾å’Œç‹¬çƒ­ç¼–ç ç±»å‹ç‰¹å¾
        combined_features = pd.concat([original_features, bus_type_dummies], axis=1)
        
        # åˆ›å»ºç‰¹å¾åç§°åˆ°ç´¢å¼•çš„æ˜ å°„ï¼Œä¾›ä¸‹æ¸¸ä»£ç ä½¿ç”¨
        feature_names = combined_features.columns.tolist()
        feature_index_map = {name: idx for idx, name in enumerate(feature_names)}
        
        # åˆ›å»ºç»Ÿä¸€çš„'bus'èŠ‚ç‚¹ç±»å‹
        data['bus'].x = torch.tensor(combined_features.values.astype(np.float32), dtype=torch.float32)
        data['bus'].global_ids = torch.tensor(df_nodes.index.tolist(), dtype=torch.long)
        
        # å­˜å‚¨ç‰¹å¾æ˜ å°„ä¿¡æ¯ä¾›ä¸‹æ¸¸ä½¿ç”¨
        data['bus'].feature_names = feature_names
        data['bus'].feature_index_map = feature_index_map
        
        print(f"  ğŸ“ bus: {len(df_nodes)} ä¸ªèŠ‚ç‚¹ï¼Œç‰¹å¾ç»´åº¦: {combined_features.shape[1]}")
        print(f"    - åŸå§‹æ•°å€¼ç‰¹å¾: {original_features.shape[1]}")
        print(f"    - ç‹¬çƒ­ç¼–ç ç±»å‹ç‰¹å¾: {bus_type_dummies.shape[1]}")
        print(f"    - ç‰¹å¾é¡ºåº: {feature_names}")
        
        # --- 2. å¤„ç†è¾¹ï¼šç»Ÿä¸€å…³ç³»ç±»å‹ ---
        print(f"ğŸ”— è¾¹ç±»å‹åˆ†å¸ƒ: is_transformer = {df_edge_features['is_transformer'].value_counts().to_dict()}")
        
        # æ„å»ºè¾¹ç´¢å¼•å¼ é‡
        edge_index = torch.tensor(df_edges[['from_bus', 'to_bus']].values.T, dtype=torch.long)
        
        # æ„å»ºè¾¹ç‰¹å¾å¼ é‡ï¼ˆå·²åŒ…å«is_transformerç‰¹å¾ï¼‰
        edge_attr = torch.tensor(df_edge_features.values.astype(np.float32), dtype=torch.float32)
        
        # åˆ›å»ºè¾¹ç‰¹å¾æ˜ å°„
        edge_feature_names = df_edge_features.columns.tolist()
        edge_feature_index_map = {name: idx for idx, name in enumerate(edge_feature_names)}
        
        # åˆ›å»ºç»Ÿä¸€çš„è¾¹å…³ç³»
        data['bus', 'connects', 'bus'].edge_index = edge_index
        data['bus', 'connects', 'bus'].edge_attr = edge_attr
        data['bus', 'connects', 'bus'].edge_feature_names = edge_feature_names
        data['bus', 'connects', 'bus'].edge_feature_index_map = edge_feature_index_map
        
        print(f"  ğŸ”— ('bus', 'connects', 'bus'): {edge_index.shape[1]} æ¡è¾¹ï¼Œç‰¹å¾ç»´åº¦: {edge_attr.shape[1]}")
        print(f"    - è¾¹ç‰¹å¾é¡ºåº: {edge_feature_names}")
        
        # --- 3. åˆ›å»ºæ— å‘å›¾ ---
        try:
            from torch_geometric.transforms import ToUndirected
            data = ToUndirected()(data)
            print("âœ… æˆåŠŸåˆ›å»ºæ— å‘ç®€åŒ–å¼‚æ„å›¾")
            print(f"  ğŸ”— æ— å‘åŒ–åè¾¹æ•°: {data['bus', 'connects', 'bus'].edge_index.shape[1]}")
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•ä½¿ç”¨ToUndirectedè½¬æ¢: {e}")

        return data

    def _extract_node_features(self, bus: np.ndarray, branch: np.ndarray, baseMVA: float) -> np.ndarray:
        """
        æå–èŠ‚ç‚¹ç‰¹å¾ (V2.0: ä¸å†è¿›è¡Œone-hotç¼–ç ï¼Œåªæå–æ•°å€¼ç‰¹å¾)
        
        å‚æ•°:
            bus: æ¯çº¿æ•°æ®çŸ©é˜µ
            branch: æ”¯è·¯æ•°æ®çŸ©é˜µ  
            baseMVA: åŸºå‡†åŠŸç‡
            
        è¿”å›:
            features: èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ [n_bus, n_features]
            
        ç‰¹å¾åŒ…æ‹¬:
            - æœ‰åŠŸ/æ— åŠŸè´Ÿè· (å½“å‰å€¼ï¼Œç”¨äºRLçŠ¶æ€è¡¨å¾)
            - å¹¶è”ç”µå¯¼/ç”µçº³
            - ç”µå‹è¿è¡ŒçŠ¶æ€å’Œçº¦æŸ
            - èŠ‚ç‚¹åº¦æ•°
            æ³¨ï¼šèŠ‚ç‚¹ç±»å‹å°†åœ¨åç»­é˜¶æ®µé€šè¿‡DataFrameçš„'type'åˆ—å•ç‹¬å¤„ç†
        """
        n_bus = bus.shape[0]
        
        # 1. è¿è¡ŒçŠ¶æ€ç‰¹å¾
        Pd_pu = bus[:, 2] / baseMVA
        Qd_pu = bus[:, 3] / baseMVA
        Gs = bus[:, 4]
        Bs = bus[:, 5]
        Vm = bus[:, 7]
        Va = np.deg2rad(bus[:, 8])
        
        # 2. ç”µå‹çº¦æŸ
        Vmax = bus[:, 11] if bus.shape[1] > 11 else np.ones(n_bus) * 1.1
        Vmin = bus[:, 12] if bus.shape[1] > 12 else np.ones(n_bus) * 0.9
        
        # 3. æ‹“æ‰‘ç‰¹å¾ï¼šè®¡ç®—èŠ‚ç‚¹åº¦æ•°
        from_idx = branch[:, 0].astype(int) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
        to_idx = branch[:, 1].astype(int) - 1
        degree = np.bincount(np.hstack([from_idx, to_idx]), minlength=n_bus)
        
        # 4. ç»„åˆæ‰€æœ‰æ•°å€¼ç‰¹å¾ (ä¸å†åŒ…å«one-hotç¼–ç çš„ç±»å‹ä¿¡æ¯)
        features = np.column_stack([
            Pd_pu, Qd_pu, Gs, Bs, Vm, Va, Vmax, Vmin, degree
        ])
        
        return features
    
    def _extract_edge_features(self, branch: np.ndarray, baseMVA: float) -> Tuple[np.ndarray, np.ndarray]:
        """
        æå–è¾¹ç‰¹å¾ (é€»è¾‘åŸºæœ¬ä¸å˜)
        
        å‚æ•°:
            branch: æ”¯è·¯æ•°æ®çŸ©é˜µ
            baseMVA: åŸºå‡†åŠŸç‡
            
        è¿”å›:
            features: è¾¹ç‰¹å¾çŸ©é˜µ [n_branch, n_features]
            edge_index: è¾¹ç´¢å¼•çŸ©é˜µ [n_branch, 2]
            
        ç‰¹å¾åŒ…æ‹¬:
            - ç”µé˜»ã€ç”µæŠ—ã€ç”µçº³
            - é˜»æŠ—æ¨¡é•¿ã€å¯¼çº³
            - è½½æµé™åˆ¶
            - ç›¸è§’å·®é™åˆ¶  
            - æ˜¯å¦ä¸ºå˜å‹å™¨
            - æ”¯è·¯è¿è¡ŒçŠ¶æ€
        """
        # 1. ç”µæ°”å‚æ•°
        r_raw = branch[:, 2]
        x_raw = branch[:, 3]
        b = branch[:, 4]

        # 2. å¤„ç†NaNå€¼
        valid_mask = ~np.isnan(r_raw) & ~np.isnan(x_raw)
        r_filled = np.nan_to_num(r_raw, nan=0.0)
        x_filled = np.nan_to_num(x_raw, nan=0.0)
        
        # 3. è®¡ç®—é˜»æŠ—æ¨¡é•¿å’Œå¯¼çº³
        z_mag_calc = np.sqrt(r_filled**2 + x_filled**2)
        z_magnitude = np.where(valid_mask, z_mag_calc, np.inf)
        y = np.where(np.isinf(z_magnitude), 0.0, 1.0 / (z_magnitude + 1e-10))
        
        # 4. è½½æµé™åˆ¶å’Œç›¸è§’çº¦æŸ
        rateA = branch[:, 5] / baseMVA
        angle_min = branch[:, 11] if branch.shape[1] > 11 else -np.pi * np.ones(len(branch))
        angle_max = branch[:, 12] if branch.shape[1] > 12 else np.pi * np.ones(len(branch))
        angle_diff = angle_max - angle_min
        
        # 5. å˜å‹å™¨æ ‡è¯†å’Œè¿è¡ŒçŠ¶æ€
        # æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„å˜å‹å™¨æŒ‡æ ‡
        tap_ratio = branch[:, 8]
        phase_shift = branch[:, 9] if branch.shape[1] > 9 else np.zeros(len(branch))
        
        # å˜å‹å™¨è¯†åˆ«ï¼štap_ratio != 1 æˆ– phase_shift != 0 æˆ– æ˜¾å¼å˜å‹å™¨æ ‡è®°
        is_transformer_tap = (tap_ratio != 1.0).astype(float)
        is_transformer_phase = (phase_shift != 0.0).astype(float)
        
        # å¦‚æœæœ‰æ˜¾å¼çš„å˜å‹å™¨æ ‡è®°åˆ—ï¼ˆcolumn[9]ï¼‰ï¼Œä½¿ç”¨å®ƒ
        if branch.shape[1] > 9:
            is_transformer_explicit = branch[:, 9].astype(float)
            is_transformer = np.maximum(np.maximum(is_transformer_tap, is_transformer_phase), is_transformer_explicit)
        else:
            is_transformer = np.maximum(is_transformer_tap, is_transformer_phase)
            
        status = branch[:, 10].astype(float) if branch.shape[1] > 10 else np.ones(len(branch))
        
        # 6. è¾¹ç´¢å¼• (è½¬æ¢ä¸º0-based)
        edge_index = np.column_stack([
            branch[:, 0].astype(int) - 1,
            branch[:, 1].astype(int) - 1
        ])
        
        # 7. ç»„åˆæ‰€æœ‰ç‰¹å¾
        features = np.column_stack([
            r_filled, x_filled, b, z_magnitude, y, rateA, angle_diff, is_transformer, status
        ])
        
        # 8. æœ€ç»ˆNaNæ£€æŸ¥å’Œå¤„ç†
        if np.any(np.isnan(features)):
            print("âš ï¸ è­¦å‘Šï¼šæ¸…ç†ç‰¹å¾çŸ©é˜µä¸­çš„NaNå€¼...")
            features = np.nan_to_num(features, nan=0.0, posinf=1e6, neginf=-1e6)
        
        return features, edge_index

    def _extract_generator_features(self, gen: np.ndarray, bus: np.ndarray, baseMVA: float) -> np.ndarray:
        """
        æå–å‘ç”µæœºç‰¹å¾å¹¶æ˜ å°„åˆ°èŠ‚ç‚¹ (é€»è¾‘åŸºæœ¬ä¸å˜)
        
        å‚æ•°:
            gen: å‘ç”µæœºæ•°æ®çŸ©é˜µ
            bus: æ¯çº¿æ•°æ®çŸ©é˜µ
            baseMVA: åŸºå‡†åŠŸç‡
            
        è¿”å›:
            features: å‘ç”µæœºç‰¹å¾çŸ©é˜µ [n_bus, n_gen_features]
            
        ç‰¹å¾åŒ…æ‹¬:
            - å½“å‰æœ‰åŠŸ/æ— åŠŸå‡ºåŠ› (ç”¨äºçŠ¶æ€è¡¨å¾)
            - æœ‰åŠŸå‘ç”µå®¹é‡ä¸Šä¸‹é™ (ç”¨äºçº¦æŸ)
            - å‘ç”µæœºæ ‡è¯†
        """
        n_bus = bus.shape[0]
        
        # 1. åˆå§‹åŒ–å‘ç”µæœºç‰¹å¾
        Pg = np.zeros(n_bus)
        Qg = np.zeros(n_bus)
        Pg_max = np.zeros(n_bus)
        Pg_min = np.zeros(n_bus)
        is_gen = np.zeros(n_bus)
        
        # 2. èšåˆæ¯ä¸ªèŠ‚ç‚¹çš„å‘ç”µæœºç‰¹å¾
        if len(gen) > 0:
            idx = gen[:, 0].astype(int) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
            # å½“å‰å‡ºåŠ› (ç”¨äºçŠ¶æ€è¡¨å¾)
            np.add.at(Pg, idx, gen[:, 1] / baseMVA)      # å½“å‰æœ‰åŠŸå‡ºåŠ›
            np.add.at(Qg, idx, gen[:, 2] / baseMVA)      # å½“å‰æ— åŠŸå‡ºåŠ›
            # å®¹é‡çº¦æŸ (ç”¨äºå¯è¡ŒåŸŸçº¦æŸ)
            np.add.at(Pg_max, idx, gen[:, 8] / baseMVA)  # æœ‰åŠŸå®¹é‡ä¸Šé™
            np.add.at(Pg_min, idx, gen[:, 9] / baseMVA)  # æœ‰åŠŸå®¹é‡ä¸‹é™
            is_gen[idx] = 1.0
        
        return np.column_stack([Pg, Qg, Pg_max, Pg_min, is_gen])
    
    def _normalize_features(self, features: np.ndarray, feature_type: str) -> np.ndarray:
        """
        æ ‡å‡†åŒ–ç‰¹å¾ (é€»è¾‘åŸºæœ¬ä¸å˜)
        
        å‚æ•°:
            features: ç‰¹å¾çŸ©é˜µ
            feature_type: ç‰¹å¾ç±»å‹ ('node' æˆ– 'edge')
            
        è¿”å›:
            normalized_features: æ ‡å‡†åŒ–åçš„ç‰¹å¾çŸ©é˜µ
        """
        # å¤„ç†infå€¼
        if np.any(np.isinf(features)):
            features = np.nan_to_num(features, nan=0.0, posinf=1e6, neginf=-1e6)

        scaler_attr = f"{feature_type}_scaler"
        if getattr(self, scaler_attr) is None:
            scaler = RobustScaler()
            setattr(self, scaler_attr, scaler)
            return scaler.fit_transform(features)
        else:
            return getattr(self, scaler_attr).transform(features)

    # å‘åå…¼å®¹æ–¹æ³•
    def process_matpower_data(self, mpc: Dict) -> Tuple[float, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """
        å‘åå…¼å®¹çš„æ–¹æ³•ï¼Œç°åœ¨è°ƒç”¨ç§æœ‰çš„_process_matpower_dataæ–¹æ³•
        """
        print("âš ï¸ æç¤ºï¼šprocess_matpower_dataç°åœ¨ä½¿ç”¨ç®€åŒ–å¼‚æ„å›¾å®ç°")
        return self._process_matpower_data(mpc)
    
    def create_pyg_hetero_data(self, df_nodes: pd.DataFrame, df_edges: pd.DataFrame, 
                               df_edge_features: pd.DataFrame) -> HeteroData:
        """
        å‘åå…¼å®¹çš„æ–¹æ³•ï¼Œç°åœ¨è°ƒç”¨ç®€åŒ–çš„å¼‚æ„å›¾åˆ›å»ºæ–¹æ³•
        """
        print("âš ï¸ æç¤ºï¼šcreate_pyg_hetero_dataç°åœ¨ä½¿ç”¨ç®€åŒ–å¼‚æ„å›¾å®ç°")
        return self._create_simplified_hetero_data(df_nodes, df_edges, df_edge_features)

    def create_pyg_data(self, df_nodes: pd.DataFrame, df_edges: pd.DataFrame, 
                       df_edge_features: pd.DataFrame):
        """
        å‘åå…¼å®¹çš„æ–¹æ³•ï¼Œç°åœ¨é‡å®šå‘åˆ°ç®€åŒ–å¼‚æ„å›¾åˆ›å»º
        """
        print("âš ï¸ æç¤ºï¼šcreate_pyg_dataç°åœ¨ä½¿ç”¨ç®€åŒ–å¼‚æ„å›¾å®ç°")
        return self._create_simplified_hetero_data(df_nodes, df_edges, df_edge_features)

