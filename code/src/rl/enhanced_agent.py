#!/usr/bin/env python3
"""
Enhanced PPO Agent with Action Embedding Support

åŸºäºåŠ¨ä½œåµŒå…¥çš„PPOæ™ºèƒ½ä½“å®ç°ï¼Œæ”¯æŒï¼š
- åŒå¡”æ¶æ„ï¼ˆçŠ¶æ€å¡”+åŠ¨ä½œå¡”ï¼‰
- åŠ¨æ€Kå€¼æ”¯æŒ
- è¿é€šæ€§ç¡¬çº¦æŸ
- é«˜æ•ˆçš„åŠ¨ä½œé€‰æ‹©æµç¨‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
import logging
from dataclasses import dataclass

from .agent import PPOAgent, BatchedState
from models.partition_encoder import PartitionEncoder, create_partition_encoder
from models.actor_network import EnhancedActorNetwork, create_actor_network

logger = logging.getLogger(__name__)


class EnhancedPPOAgent(PPOAgent):
    """
    å¢å¼ºçš„PPOæ™ºèƒ½ä½“ - æ”¯æŒåŠ¨ä½œåµŒå…¥
    
    ç»§æ‰¿è‡ªåŸPPOAgentï¼Œé‡å†™å…³é”®æ–¹æ³•ä»¥æ”¯æŒåŒå¡”æ¶æ„
    """
    
    def __init__(self,
                 state_dim: int,
                 num_partitions: int,
                 config: Dict[str, Any],
                 device: str = 'auto'):
        """
        åˆå§‹åŒ–å¢å¼ºçš„PPOæ™ºèƒ½ä½“

        Args:
            state_dim: çŠ¶æ€ç»´åº¦
            num_partitions: åˆå§‹åˆ†åŒºæ•°
            config: é…ç½®å­—å…¸ï¼Œéœ€åŒ…å«:
                - node_dim: èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
                - edge_dim: è¾¹ç‰¹å¾ç»´åº¦
                - gnn_hidden: GNNéšè—å±‚ç»´åº¦
                - strategy_vector_dim: ç­–ç•¥å‘é‡ç»´åº¦
                - partition_encoder: åˆ†åŒºç¼–ç å™¨é…ç½®
                - use_two_tower: æ˜¯å¦ä½¿ç”¨åŒå¡”æ¶æ„
            device: è®¡ç®—è®¾å¤‡
        """
        # ã€ä¿®å¤ã€‘ä»é…ç½®ä¸­è·å–æ­£ç¡®çš„ç»´åº¦ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä»state_dimæ¨æ–­
        # state_dimæ˜¯çŠ¶æ€å‘é‡çš„ç»´åº¦ï¼Œä¸ç­‰äºåµŒå…¥ç»´åº¦
        node_embedding_dim = config.get('node_embedding_dim', 128)  # èŠ‚ç‚¹åµŒå…¥ç»´åº¦
        region_embedding_dim = config.get('region_embedding_dim', 256)  # åŒºåŸŸåµŒå…¥ç»´åº¦
        
        # å¤„ç†è®¾å¤‡å‚æ•°
        if isinstance(device, str):
            if device == 'auto':
                device_obj = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            else:
                device_obj = torch.device(device)
        else:
            device_obj = device
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼Œä¼ é€’æ­£ç¡®çš„å‚æ•°
        super().__init__(
            node_embedding_dim=node_embedding_dim,
            region_embedding_dim=region_embedding_dim,
            num_partitions=num_partitions,
            agent_config=config,  # ä¼ é€’æ•´ä¸ªconfigä½œä¸ºagent_config
            device=device_obj
        )
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åŒå¡”æ¶æ„
        self.use_two_tower = config.get('use_two_tower', True)

        # ã€è°ƒè¯•ã€‘æ‰“å°ç»´åº¦ä¿¡æ¯
        print(f"ğŸ”§ EnhancedPPOAgentç»´åº¦é…ç½®:")
        print(f"   node_embedding_dim: {self.node_embedding_dim}")
        print(f"   region_embedding_dim: {self.region_embedding_dim}")
        print(f"   state_dim: {state_dim}")
        print(f"   num_partitions: {self.num_partitions}")
        
        if self.use_two_tower:
            # ç­–ç•¥å‘é‡ç»´åº¦
            self.strategy_vector_dim = config.get('strategy_vector_dim', 128)
            
            # æ›¿æ¢actorç½‘ç»œä¸ºå¢å¼ºç‰ˆæœ¬
            self.actor = create_actor_network({
                'node_embedding_dim': self.node_embedding_dim,
                'region_embedding_dim': self.region_embedding_dim,
                'strategy_vector_dim': self.strategy_vector_dim,
                'hidden_dim': config.get('actor_hidden_dim', 256),
                'dropout': config.get('dropout', 0.1),

            }, use_two_tower=True).to(self.device)
            
            # åˆ›å»ºåˆ†åŒºç¼–ç å™¨
            partition_encoder_config = config.get('partition_encoder', {})
            partition_encoder_config['embedding_dim'] = self.strategy_vector_dim
            self.partition_encoder = create_partition_encoder(
                partition_encoder_config
            ).to(self.device)
            
            # é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨ä»¥åŒ…å«æ–°å‚æ•°
            # ä¿æŒä¸çˆ¶ç±»ä¸€è‡´çš„ä¼˜åŒ–å™¨å‘½å
            lr = config.get('lr', 3e-4)
            self.actor_optimizer = torch.optim.Adam([
                {'params': self.actor.parameters()},
                {'params': self.partition_encoder.parameters()}
            ], lr=lr)
            self.critic_optimizer = torch.optim.Adam(
                self.critic.parameters(), lr=lr
            )
            
            logger.info("EnhancedPPOAgent initialized with two-tower architecture")
        else:
            logger.info("EnhancedPPOAgent using standard architecture")
    
    def select_action(self,
                     state: Dict[str, torch.Tensor],
                     training: bool = True,
                     return_embeddings: bool = False) -> Tuple[Optional[Tuple[int, int]], float, float, Optional[Dict]]:
        """
        ä½¿ç”¨åŠ¨ä½œåµŒå…¥æœºåˆ¶é€‰æ‹©åŠ¨ä½œ
        
        Args:
            state: çŠ¶æ€å­—å…¸ï¼Œéœ€åŒ…å«:
                - available_partitions: æ¯ä¸ªèŠ‚ç‚¹çš„å¯ç”¨åˆ†åŒºä¿¡æ¯
                - partition_features: åˆ†åŒºç‰¹å¾ä¿¡æ¯
            training: æ˜¯å¦å¤„äºè®­ç»ƒæ¨¡å¼
            return_embeddings: æ˜¯å¦è¿”å›åµŒå…¥å‘é‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        
        Returns:
            action: é€‰æ‹©çš„åŠ¨ä½œ (node_idx, partition_idx)
            log_prob: åŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡
            value: çŠ¶æ€ä»·å€¼ä¼°è®¡
            embeddings: åµŒå…¥ä¿¡æ¯ï¼ˆå¦‚æœreturn_embeddings=Trueï¼‰
        """
        # å¢å¼ºæ™ºèƒ½ä½“å§‹ç»ˆä½¿ç”¨åŒå¡”æ¶æ„
        
        with torch.no_grad():
            # 1. å‡†å¤‡æ‰¹å¤„ç†çŠ¶æ€
            batched_state = self._prepare_batched_state([state])
            
            # 2. è·å–ä»·å€¼ä¼°è®¡
            value = self.critic(batched_state).item()
            
            # 3. æ£€æŸ¥è¾¹ç•ŒèŠ‚ç‚¹
            if batched_state.boundary_nodes.numel() == 0:
                return None, 0.0, value, None
            
            # 4. è·å–èŠ‚ç‚¹logitså’Œç­–ç•¥å‘é‡
            node_logits, strategy_vectors = self.actor(batched_state)
            
            # 5. èŠ‚ç‚¹é€‰æ‹©
            # è·å–æ¯ä¸ªè¾¹ç•ŒèŠ‚ç‚¹æ˜¯å¦æœ‰æœ‰æ•ˆåˆ†åŒº
            boundary_mask = batched_state.action_mask[batched_state.boundary_nodes]
            valid_node_mask = boundary_mask.any(dim=1)
            node_logits = node_logits.masked_fill(~valid_node_mask, -1e9)
            
            if training:
                node_probs = F.softmax(node_logits, dim=0)
                node_dist = torch.distributions.Categorical(probs=node_probs)
                node_action_idx = node_dist.sample()
            else:
                node_action_idx = torch.argmax(node_logits)
            
            # 6. è·å–é€‰ä¸­èŠ‚ç‚¹çš„ç­–ç•¥å‘é‡
            selected_strategy_vector = strategy_vectors[node_action_idx]
            selected_node = batched_state.boundary_nodes[node_action_idx].item()
            
            # 7. è·å–è¯¥èŠ‚ç‚¹çš„å¯ç”¨åˆ†åŒºä¿¡æ¯
            available_partitions = self._get_available_partitions(
                state, selected_node, batched_state
            )
            
            if not available_partitions:
                # å¦‚æœæ²¡æœ‰è¿é€šæ€§å®‰å…¨çš„åˆ†åŒºï¼Œä½¿ç”¨è½¯çº¦æŸå›é€€
                logger.warning(f"No available partitions for node {selected_node}")
                # å›é€€åˆ°æ‰€æœ‰ç›¸é‚»åˆ†åŒºï¼ˆè½¯çº¦æŸæ¨¡å¼ï¼‰
                available_partitions = self._get_fallback_partitions(
                    state, selected_node, batched_state
                )

                if not available_partitions:
                    # å¦‚æœä»ç„¶æ²¡æœ‰åˆ†åŒºï¼Œè¿”å›None
                    return None, 0.0, value, None
            
            # 8. ç¼–ç å¯ç”¨åˆ†åŒº
            partition_embeddings = self._encode_partitions(
                state, available_partitions
            )
            
            # 9. è®¡ç®—ç›¸ä¼¼åº¦å¹¶é€‰æ‹©åˆ†åŒº
            similarities = self.partition_encoder.compute_similarity(
                selected_strategy_vector,
                partition_embeddings,
                temperature=1.0  # å¯ä»¥ä»configä¸­è·å–
            )
            
            # 10. åŸºäºç›¸ä¼¼åº¦é€‰æ‹©åˆ†åŒº
            if training:
                partition_probs = F.softmax(similarities, dim=0)
                partition_dist = torch.distributions.Categorical(probs=partition_probs)
                partition_idx = partition_dist.sample()
                
                # è®¡ç®—æ€»çš„log_prob
                node_log_prob = node_dist.log_prob(node_action_idx)
                partition_log_prob = partition_dist.log_prob(partition_idx)
                log_prob = (node_log_prob + partition_log_prob).item()
            else:
                partition_idx = torch.argmax(similarities)
                log_prob = 0.0
            
            # 11. è½¬æ¢ä¸ºå®é™…çš„åˆ†åŒºID
            selected_partition = available_partitions[partition_idx.item()]

            # ç¡®ä¿åˆ†åŒºIDæ˜¯æ•´æ•°è€Œä¸æ˜¯å¼ é‡
            if isinstance(selected_partition, torch.Tensor):
                selected_partition = selected_partition.item()

            action = (selected_node, selected_partition)
            
            # å‡†å¤‡è¿”å›çš„åµŒå…¥ä¿¡æ¯
            embeddings = None
            if return_embeddings:
                embeddings = {
                    'strategy_vector': selected_strategy_vector.cpu().numpy(),
                    'partition_embeddings': partition_embeddings.cpu().numpy(),
                    'similarities': similarities.cpu().numpy(),
                    'node_logits': node_logits.cpu().numpy()
                }
            
            return action, log_prob, value, embeddings
    
    def _get_available_partitions(self, 
                                 state: Dict,
                                 node_id: int,
                                 batched_state: BatchedState) -> List[int]:
        """
        è·å–èŠ‚ç‚¹çš„å¯ç”¨åˆ†åŒºåˆ—è¡¨ï¼ˆç¡®ä¿è¿é€šæ€§ï¼‰
        
        Args:
            state: åŸå§‹çŠ¶æ€å­—å…¸
            node_id: èŠ‚ç‚¹ID
            batched_state: æ‰¹å¤„ç†çŠ¶æ€
        
        Returns:
            å¯ç”¨åˆ†åŒºIDåˆ—è¡¨
        """
        # ä»ç¯å¢ƒæä¾›çš„ä¿¡æ¯ä¸­è·å–
        if 'connectivity_safe_partitions' in state:
            node_safe_partitions = state['connectivity_safe_partitions'].get(node_id, [])
            return node_safe_partitions
        
        # ä½¿ç”¨action_mask
        if hasattr(batched_state, 'action_mask'):
            # æ‰¾åˆ°èŠ‚ç‚¹åœ¨boundary_nodesä¸­çš„ä½ç½®
            node_positions = (batched_state.boundary_nodes == node_id).nonzero(as_tuple=True)[0]
            if len(node_positions) > 0:
                node_pos = node_positions[0]
                # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨node_idä½œä¸ºaction_maskçš„ç´¢å¼•ï¼Œè€Œä¸æ˜¯boundary_nodes[node_pos]
                # å› ä¸ºaction_maskçš„ç¬¬ä¸€ç»´æ˜¯æŒ‰èŠ‚ç‚¹IDæ’åˆ—çš„ï¼Œä¸æ˜¯æŒ‰boundary_nodesä½ç½®æ’åˆ—çš„
                if node_id < batched_state.action_mask.size(0):
                    mask = batched_state.action_mask[node_id]
                    available = torch.where(mask)[0].cpu().tolist()
                    return [p + 1 for p in available]  # è½¬æ¢ä¸º1-indexed
                else:
                    logger.warning(f"èŠ‚ç‚¹ID {node_id} è¶…å‡ºaction_maskèŒƒå›´ {batched_state.action_mask.size(0)}")
                    return []
        
        # é»˜è®¤è¿”å›æ‰€æœ‰åˆ†åŒº
        return list(range(1, self.num_partitions + 1))
    
    def _encode_partitions(self, 
                          state: Dict,
                          partition_ids: List[int]) -> torch.Tensor:
        """
        ç¼–ç åˆ†åŒºç‰¹å¾
        
        Args:
            state: çŠ¶æ€å­—å…¸ï¼Œéœ€åŒ…å«partition_info
            partition_ids: è¦ç¼–ç çš„åˆ†åŒºIDåˆ—è¡¨
        
        Returns:
            åˆ†åŒºåµŒå…¥çŸ©é˜µ [num_partitions, embedding_dim]
        """
        # ä»çŠ¶æ€ä¸­è·å–åˆ†åŒºä¿¡æ¯
        partition_info = state.get('partition_info', {})
        grid_info = state.get('grid_info', {})
        
        # å‡†å¤‡åˆ†åŒºç‰¹å¾
        partitions_data = []
        for pid in partition_ids:
            if pid in partition_info:
                partitions_data.append(partition_info[pid])
            else:
                # åˆ›å»ºé»˜è®¤ç‰¹å¾
                partitions_data.append({
                    'nodes': [],
                    'load': 0.0,
                    'generation': 0.0,
                    'internal_edges': 0,
                    'boundary_nodes': 0
                })
        
        # ä½¿ç”¨åˆ†åŒºç¼–ç å™¨ç¼–ç 
        embeddings = self.partition_encoder.encode_partitions(
            partitions_data,
            grid_info,
            self.device
        )
        
        return embeddings
    
    def update_partition_cache(self, 
                             partition_changes: Dict[int, List[int]]):
        """
        æ›´æ–°åˆ†åŒºç¼“å­˜ï¼ˆå½“åˆ†åŒºå‘ç”Ÿå˜åŒ–æ—¶ï¼‰
        
        Args:
            partition_changes: å˜åŒ–çš„åˆ†åŒº {partition_id: affected_nodes}
        """
        if hasattr(self.partition_encoder, 'invalidate_cache'):
            self.partition_encoder.invalidate_cache(list(partition_changes.keys()))
    
    def get_strategy_vector(self, 
                           state: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        è·å–å½“å‰çŠ¶æ€çš„ç­–ç•¥å‘é‡ï¼ˆç”¨äºåˆ†æï¼‰
        
        Args:
            state: çŠ¶æ€è§‚å¯Ÿ
        
        Returns:
            æ‰€æœ‰è¾¹ç•ŒèŠ‚ç‚¹çš„ç­–ç•¥å‘é‡ [num_boundary_nodes, strategy_vector_dim]
        """
        if not self.use_two_tower:
            raise ValueError("Strategy vector only available in two-tower mode")
        
        with torch.no_grad():
            batched_state = self._prepare_batched_state([state])
            _, strategy_vectors = self.actor(batched_state)
            return strategy_vectors


def create_enhanced_agent(state_dim: int,
                         num_partitions: int,
                         config: Dict[str, Any],
                         device: str = 'auto') -> EnhancedPPOAgent:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå¢å¼ºPPOæ™ºèƒ½ä½“

    Args:
        state_dim: çŠ¶æ€ç»´åº¦
        num_partitions: åˆ†åŒºæ•°
        config: é…ç½®å­—å…¸
        device: è®¾å¤‡

    Returns:
        å¢å¼ºPPOæ™ºèƒ½ä½“å®ä¾‹
    """
    return EnhancedPPOAgent(state_dim, num_partitions, config, device)