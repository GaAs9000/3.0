#!/usr/bin/env python3
"""
Enhanced Power Grid Partitioning Environment

å¢å¼ºçš„ç”µç½‘åˆ†åŒºç¯å¢ƒï¼Œæ”¯æŒï¼š
- åŠ¨æ€Kå€¼
- è¿é€šæ€§ä¿è¯çš„åŠ¨ä½œç©ºé—´
- åˆ†åŒºç‰¹å¾è®¡ç®—å’Œç¼“å­˜
- ä¸åŒå¡”æ¶æ„çš„æ— ç¼é›†æˆ
"""

import torch
import numpy as np
from typing import Dict, Tuple, List, Optional, Union, Any, Set
from torch_geometric.data import HeteroData
import networkx as nx
from collections import defaultdict
import logging

from .environment import PowerGridPartitioningEnv
from .state import StateManager
from .action_space import ActionSpace
from .decision_context import AbstractDecisionContext, materialize_decision_context

logger = logging.getLogger(__name__)


class EnhancedPowerGridPartitioningEnv(PowerGridPartitioningEnv):
    """
    å¢å¼ºçš„ç”µç½‘åˆ†åŒºç¯å¢ƒ
    
    æ‰©å±•åŸç¯å¢ƒä»¥æ”¯æŒï¼š
    1. è¿é€šæ€§ä¿è¯çš„åŠ¨ä½œæŸ¥è¯¢
    2. åˆ†åŒºç‰¹å¾è®¡ç®—
    3. åŠ¨æ€Kå€¼æ”¯æŒ
    4. é«˜æ•ˆçš„å¢é‡æ›´æ–°
    """
    
    def __init__(self, *args, enable_features_cache: bool = True, **kwargs):
        """
        åˆå§‹åŒ–å¢å¼ºç¯å¢ƒ
        
        Args:
            *args: ä¼ é€’ç»™çˆ¶ç±»çš„å‚æ•°
            enable_features_cache: æ˜¯å¦å¯ç”¨åˆ†åŒºç‰¹å¾ç¼“å­˜
            **kwargs: ä¼ é€’ç»™çˆ¶ç±»çš„å…³é”®å­—å‚æ•°
        """
        super().__init__(*args, **kwargs)
        
        # åˆå§‹åŒ–å¢å¼ºåŠŸèƒ½
        self.enable_features_cache = enable_features_cache
        self.partition_features_cache = {}
        self.connectivity_cache = {}
        
        # æ„å»ºNetworkXå›¾ç”¨äºè¿é€šæ€§æ£€æŸ¥
        self._build_nx_graph()
        
        # åˆå§‹åŒ–åˆ†åŒºä¿¡æ¯
        self._update_partition_info()
        
        logger.info("EnhancedPowerGridPartitioningEnv initialized")
    
    def _build_nx_graph(self):
        """æ„å»ºNetworkXå›¾ç”¨äºé«˜æ•ˆçš„è¿é€šæ€§æ£€æŸ¥"""
        self.nx_graph = nx.Graph()
        
        # æ·»åŠ èŠ‚ç‚¹
        num_nodes = self.hetero_data['bus'].x.size(0)
        self.nx_graph.add_nodes_from(range(num_nodes))
        
        # æ·»åŠ è¾¹ï¼ˆä»å¼‚æ„å›¾çš„è¾¹ç´¢å¼•ï¼‰
        edge_index = self.hetero_data['bus', 'connects', 'bus'].edge_index
        
        # è¿‡æ»¤æ— æ•ˆè¾¹ç´¢å¼•
        valid_mask = (edge_index[0] < num_nodes) & (edge_index[1] < num_nodes) & (edge_index[0] >= 0) & (edge_index[1] >= 0)
        invalid_count = (~valid_mask).sum().item()
        if invalid_count > 0:
            logger.warning(f"Filtered {invalid_count} invalid edges (out of range [0,{num_nodes-1}])")
            edge_index = edge_index[:, valid_mask]
        
        edges = edge_index.t().cpu().numpy()  # ä½¿ç”¨è¿‡æ»¤åçš„edge_index
        self.nx_graph.add_edges_from(edges)
        
        logger.info(f"Built NetworkX graph with {num_nodes} nodes and {len(edges)} edges")
    
    def get_connectivity_safe_partitions(self, node_id: int) -> List[int]:
        """
        è·å–èŠ‚ç‚¹å¯ä»¥ç§»åŠ¨åˆ°çš„æ‰€æœ‰ä¿è¯è¿é€šæ€§çš„åˆ†åŒº

        Args:
            node_id: è¾¹ç•ŒèŠ‚ç‚¹ID

        Returns:
            å¯ä»¥å®‰å…¨ç§»åŠ¨åˆ°çš„åˆ†åŒºIDåˆ—è¡¨
        """
        # ç¡®ä¿node_idæ˜¯æ­£ç¡®çš„ç±»å‹
        node_id_int = int(node_id.item()) if torch.is_tensor(node_id) else int(node_id)

        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥èŠ‚ç‚¹IDæ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼Œå¹¶å¤„ç†ç´¢å¼•åç§»
        max_nodes = self.state_manager.current_partition.size(0)
        if node_id_int >= max_nodes:
            # å¦‚æœèŠ‚ç‚¹IDä»1å¼€å§‹ï¼Œè½¬æ¢ä¸ºä»0å¼€å§‹çš„ç´¢å¼•
            node_idx = node_id_int - 1
            if node_idx < 0 or node_idx >= max_nodes:
                # å¦‚æœä»ç„¶è¶Šç•Œï¼Œè¿”å›ç©ºåˆ—è¡¨
                return []
        else:
            # èŠ‚ç‚¹IDå·²ç»æ˜¯ä»0å¼€å§‹çš„ç´¢å¼•
            node_idx = node_id_int

        # ä½¿ç”¨æ›´é«˜æ•ˆçš„ç¼“å­˜é”®ï¼šåªåŒ…å«èŠ‚ç‚¹IDå’Œå…¶å½“å‰åˆ†åŒº
        current_assignment = self.state_manager.current_partition[node_idx]

        # è·å–èŠ‚ç‚¹çš„é‚»å±…åˆ†åŒºï¼ˆè¿™æ˜¯å¿…è¦çš„è®¡ç®—ï¼‰
        # ä¿®å¤ç´¢å¼•åç§»é—®é¢˜
        max_node_id = max(self.nx_graph.nodes()) if self.nx_graph.nodes() else 0
        if node_id_int > max_node_id:
            logger.warning(f"Node {node_id_int} exceeds graph range [0,{max_node_id}], mapping to valid range")
            node_id_int = node_id_int % (max_node_id + 1)
        
        try:
            neighbors = list(self.nx_graph.neighbors(node_id_int))
        except Exception as e:
            logger.warning(f"Failed to get neighbors for node {node_id_int}: {e}. Graph has {len(self.nx_graph.nodes())} nodes (0-{max(self.nx_graph.nodes()) if self.nx_graph.nodes() else 0})")
            # å›é€€ï¼šè¿”å›é™¤å½“å‰åˆ†åŒºå¤–çš„æ‰€æœ‰åˆ†åŒº
            num_partitions = int(self.state_manager.current_partition.max().item())
            return [p for p in range(1, num_partitions + 1) if p != current_assignment]

        neighbor_partitions = set()
        for neighbor in neighbors:
            # ğŸ”§ ä¿®å¤ï¼šå¤„ç†é‚»å±…èŠ‚ç‚¹çš„ç´¢å¼•åç§»
            max_nodes = self.state_manager.current_partition.size(0)
            if neighbor >= max_nodes:
                # å¦‚æœé‚»å±…èŠ‚ç‚¹IDä»1å¼€å§‹ï¼Œè½¬æ¢ä¸ºä»0å¼€å§‹çš„ç´¢å¼•
                neighbor_idx = neighbor - 1
                if neighbor_idx < 0 or neighbor_idx >= max_nodes:
                    continue  # è·³è¿‡æ— æ•ˆçš„é‚»å±…èŠ‚ç‚¹
            else:
                # é‚»å±…èŠ‚ç‚¹IDå·²ç»æ˜¯ä»0å¼€å§‹çš„ç´¢å¼•
                neighbor_idx = neighbor

            partition = self.state_manager.current_partition[neighbor_idx].item()
            if partition != current_assignment and partition > 0:
                neighbor_partitions.add(partition)

        # å¦‚æœæ²¡æœ‰é‚»å±…åˆ†åŒºï¼Œè¿”å›æ‰€æœ‰å…¶ä»–åˆ†åŒºï¼ˆç®€åŒ–å¤„ç†ï¼‰
        if not neighbor_partitions:
            num_partitions = int(self.state_manager.current_partition.max().item())
            return [p for p in range(1, num_partitions + 1) if p != current_assignment]

        # å¯¹æ¯ä¸ªé‚»å±…åˆ†åŒºè¿›è¡Œè¿é€šæ€§æµ‹è¯•
        safe_partitions = []
        for target_partition in neighbor_partitions:
            # åˆ›å»ºé’ˆå¯¹ç‰¹å®šç§»åŠ¨çš„ç¼“å­˜é”®
            move_key = (node_id_int, current_assignment, target_partition,
                       self.state_manager.current_step)  # ä½¿ç”¨stepä½œä¸ºç‰ˆæœ¬å·

            if move_key in self.connectivity_cache:
                if self.connectivity_cache[move_key]:
                    safe_partitions.append(target_partition)
            else:
                # æ¨¡æ‹ŸèŠ‚ç‚¹ç§»åŠ¨è¿›è¡Œè¿é€šæ€§éªŒè¯
                test_partition = self.state_manager.current_partition.clone()
                test_partition[node_id_int] = target_partition

                # æ£€æŸ¥è¿é€šæ€§
                is_safe = self._check_partition_connectivity(test_partition)
                self.connectivity_cache[move_key] = is_safe

                if is_safe:
                    safe_partitions.append(target_partition)

        # å¦‚æœæ²¡æœ‰å®‰å…¨åˆ†åŒºï¼Œè‡³å°‘è¿”å›ä¸€ä¸ªé‚»å±…åˆ†åŒºï¼ˆé™çº§å¤„ç†ï¼‰
        if not safe_partitions and neighbor_partitions:
            safe_partitions = [list(neighbor_partitions)[0]]

        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.connectivity_cache) > 10000:
            # æ¸…ç†æ—§çš„ç¼“å­˜æ¡ç›®
            self.connectivity_cache.clear()

        return safe_partitions
    
    def _check_partition_connectivity(self, partition: Dict[int, int]) -> bool:
        """
        æ£€æŸ¥åˆ†åŒºæ–¹æ¡ˆæ˜¯å¦ä¿æŒæ‰€æœ‰åˆ†åŒºçš„è¿é€šæ€§
        
        Args:
            partition: åˆ†åŒºåˆ†é… {node_id: partition_id}
        
        Returns:
            æ˜¯å¦æ‰€æœ‰åˆ†åŒºéƒ½æ˜¯è¿é€šçš„
        """
        # æŒ‰åˆ†åŒºåˆ†ç»„èŠ‚ç‚¹
        partition_nodes = defaultdict(set)
        # å¤„ç†å¼ é‡ç±»å‹çš„partition
        if torch.is_tensor(partition):
            for node in range(len(partition)):
                pid = partition[node].item()
                if pid > 0:  # å¿½ç•¥æœªåˆ†é…çš„èŠ‚ç‚¹
                    partition_nodes[pid].add(node)
        else:
            # å¤„ç†å­—å…¸ç±»å‹çš„partition
            for node, pid in partition.items():
                if pid > 0:  # å¿½ç•¥æœªåˆ†é…çš„èŠ‚ç‚¹
                    partition_nodes[pid].add(node)
        
        # æ£€æŸ¥æ¯ä¸ªåˆ†åŒºçš„è¿é€šæ€§
        for pid, nodes in partition_nodes.items():
            if not self._is_connected_subgraph(nodes):
                return False
        
        return True
    
    def _is_connected_subgraph(self, nodes: Set[int]) -> bool:
        """
        æ£€æŸ¥èŠ‚ç‚¹é›†åˆæ˜¯å¦å½¢æˆè¿é€šå­å›¾
        
        Args:
            nodes: èŠ‚ç‚¹é›†åˆ
        
        Returns:
            æ˜¯å¦è¿é€š
        """
        if not nodes:
            return True
        
        # ä½¿ç”¨BFSæ£€æŸ¥è¿é€šæ€§
        subgraph = self.nx_graph.subgraph(nodes)
        return nx.is_connected(subgraph)
    
    def get_partition_features(self, partition_id: int) -> Dict[str, float]:
        """
        è®¡ç®—åˆ†åŒºçš„ç‰¹å¾
        
        Args:
            partition_id: åˆ†åŒºID
        
        Returns:
            åˆ†åŒºç‰¹å¾å­—å…¸
        """
        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿partition_idæ˜¯å•ä¸ªå€¼è€Œä¸æ˜¯list
        if isinstance(partition_id, (list, tuple)):
            if len(partition_id) == 0:
                return self._empty_partition_features()
            partition_id = partition_id[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
        elif isinstance(partition_id, torch.Tensor):
            partition_id = partition_id.item()

        # æ£€æŸ¥ç¼“å­˜
        if self.enable_features_cache and partition_id in self.partition_features_cache:
            return self.partition_features_cache[partition_id]
        
        # è·å–åˆ†åŒºèŠ‚ç‚¹
        # current_partitionæ˜¯ä¸€ä¸ªå¼ é‡ï¼Œéœ€è¦ä½¿ç”¨å¼ é‡æ“ä½œ
        mask = (self.state_manager.current_partition == partition_id)
        partition_nodes = torch.where(mask)[0].cpu().tolist()
        
        if not partition_nodes:
            return self._empty_partition_features()
        
        # è®¡ç®—ç‰¹å¾
        features = self._compute_partition_features(partition_nodes, partition_id)
        
        # ç¼“å­˜ç»“æœ
        if self.enable_features_cache:
            self.partition_features_cache[partition_id] = features
        
        return features
    
    def _compute_partition_features(self, nodes: List[int], partition_id: int) -> Dict[str, float]:
        """
        è®¡ç®—åˆ†åŒºçš„è¯¦ç»†ç‰¹å¾
        
        Args:
            nodes: åˆ†åŒºä¸­çš„èŠ‚ç‚¹åˆ—è¡¨
            partition_id: åˆ†åŒºID
        
        Returns:
            ç‰¹å¾å­—å…¸
        """
        # åŸºç¡€ç»Ÿè®¡
        num_nodes = len(nodes)
        total_nodes = self.hetero_data['bus'].x.size(0)
        
        # è´Ÿè·å’Œå‘ç”µä¿¡æ¯
        node_features = self.hetero_data['bus'].x[nodes]
        total_load = node_features[:, 2].sum().item()  # PD
        total_generation = 0.0
        
        # ä»genæ•°æ®ä¸­è·å–å‘ç”µä¿¡æ¯
        if 'gen' in self.hetero_data:
            gen_buses = self.hetero_data['gen'].bus_idx
            gen_powers = self.hetero_data['gen'].x[:, 0]  # PG
            for i, bus in enumerate(gen_buses):
                if bus.item() in nodes:
                    total_generation += gen_powers[i].item()
        
        # å†…éƒ¨è¾¹æ•°
        internal_edges = 0
        edge_index = self.hetero_data['bus', 'connects', 'bus'].edge_index
        for i in range(edge_index.size(1)):
            src, dst = edge_index[0, i].item(), edge_index[1, i].item()
            if src in nodes and dst in nodes:
                internal_edges += 1
        internal_edges //= 2  # æ— å‘å›¾ï¼Œæ¯æ¡è¾¹è®¡ç®—äº†ä¸¤æ¬¡
        
        # è¾¹ç•ŒèŠ‚ç‚¹æ•°
        boundary_nodes = 0
        for node in nodes:
            # ç¡®ä¿nodeæ˜¯Python intç±»å‹ï¼Œç”¨äºNetworkXæ¥å£
            node_int = int(node) if not isinstance(node, int) else node
            neighbors = list(self.nx_graph.neighbors(node_int))
            for neighbor in neighbors:
                if neighbor < len(self.state_manager.current_partition):
                    if self.state_manager.current_partition[neighbor].item() != partition_id:
                        boundary_nodes += 1
                        break
        
        # è®¡ç®—æ¯”ç‡
        size_ratio = num_nodes / total_nodes if total_nodes > 0 else 0
        
        # è·å–å…¨å±€ç»Ÿè®¡
        grid_info = self._get_grid_info()
        load_ratio = total_load / grid_info['total_load'] if grid_info['total_load'] > 0 else 0
        generation_ratio = total_generation / grid_info['total_generation'] if grid_info['total_generation'] > 0 else 0
        
        # å†…éƒ¨è¿é€šæ€§
        max_edges = num_nodes * (num_nodes - 1) / 2
        internal_connectivity = internal_edges / max_edges if max_edges > 0 else 0
        
        # è¾¹ç•Œæ¯”ç‡
        boundary_ratio = boundary_nodes / num_nodes if num_nodes > 0 else 0
        
        # åŠŸç‡ä¸å¹³è¡¡
        power_imbalance = (total_generation - total_load) / total_load if total_load > 0 else 0
        
        return {
            'nodes': nodes,
            'num_nodes': num_nodes,
            'load': total_load,
            'generation': total_generation,
            'internal_edges': internal_edges,
            'boundary_nodes': boundary_nodes,
            'size_ratio': size_ratio,
            'load_ratio': load_ratio,
            'generation_ratio': generation_ratio,
            'internal_connectivity': internal_connectivity,
            'boundary_ratio': boundary_ratio,
            'power_imbalance': power_imbalance
        }
    
    def _empty_partition_features(self) -> Dict[str, float]:
        """è¿”å›ç©ºåˆ†åŒºçš„ç‰¹å¾"""
        return {
            'nodes': [],
            'num_nodes': 0,
            'load': 0.0,
            'generation': 0.0,
            'internal_edges': 0,
            'boundary_nodes': 0,
            'size_ratio': 0.0,
            'load_ratio': 0.0,
            'generation_ratio': 0.0,
            'internal_connectivity': 0.0,
            'boundary_ratio': 0.0,
            'power_imbalance': 0.0
        }
    
    def _get_grid_info(self) -> Dict[str, float]:
        """è·å–ç”µç½‘å…¨å±€ä¿¡æ¯"""
        if not hasattr(self, '_grid_info_cache'):
            # è®¡ç®—å…¨å±€ç»Ÿè®¡
            # ä½¿ç”¨ total_nodes å±æ€§ï¼ˆå·²åœ¨çˆ¶ç±»ä¸­è®¡ç®—ï¼‰
            total_nodes = self.total_nodes

            # è®¡ç®—æ€»è´Ÿè½½
            total_load = 0.0
            if 'bus' in self.hetero_data.x_dict:
                bus_features = self.hetero_data.x_dict['bus']
                if bus_features.size(1) > 2:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç»´åº¦
                    total_load = bus_features[:, 2].sum().item()

            # è®¡ç®—æ€»å‘ç”µé‡
            total_generation = 0.0
            if 'gen' in self.hetero_data.x_dict:
                gen_features = self.hetero_data.x_dict['gen']
                if gen_features.size(1) > 0:  # ç¡®ä¿æœ‰ç‰¹å¾
                    total_generation = gen_features[:, 0].sum().item()

            self._grid_info_cache = {
                'total_nodes': total_nodes,
                'total_load': total_load,
                'total_generation': total_generation
            }

        return self._grid_info_cache
    
    def _update_partition_info(self):
        """æ›´æ–°åˆ†åŒºä¿¡æ¯ï¼ˆåœ¨æ¯æ¬¡åŠ¨ä½œåè°ƒç”¨ï¼‰"""
        # æ¸…ç†ç¼“å­˜
        self.partition_features_cache.clear()
        self.connectivity_cache.clear()

        # é‡æ–°è®¡ç®—æ‰€æœ‰åˆ†åŒºçš„ç‰¹å¾
        if self.enable_features_cache and self.state_manager.current_partition is not None:
            # current_partitionæ˜¯ä¸€ä¸ªå¼ é‡ï¼Œä¸æ˜¯å­—å…¸ï¼Œéœ€è¦è·å–å”¯ä¸€å€¼
            partition_ids = torch.unique(self.state_manager.current_partition).cpu().tolist()
            for pid in partition_ids:
                if pid > 0:  # å¿½ç•¥æœªåˆ†é…
                    self.get_partition_features(pid)
    
    def step(self, action: Union[Tuple[int, int], AbstractDecisionContext]) -> Tuple[Dict[str, torch.Tensor], float, bool, bool, Dict[str, Any]]:
        """
        æ‰§è¡Œç¯å¢ƒæ­¥éª¤ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒv3.0 AbstractDecisionContextï¼‰
        
        Args:
            action: å…·ä½“åŠ¨ä½œtupleæˆ–AbstractDecisionContext
        
        Returns:
            è§‚å¯Ÿã€å¥–åŠ±ã€ç»ˆæ­¢æ ‡å¿—ã€æˆªæ–­æ ‡å¿—ã€ä¿¡æ¯å­—å…¸
        """
        # v3.0æ¶æ„ï¼šå°†AbstractDecisionContextè½¬æ¢ä¸ºå…·ä½“åŠ¨ä½œ
        if isinstance(action, AbstractDecisionContext):
            materialized_action = self.materialize_action(action)
            if materialized_action is None:
                # æ— æ³•å®ä½“åŒ–ï¼Œè¿”å›æ— æ•ˆåŠ¨ä½œ
                return self.state_manager.get_observation(), -1.0, True, False, {
                    'termination_reason': 'materialize_failed',
                    'error': 'Cannot materialize AbstractDecisionContext to concrete action'
                }
            concrete_action = materialized_action
        else:
            # ä¼ ç»Ÿå…·ä½“åŠ¨ä½œ
            concrete_action = action
        
        # æ‰§è¡Œçˆ¶ç±»step
        obs, reward, terminated, truncated, info = super().step(concrete_action)
        
        # å¦‚æœåŠ¨ä½œæˆåŠŸæ‰§è¡Œï¼Œæ›´æ–°åˆ†åŒºä¿¡æ¯
        if not terminated or info.get('termination_reason') != 'invalid_action':
            self._update_partition_info()
        
        # æ·»åŠ å¢å¼ºä¿¡æ¯åˆ°è§‚å¯Ÿä¸­
        obs = self._enhance_observation(obs)
        
        return obs, reward, terminated, truncated, info
    
    def materialize_action(self, context: AbstractDecisionContext, 
                          similarity_threshold: float = 0.8) -> Optional[Tuple[int, int]]:
        """
        å°†æŠ½è±¡å†³ç­–ä¸Šä¸‹æ–‡å®ä½“åŒ–ä¸ºå…·ä½“çš„æ‰§è¡ŒåŠ¨ä½œ
        
        è¿™æ˜¯v3.0æ¶æ„çš„å…³é”®æ–¹æ³•ï¼Œå®ç°è·¨æ‹“æ‰‘æ³›åŒ–ï¼š
        é€šè¿‡åµŒå…¥ç›¸ä¼¼åº¦åŒ¹é…ï¼Œå°†æŠ½è±¡è¡¨ç¤ºè½¬æ¢ä¸ºå½“å‰ç¯å¢ƒçš„å…·ä½“åŠ¨ä½œã€‚
        
        Args:
            context: æŠ½è±¡å†³ç­–ä¸Šä¸‹æ–‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºæ— æ³•åŒ¹é…
        
        Returns:
            (node_id, partition_id) tupleï¼Œæˆ–Noneå¦‚æœæ— æ³•åŒ¹é…
        """
        try:
            # è·å–å½“å‰ç¯å¢ƒçš„èŠ‚ç‚¹å’Œåˆ†åŒºåµŒå…¥
            current_state = self.state_manager.get_observation()
            
            # è·å–èŠ‚ç‚¹åµŒå…¥
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä»GNNç¼–ç å™¨è·å–èŠ‚ç‚¹åµŒå…¥
            if 'node_embeddings' in current_state:
                current_node_embeddings = current_state['node_embeddings']
            else:
                # å¦‚æœè§‚å¯Ÿä¸­æ²¡æœ‰é¢„è®¡ç®—çš„åµŒå…¥ï¼Œéœ€è¦é€šè¿‡GNNç”Ÿæˆ
                # è¿™å¯èƒ½éœ€è¦è°ƒç”¨çŠ¶æ€ç®¡ç†å™¨æˆ–GNNç¼–ç å™¨
                logger.warning("å½“å‰è§‚å¯Ÿä¸­ç¼ºå°‘node_embeddingsï¼Œä½¿ç”¨ç®€åŒ–çš„ç‰¹å¾æ˜ å°„")
                # ç®€åŒ–å®ç°ï¼šä½¿ç”¨èŠ‚ç‚¹ç‰¹å¾ä½œä¸ºåµŒå…¥ä»£ç†
                current_node_embeddings = current_state.get('x', torch.randn(self.graph.number_of_nodes(), 
                                                                           context.node_embedding.size(0)))
            
            # è·å–åˆ†åŒºåµŒå…¥ï¼ˆéœ€è¦ä¸ºæ‰€æœ‰å½“å‰åˆ†åŒºè®¡ç®—åµŒå…¥ï¼‰
            current_partitions = torch.unique(current_state['current_partition'])
            partition_embeddings_list = []
            
            for pid in current_partitions:
                # è·å–åˆ†åŒºç‰¹å¾å¹¶ç¼–ç ä¸ºåµŒå…¥
                partition_features = self.get_partition_features(pid.item())
                
                # è½¬æ¢ä¸ºæ ‡å‡†åŒ–ç‰¹å¾å‘é‡ï¼ˆä¸PartitionEncoderæœŸæœ›çš„æ ¼å¼ä¸€è‡´ï¼‰
                expected_features = [
                    'size_ratio', 'load_ratio', 'generation_ratio',
                    'internal_connectivity', 'boundary_ratio', 'power_imbalance'
                ]
                
                feature_values = []
                for key in expected_features:
                    val = partition_features.get(key, 0.0)
                    if isinstance(val, (int, float)):
                        feature_values.append(float(val))
                    elif isinstance(val, torch.Tensor):
                        feature_values.append(val.item() if val.numel() == 1 else val.mean().item())
                    else:
                        feature_values.append(0.0)
                
                feature_tensor = torch.tensor(feature_values, dtype=torch.float32, device=self.device)
                partition_embeddings_list.append(feature_tensor)
            
            if partition_embeddings_list:
                current_partition_embeddings = torch.stack(partition_embeddings_list)
            else:
                logger.error("æ— æ³•è·å–å½“å‰åˆ†åŒºåµŒå…¥")
                return None
            
            # ä½¿ç”¨decision_contextæ¨¡å—çš„materializeå‡½æ•°
            # åˆ›å»ºå€™é€‰æ˜ å°„ï¼šä»å½“å‰åˆ†åŒºIDåˆ—è¡¨
            candidate_mappings = [(0, pid.item()) for pid in current_partitions]  # ç®€åŒ–æ˜ å°„
            
            result = materialize_decision_context(
                context=context,
                candidate_mappings=candidate_mappings,
                similarity_threshold=similarity_threshold
            )
            
            if result is not None:
                node_id, partition_idx = result
                # å°†åˆ†åŒºç´¢å¼•è½¬æ¢ä¸ºå®é™…çš„åˆ†åŒºID
                actual_partition_id = current_partitions[partition_idx].item()
                return (node_id, actual_partition_id)
            else:
                logger.warning(f"æ— æ³•å°†DecisionContextå®ä½“åŒ–ï¼šç›¸ä¼¼åº¦ä½äºé˜ˆå€¼{similarity_threshold}")
                return None
                
        except Exception as e:
            logger.error(f"materialize_actionå¤±è´¥: {e}")
            return None
    
    def _enhance_observation(self, obs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        å¢å¼ºè§‚å¯Ÿï¼Œæ·»åŠ é¢å¤–ä¿¡æ¯
        
        Args:
            obs: åŸå§‹è§‚å¯Ÿ
        
        Returns:
            å¢å¼ºçš„è§‚å¯Ÿ
        """
        # æ·»åŠ è¿é€šæ€§å®‰å…¨åˆ†åŒºä¿¡æ¯
        connectivity_info = {}
        boundary_nodes = self.state_manager.get_boundary_nodes()
        
        for node in boundary_nodes:
            # ç¡®ä¿nodeæ˜¯Python intç±»å‹ï¼Œç”¨äºå­—å…¸é”®
            node_int = int(node.item()) if torch.is_tensor(node) else int(node)
            safe_partitions = self.get_connectivity_safe_partitions(node)
            connectivity_info[node_int] = safe_partitions
        
        obs['connectivity_safe_partitions'] = connectivity_info
        
        # æ·»åŠ åˆ†åŒºç‰¹å¾ä¿¡æ¯
        partition_info = {}
        # current_partitionæ˜¯ä¸€ä¸ªå¼ é‡ï¼Œéœ€è¦è·å–å”¯ä¸€å€¼
        partition_ids = torch.unique(self.state_manager.current_partition).cpu().tolist()
        
        for pid in partition_ids:
            if pid > 0:
                partition_info[pid] = self.get_partition_features(pid)
        
        obs['partition_info'] = partition_info
        
        # æ·»åŠ ç½‘æ ¼å…¨å±€ä¿¡æ¯
        obs['grid_info'] = self._get_grid_info()
        
        # v3.0æ¶æ„ï¼šæ·»åŠ åµŒå…¥ä¿¡æ¯ä»¥æ”¯æŒç›¸ä¼¼åº¦åŒ¹é…
        obs = self._add_embedding_info(obs)
        
        return obs
    
    def _add_embedding_info(self, obs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        ä¸ºè§‚å¯Ÿæ·»åŠ åµŒå…¥ä¿¡æ¯ï¼Œæ”¯æŒv3.0æ¶æ„çš„ç›¸ä¼¼åº¦åŒ¹é…
        
        Args:
            obs: åŸå§‹è§‚å¯Ÿå­—å…¸
            
        Returns:
            å¢å¼ºçš„è§‚å¯Ÿå­—å…¸ï¼ŒåŒ…å«èŠ‚ç‚¹å’Œåˆ†åŒºåµŒå…¥
        """
        try:
            # æ·»åŠ èŠ‚ç‚¹åµŒå…¥ä¿¡æ¯
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªGNNç¼–ç å™¨å¯ä»¥ç”ŸæˆèŠ‚ç‚¹åµŒå…¥
            # å®é™…å®ç°ä¸­ï¼Œè¿™å¯èƒ½éœ€è¦è°ƒç”¨state_managerçš„GNNç¼–ç åŠŸèƒ½
            
            if hasattr(self.state_manager, 'get_node_embeddings'):
                # å¦‚æœstate_manageræ”¯æŒç›´æ¥è·å–èŠ‚ç‚¹åµŒå…¥
                node_embeddings = self.state_manager.get_node_embeddings()
                obs['node_embeddings'] = node_embeddings
            else:
                # ç”Ÿæˆæ ‡å‡†åŒ–çš„èŠ‚ç‚¹åµŒå…¥ï¼ˆåŸºäºèŠ‚ç‚¹ç‰¹å¾ï¼‰
                node_features = obs.get('x', self.state_manager.hetero_data['bus'].x)
                if node_features.size(1) >= 64:
                    obs['node_embeddings'] = node_features[:, :64]  # æˆªå–å‰64ç»´
                else:
                    # æ‰©å±•åˆ°64ç»´ï¼ˆå·¥ç¨‹çº§å®ç°ï¼‰
                    pad_size = 64 - node_features.size(1)
                    padding = torch.zeros(node_features.size(0), pad_size, device=node_features.device)
                    obs['node_embeddings'] = torch.cat([node_features, padding], dim=1)
            
            # æ·»åŠ å½“å‰åˆ†åŒºçš„åµŒå…¥ä¿¡æ¯
            current_partitions = torch.unique(obs['current_partition'])
            partition_embeddings = self._compute_partition_embeddings(current_partitions)
            obs['partition_embeddings'] = partition_embeddings
            obs['partition_ids'] = current_partitions
            
            # æ·»åŠ è¾¹ç•ŒèŠ‚ç‚¹çš„åµŒå…¥ç´¢å¼•ï¼Œä¾¿äºå¿«é€ŸæŸ¥æ‰¾
            boundary_nodes = self.state_manager.get_boundary_nodes()
            obs['boundary_node_indices'] = boundary_nodes
            
        except Exception as e:
            logger.warning(f"æ·»åŠ åµŒå…¥ä¿¡æ¯å¤±è´¥ï¼š{e}ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
            # å³ä½¿å¤±è´¥ä¹Ÿè¦æä¾›åŸºæœ¬çš„åµŒå…¥ä¿¡æ¯
            num_nodes = self.graph.number_of_nodes()
            obs['node_embeddings'] = torch.randn(num_nodes, 64, device=self.device)
            obs['partition_embeddings'] = torch.randn(1, 6, device=self.device)  # è‡³å°‘æœ‰ä¸€ä¸ªåˆ†åŒº
            obs['partition_ids'] = torch.tensor([1], device=self.device)
            obs['boundary_node_indices'] = torch.tensor([], dtype=torch.long, device=self.device)
        
        return obs
    
    def _compute_partition_embeddings(self, partition_ids: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—åˆ†åŒºåµŒå…¥è¡¨ç¤º
        
        Args:
            partition_ids: åˆ†åŒºIDå¼ é‡
            
        Returns:
            åˆ†åŒºåµŒå…¥å¼ é‡ [num_partitions, embedding_dim]
        """
        embeddings = []
        
        for pid in partition_ids:
            if pid.item() == 0:  # è·³è¿‡æœªåˆ†é…çš„èŠ‚ç‚¹
                continue
                
            # è·å–åˆ†åŒºç‰¹å¾
            partition_features = self.get_partition_features(pid.item())
            
            # è½¬æ¢ä¸ºæ ‡å‡†åŒ–ç‰¹å¾å‘é‡
            expected_features = [
                'size_ratio', 'load_ratio', 'generation_ratio',
                'internal_connectivity', 'boundary_ratio', 'power_imbalance'
            ]
            
            feature_values = []
            for key in expected_features:
                val = partition_features.get(key, 0.0)
                if isinstance(val, (int, float)):
                    feature_values.append(float(val))
                elif isinstance(val, torch.Tensor):
                    feature_values.append(val.item() if val.numel() == 1 else val.mean().item())
                else:
                    feature_values.append(0.0)
            
            # ç¡®ä¿ç‰¹å¾é•¿åº¦æ­£ç¡®
            if len(feature_values) != 6:
                feature_values = feature_values[:6] + [0.0] * (6 - len(feature_values))
            
            feature_tensor = torch.tensor(feature_values, dtype=torch.float32, device=self.device)
            embeddings.append(feature_tensor)
        
        if embeddings:
            return torch.stack(embeddings)
        else:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆåˆ†åŒºï¼Œè¿”å›ç©ºå¼ é‡
            return torch.empty((0, 6), dtype=torch.float32, device=self.device)
    
    def get_current_embeddings(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        è·å–å½“å‰ç¯å¢ƒçš„å®Œæ•´åµŒå…¥ä¿¡æ¯
        
        ä¾¿æ·æ–¹æ³•ï¼Œç”¨äºAbstractDecisionContextçš„å®ä½“åŒ–è¿‡ç¨‹
        
        Returns:
            (node_embeddings, partition_embeddings, partition_ids)
        """
        current_obs = self.state_manager.get_observation()
        enhanced_obs = self._add_embedding_info(current_obs)
        
        return (
            enhanced_obs['node_embeddings'],
            enhanced_obs['partition_embeddings'], 
            enhanced_obs['partition_ids']
        )
    
    def find_similar_node(self, target_embedding: torch.Tensor, 
                         threshold: float = 0.8) -> Optional[int]:
        """
        é€šè¿‡åµŒå…¥ç›¸ä¼¼åº¦æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„èŠ‚ç‚¹
        
        Args:
            target_embedding: ç›®æ ‡èŠ‚ç‚¹åµŒå…¥
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            æœ€ç›¸ä¼¼çš„èŠ‚ç‚¹IDï¼Œæˆ–Noneå¦‚æœæ²¡æœ‰æ»¡è¶³é˜ˆå€¼çš„èŠ‚ç‚¹
        """
        node_embeddings, _, _ = self.get_current_embeddings()
        
        similarities = torch.cosine_similarity(
            target_embedding.unsqueeze(0),
            node_embeddings,
            dim=1
        )
        
        best_similarity, best_idx = torch.max(similarities, dim=0)
        
        if best_similarity.item() >= threshold:
            return best_idx.item()
        else:
            return None
    
    def find_similar_partition(self, target_embedding: torch.Tensor,
                              threshold: float = 0.8) -> Optional[int]:
        """
        é€šè¿‡åµŒå…¥ç›¸ä¼¼åº¦æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„åˆ†åŒº
        
        Args:
            target_embedding: ç›®æ ‡åˆ†åŒºåµŒå…¥
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            æœ€ç›¸ä¼¼çš„åˆ†åŒºIDï¼Œæˆ–Noneå¦‚æœæ²¡æœ‰æ»¡è¶³é˜ˆå€¼çš„åˆ†åŒº
        """
        _, partition_embeddings, partition_ids = self.get_current_embeddings()
        
        if partition_embeddings.size(0) == 0:
            return None
        
        similarities = torch.cosine_similarity(
            target_embedding.unsqueeze(0),
            partition_embeddings,
            dim=1
        )
        
        best_similarity, best_idx = torch.max(similarities, dim=0)
        
        if best_similarity.item() >= threshold:
            return partition_ids[best_idx].item()
        else:
            return None
    
    def reset(self, *args, **kwargs) -> Tuple[Dict[str, torch.Tensor], Dict[str, Any]]:
        """
        é‡ç½®ç¯å¢ƒï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
        """
        obs, info = super().reset(*args, **kwargs)
        
        # é‡å»ºç¼“å­˜
        self._update_partition_info()
        
        # å¢å¼ºè§‚å¯Ÿ
        obs = self._enhance_observation(obs)
        
        return obs, info
    
    def get_action_mask_with_connectivity(self) -> torch.Tensor:
        """
        è·å–è€ƒè™‘è¿é€šæ€§çº¦æŸçš„åŠ¨ä½œæ©ç 
        
        Returns:
            åŠ¨ä½œæ©ç å¼ é‡ [num_nodes, num_partitions]
        """
        num_nodes = self.hetero_data['bus'].x.size(0)
        mask = torch.zeros(num_nodes, self.num_partitions, dtype=torch.bool, device=self.device)
        
        # åªä¸ºè¾¹ç•ŒèŠ‚ç‚¹è®¾ç½®æ©ç 
        boundary_nodes = self.state_manager.get_boundary_nodes()
        
        for node in boundary_nodes:
            # ç¡®ä¿nodeæ˜¯Python intç±»å‹ç”¨äºç´¢å¼•
            node_int = int(node.item()) if torch.is_tensor(node) else int(node)
            safe_partitions = self.get_connectivity_safe_partitions(node)
            for pid in safe_partitions:
                mask[node_int, pid - 1] = True  # è½¬æ¢ä¸º0-indexed
        
        return mask
    
    def visualize_partition_features(self, partition_id: int):
        """
        å¯è§†åŒ–åˆ†åŒºç‰¹å¾ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        
        Args:
            partition_id: åˆ†åŒºID
        """
        features = self.get_partition_features(partition_id)
        
        print(f"\n=== Partition {partition_id} Features ===")
        print(f"Nodes: {len(features['nodes'])} ({features['size_ratio']:.2%} of total)")
        print(f"Load: {features['load']:.2f} MW ({features['load_ratio']:.2%} of total)")
        print(f"Generation: {features['generation']:.2f} MW ({features['generation_ratio']:.2%} of total)")
        print(f"Power Balance: {features['power_imbalance']:.2f}")
        print(f"Internal Connectivity: {features['internal_connectivity']:.2%}")
        print(f"Boundary Ratio: {features['boundary_ratio']:.2%}")


def create_enhanced_environment(hetero_data: HeteroData,
                               node_embeddings: Dict[str, torch.Tensor],
                               num_partitions: int,
                               config: Dict[str, Any],
                               use_enhanced: bool = True,
                               gat_encoder: Optional[Any] = None) -> Union[EnhancedPowerGridPartitioningEnv, PowerGridPartitioningEnv]:
    """
    ç¯å¢ƒåˆ›å»ºçš„å·¥å‚å‡½æ•°

    Args:
        hetero_data: å¼‚æ„å›¾æ•°æ®
        node_embeddings: é¢„è®¡ç®—çš„èŠ‚ç‚¹åµŒå…¥
        num_partitions: åˆ†åŒºæ•°
        config: é…ç½®å­—å…¸
        use_enhanced: æ˜¯å¦åˆ›å»ºå¢å¼ºç¯å¢ƒ
        gat_encoder: [v3.0] é¢„è®­ç»ƒçš„GATç¼–ç å™¨å®ä¾‹

    Returns:
        ç¯å¢ƒå®ä¾‹
    """
    env_config = config.get('environment', {})
    device = torch.device(config.get('system', {}).get('device', 'cpu'))

    state_manager = StateManager(
        hetero_data=hetero_data,
        node_embeddings=node_embeddings,
        num_partitions=num_partitions,
        config=config,
        gat_encoder=gat_encoder,  # ä¼ é€’ç»™çŠ¶æ€ç®¡ç†å™¨
        device=device
    )

    action_space = ActionSpace(
        state_manager=state_manager,
        config=config
    )

    env_class = EnhancedPowerGridPartitioningEnv if use_enhanced else PowerGridPartitioningEnv
    
    env = env_class(
        state_manager=state_manager,
        action_space=action_space,
        config=env_config
    )

    # æ ¸å¿ƒä¿®å¤ï¼šå°†GATç¼–ç å™¨å®ä¾‹é™„åŠ åˆ°envå¯¹è±¡ä¸Šï¼Œä»¥ä¾¿Agentå¯ä»¥è®¿é—®
    if gat_encoder is not None:
        env.gat_encoder = gat_encoder

    return env