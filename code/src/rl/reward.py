"""
è‡ªé€‚åº”è´¨é‡å¯¼å‘è®­ç»ƒç³»ç»Ÿ - å¥–åŠ±å‡½æ•°

å®ç°åŸºäºåŠ¿å‡½æ•°ç†è®ºçš„è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±ç³»ç»Ÿï¼š
1. è´¨é‡åˆ†æ•°è®¡ç®—ï¼šç»Ÿä¸€çš„è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œæ”¯æŒè·¨ç½‘ç»œé€‚åº”æ€§
2. åŠ¿å‡½æ•°ä¸»å¥–åŠ±ï¼šåŸºäºè´¨é‡åˆ†æ•°çš„ç›¸å¯¹æ”¹å–„ï¼Œé›¶å›ºå®šé˜ˆå€¼ä¾èµ–
3. å¹³å°æœŸæ£€æµ‹ï¼šæ™ºèƒ½æ£€æµ‹è´¨é‡æ”¹å–„å¹³å°æœŸï¼Œæ”¯æŒæ—©åœæœºåˆ¶
4. æ•ˆç‡å¥–åŠ±ï¼šåœ¨å¹³å°æœŸæ¿€æ´»çš„æ•ˆç‡æ¿€åŠ±ï¼Œé¼“åŠ±å¿«é€Ÿæ”¶æ•›

æ ¸å¿ƒç‰¹æ€§ï¼š
- å®Œå…¨ç›¸å¯¹åŒ–ï¼šè‡ªåŠ¨é€‚åº”ä¸åŒç½‘ç»œçš„è´¨é‡æ°´å¹³
- å¹³å°æœŸæ£€æµ‹ï¼šåŸºäºæ”¹å–„ç‡ã€ç¨³å®šæ€§å’Œå†å²è¡¨ç°çš„ç»¼åˆåˆ¤æ–­
- æ•ˆç‡æ¿€åŠ±ï¼šä»…åœ¨è´¨é‡å¹³å°æœŸæ¿€æ´»ï¼Œé¿å…è´¨é‡ç‰ºç‰²
- æ•°å€¼ç¨³å®šæ€§ï¼šå…¨é¢çš„NaN/infä¿æŠ¤å’Œå¼‚å¸¸å¤„ç†

ä½œè€…ï¼šAugment Agent
æ—¥æœŸï¼š2025-07-01
"""

import torch
import numpy as np
import hashlib
from collections import defaultdict, deque
from typing import Dict, List, Tuple, Optional, Any, Union
from torch_geometric.data import HeteroData
from .plateau_detector import QualityPlateauDetector, PlateauResult


class RewardFunction:
    """
    è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±å‡½æ•°ç³»ç»Ÿ

    å®ç°åŸºäºåŠ¿å‡½æ•°ç†è®ºçš„è‡ªé€‚åº”è´¨é‡å¯¼å‘æ¿€åŠ±ç»“æ„ï¼š
    1. è´¨é‡åˆ†æ•°è®¡ç®—ï¼šç»Ÿä¸€çš„è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œæ”¯æŒè·¨ç½‘ç»œé€‚åº”æ€§
    2. åŠ¿å‡½æ•°ä¸»å¥–åŠ±ï¼šåŸºäºè´¨é‡åˆ†æ•°çš„ç›¸å¯¹æ”¹å–„ï¼Œé›¶å›ºå®šé˜ˆå€¼ä¾èµ–
    3. å¹³å°æœŸæ£€æµ‹ï¼šæ™ºèƒ½æ£€æµ‹è´¨é‡æ”¹å–„å¹³å°æœŸï¼Œæ”¯æŒæ—©åœæœºåˆ¶
    4. æ•ˆç‡å¥–åŠ±ï¼šåœ¨å¹³å°æœŸæ¿€æ´»çš„æ•ˆç‡æ¿€åŠ±ï¼Œé¼“åŠ±å¿«é€Ÿæ”¶æ•›

    æ ¸å¿ƒç»„ä»¶ï¼š
    - _compute_quality_score(): ç»Ÿä¸€è´¨é‡åˆ†æ•°è®¡ç®—
    - plateau_detector: å¹³å°æœŸæ£€æµ‹å™¨
    - previous_quality_score: å‰ä¸€æ­¥è´¨é‡åˆ†æ•°ç¼“å­˜
    - æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤ï¼šæ‰€æœ‰æ•°å­¦è¿ç®—éƒ½æœ‰epsilonä¿æŠ¤
    """

    def __init__(self,
                 hetero_data: HeteroData,
                 config: Dict[str, Any] = None,
                 device: torch.device = None):
        """
        åˆå§‹åŒ–è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±å‡½æ•°

        Args:
            hetero_data: å¼‚æ„å›¾æ•°æ®
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æƒé‡ã€é˜ˆå€¼ç­‰å‚æ•°
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device or torch.device('cpu')
        self.hetero_data = hetero_data.to(self.device)
        self.config = config or {}

        # ä»é…ç½®ä¸­è·å–æƒé‡å’Œè‡ªé€‚åº”è´¨é‡é…ç½®
        self.weights = self._load_weights()
        self.adaptive_quality_config = self._load_adaptive_quality_config()

        # åˆå§‹åŒ–å¹³å°æœŸæ£€æµ‹å™¨
        self.plateau_detector = self._create_plateau_detector()

        # å‰ä¸€æ­¥è´¨é‡åˆ†æ•°ç¼“å­˜
        self.previous_quality_score = None
        self.previous_metrics = None  # ä¿æŒå‘åå…¼å®¹

        # å½“å‰æ­¥æ•°ï¼ˆç”¨äºæ•ˆç‡å¥–åŠ±è®¡ç®—ï¼‰
        self.current_step = 0
        self.max_steps = self.config.get('max_steps', 200)

        # é¢„è®¡ç®—å¸¸ç”¨æ•°æ®
        self._setup_cached_data()

        # æ•°å€¼ç¨³å®šæ€§å‚æ•°
        self.epsilon = 1e-9
        
    def _load_weights(self) -> Dict[str, float]:
        """ä»é…ç½®åŠ è½½æƒé‡å‚æ•°"""
        default_weights = {
            # è´¨é‡åˆ†æ•°æƒé‡ï¼ˆæ›¿ä»£åŸæœ‰å›ºå®šé˜ˆå€¼ï¼‰
            'cv_weight': 0.4,
            'coupling_weight': 0.3,
            'power_weight': 0.3,
            # ä¿ç•™ç»ˆå±€å¥–åŠ±æƒé‡ä»¥å‘åå…¼å®¹
            'final_balance_weight': 0.4,
            'final_decoupling_weight': 0.4,
            'final_power_weight': 0.2,
        }

        adaptive_quality_config = self.config.get('adaptive_quality', {})
        quality_weights = adaptive_quality_config.get('quality_weights', {})

        # åˆå¹¶é…ç½®ï¼Œä¼˜å…ˆçº§ï¼šadaptive_quality > default
        return {**default_weights, **quality_weights}

    def _load_adaptive_quality_config(self) -> Dict[str, Any]:
        """ä»é…ç½®åŠ è½½è‡ªé€‚åº”è´¨é‡é…ç½®"""
        default_config = {
            'plateau_detection': {
                'window_size': 15,
                'min_improvement_rate': 0.005,
                'stability_threshold': 0.8,
                'min_percentile': 0.7,
                'confidence_threshold': 0.8
            },
            'efficiency_reward': {
                'lambda': 0.5,
                'early_stop_confidence': 0.85
            }
        }

        config_adaptive = self.config.get('adaptive_quality', {})

        # æ·±åº¦åˆå¹¶é…ç½®
        result = default_config.copy()
        if config_adaptive:
            if 'plateau_detection' in config_adaptive:
                result['plateau_detection'].update(config_adaptive['plateau_detection'])

            if 'efficiency_reward' in config_adaptive:
                result['efficiency_reward'].update(config_adaptive['efficiency_reward'])

        return result

    def _create_plateau_detector(self) -> QualityPlateauDetector:
        """åˆ›å»ºå¹³å°æœŸæ£€æµ‹å™¨"""
        plateau_config = self.adaptive_quality_config['plateau_detection']
        return QualityPlateauDetector(
            window_size=plateau_config['window_size'],
            min_improvement_rate=plateau_config['min_improvement_rate'],
            stability_threshold=plateau_config['stability_threshold'],
            min_percentile=plateau_config['min_percentile'],
            confidence_threshold=plateau_config['confidence_threshold']
        )
        
    def _setup_cached_data(self):
        """é¢„è®¡ç®—é¢‘ç¹ä½¿ç”¨çš„æ•°æ®"""
        # èŠ‚ç‚¹è´Ÿè½½å’Œå‘ç”µæ•°æ®
        if 'bus' in self.hetero_data.x_dict:
            bus_features = self.hetero_data.x_dict['bus']
            # å‡è®¾ç‰¹å¾é¡ºåºï¼š[Pd, Qd, Pg, Qg, ...]
            self.node_loads = bus_features[:, 0]  # æœ‰åŠŸè´Ÿè½½
            self.node_generation = bus_features[:, 2] if bus_features.shape[1] > 2 else torch.zeros_like(self.node_loads)
        else:
            # å¦‚æœæ²¡æœ‰busæ•°æ®ï¼Œåˆ›å»ºé»˜è®¤å€¼
            num_nodes = sum(x.shape[0] for x in self.hetero_data.x_dict.values())
            self.node_loads = torch.ones(num_nodes, device=self.device)
            self.node_generation = torch.zeros(num_nodes, device=self.device)
            
        # è¾¹ä¿¡æ¯ï¼ˆç”¨äºè®¡ç®—å¯¼çº³ï¼‰
        self._extract_edge_info()
        
    def _extract_edge_info(self):
        """æå–è¾¹ä¿¡æ¯ç”¨äºå¯¼çº³è®¡ç®—"""
        if ('bus', 'connects', 'bus') in self.hetero_data.edge_index_dict:
            self.edge_index = self.hetero_data.edge_index_dict[('bus', 'connects', 'bus')]

            # å¦‚æœæœ‰è¾¹å±æ€§ï¼Œæå–å¯¼çº³ä¿¡æ¯
            if ('bus', 'connects', 'bus') in self.hetero_data.edge_attr_dict:
                edge_attr = self.hetero_data.edge_attr_dict[('bus', 'connects', 'bus')]
                # å‡è®¾å¯¼çº³åœ¨è¾¹å±æ€§çš„æŸä¸ªä½ç½®ï¼Œè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®è°ƒæ•´
                self.edge_admittance = edge_attr[:, 0] if edge_attr.shape[1] > 0 else torch.ones(self.edge_index.shape[1], device=self.device)
            else:
                # é»˜è®¤å¯¼çº³ä¸º1
                self.edge_admittance = torch.ones(self.edge_index.shape[1], device=self.device)
        else:
            # å¦‚æœæ²¡æœ‰è¾¹ä¿¡æ¯ï¼Œåˆ›å»ºç©ºçš„
            self.edge_index = torch.empty((2, 0), dtype=torch.long, device=self.device)
            self.edge_admittance = torch.empty(0, device=self.device)

    def _compute_quality_score(self, partition: torch.Tensor) -> float:
        """
        è®¡ç®—ç»Ÿä¸€è´¨é‡åˆ†æ•°

        åŸºäºæŠ€æœ¯æ–¹æ¡ˆä¸­çš„å…¬å¼ï¼š
        Q(s) = 1 - normalize(wâ‚Â·CV + wâ‚‚Â·coupling_ratio + wâ‚ƒÂ·power_imbalance)

        Args:
            partition: å½“å‰åˆ†åŒºæ–¹æ¡ˆ [num_nodes]

        Returns:
            è´¨é‡åˆ†æ•° [0, 1]ï¼Œè¶Šå¤§è¶Šå¥½
        """
        try:
            # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
            metrics = self._compute_core_metrics(partition)

            cv = metrics.get('cv', 1.0)
            coupling_ratio = metrics.get('coupling_ratio', 1.0)
            power_imbalance = metrics.get('power_imbalance_normalized', 1.0)

            # å½’ä¸€åŒ–å¤„ç†
            normalized_cv = cv / (1 + cv)  # æ˜ å°„åˆ° [0, 1)
            normalized_coupling = coupling_ratio  # å·²ç»åœ¨ [0, 1]
            normalized_power = power_imbalance / (1 + power_imbalance)  # æ˜ å°„åˆ° [0, 1)

            # åŠ æƒç»„åˆï¼ˆè¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ï¼‰
            composite_badness = (
                self.weights['cv_weight'] * normalized_cv +
                self.weights['coupling_weight'] * normalized_coupling +
                self.weights['power_weight'] * normalized_power
            )

            # å½’ä¸€åŒ–åˆ°æƒé‡æ€»å’Œ
            total_weight = (
                self.weights['cv_weight'] +
                self.weights['coupling_weight'] +
                self.weights['power_weight']
            )

            if total_weight > 0:
                composite_badness = composite_badness / total_weight

            # è½¬æ¢ä¸ºè´¨é‡åˆ†æ•°ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
            quality_score = 1.0 - composite_badness

            # æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(quality_score) or np.isinf(quality_score):
                quality_score = 0.0

            return np.clip(quality_score, 0.0, 1.0)

        except Exception as e:
            print(f"è­¦å‘Šï¼šè´¨é‡åˆ†æ•°è®¡ç®—å‡ºç°å¼‚å¸¸: {e}")
            return 0.0
            
    def _compute_core_metrics(self, partition: torch.Tensor) -> Dict[str, float]:
        """
        ä¸­å¿ƒåŒ–çš„æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—æ–¹æ³•
        
        é«˜æ•ˆè®¡ç®—æ‰€æœ‰åç»­å¥–åŠ±æ‰€éœ€çš„åŸºç¡€ç‰©ç†é‡ï¼Œé¿å…é‡å¤è®¡ç®—ï¼š
        - CV (å˜å¼‚ç³»æ•°): è´Ÿè½½å¹³è¡¡æŒ‡æ ‡
        - coupling: ç”µæ°”è€¦åˆåº¦æŒ‡æ ‡  
        - power_imbalance: åŠŸç‡ä¸å¹³è¡¡æŒ‡æ ‡
        - å…¶ä»–è¾…åŠ©æŒ‡æ ‡
        
        Args:
            partition: å½“å‰åˆ†åŒºæ–¹æ¡ˆ [num_nodes]
            
        Returns:
            åŒ…å«æ‰€æœ‰æ ¸å¿ƒæŒ‡æ ‡çš„å­—å…¸
        """
        metrics = {}
        
        # è·å–åˆ†åŒºæ•°é‡
        num_partitions = partition.max().item()
        if num_partitions <= 0:
            # å¦‚æœæ²¡æœ‰åˆ†åŒºï¼Œè¿”å›æœ€å·®æŒ‡æ ‡
            return {
                'cv': 1.0,
                'coupling_ratio': 1.0, 
                'power_imbalance_normalized': 1.0,
                'num_partitions': 0
            }
            
        # 1. è®¡ç®—è´Ÿè½½å¹³è¡¡æŒ‡æ ‡ (CV)
        partition_loads = torch.zeros(num_partitions, device=self.device)
        for i in range(1, num_partitions + 1):
            mask = (partition == i)
            if mask.any():
                partition_loads[i-1] = self.node_loads[mask].abs().sum()
                
        # è®¡ç®—å˜å¼‚ç³»æ•°ï¼Œæ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
        mean_load = partition_loads.mean()
        std_load = partition_loads.std()
        
        # å¤šé‡ä¿æŠ¤ï¼šé˜²æ­¢é™¤é›¶ã€NaNå’Œinf
        if torch.isnan(mean_load) or torch.isinf(mean_load) or mean_load <= 0:
            cv = 1.0  # æœ€å·®æƒ…å†µ
        elif torch.isnan(std_load) or torch.isinf(std_load):
            cv = 1.0
        else:
            cv = std_load / (mean_load + self.epsilon)
            cv = torch.clamp(cv, 0.0, 10.0)  # é™åˆ¶CVåœ¨åˆç†èŒƒå›´å†…
            
        metrics['cv'] = cv.item() if torch.is_tensor(cv) else cv
        
        # 2. è®¡ç®—ç”µæ°”è§£è€¦æŒ‡æ ‡
        if self.edge_index.shape[1] > 0:
            # è®¡ç®—è·¨åŒºçº¿è·¯çš„å¯¼çº³å’Œ
            cross_partition_admittance = 0.0
            total_admittance = self.edge_admittance.sum().item()
            
            # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
            if torch.isnan(self.edge_admittance).any() or torch.isinf(self.edge_admittance).any():
                # å¦‚æœå¯¼çº³æ•°æ®æœ‰é—®é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼
                metrics['coupling_ratio'] = 0.5
                metrics['edge_decoupling_ratio'] = 0.5
            else:
                for i in range(self.edge_index.shape[1]):
                    node1, node2 = self.edge_index[:, i]
                    # æ·»åŠ è¾¹ç•Œæ£€æŸ¥
                    if (node1 < len(partition) and node2 < len(partition) and 
                        partition[node1] != partition[node2] and 
                        partition[node1] > 0 and partition[node2] > 0):
                        admittance_val = self.edge_admittance[i].item()
                        if not (np.isnan(admittance_val) or np.isinf(admittance_val)):
                            cross_partition_admittance += admittance_val
                        
                # è®¡ç®—è€¦åˆæ¯”ç‡ï¼Œæ·»åŠ ä¿æŠ¤
                if total_admittance <= 0 or np.isnan(total_admittance) or np.isinf(total_admittance):
                    coupling_ratio = 0.0
                else:
                    coupling_ratio = cross_partition_admittance / (total_admittance + self.epsilon)
                    coupling_ratio = np.clip(coupling_ratio, 0.0, 1.0)
                metrics['coupling_ratio'] = coupling_ratio
                
                # è®¡ç®—æ‹“æ‰‘è§£è€¦ç‡
                cross_edges = 0
                total_edges = self.edge_index.shape[1]
                for i in range(total_edges):
                    node1, node2 = self.edge_index[:, i]
                    if (node1 < len(partition) and node2 < len(partition) and
                        partition[node1] != partition[node2] and 
                        partition[node1] > 0 and partition[node2] > 0):
                        cross_edges += 1
                        
                edge_decoupling_ratio = 1.0 - (cross_edges / (total_edges + self.epsilon))
                edge_decoupling_ratio = np.clip(edge_decoupling_ratio, 0.0, 1.0)
                metrics['edge_decoupling_ratio'] = edge_decoupling_ratio
        else:
            metrics['coupling_ratio'] = 0.0
            metrics['edge_decoupling_ratio'] = 1.0
            
        # 3. è®¡ç®—åŠŸç‡å¹³è¡¡æŒ‡æ ‡
        total_imbalance = 0.0
        
        # æ£€æŸ¥èŠ‚ç‚¹æ•°æ®çš„æ•°å€¼ç¨³å®šæ€§
        if (torch.isnan(self.node_generation).any() or torch.isinf(self.node_generation).any() or
            torch.isnan(self.node_loads).any() or torch.isinf(self.node_loads).any()):
            # å¦‚æœæ•°æ®æœ‰é—®é¢˜ï¼Œè¿”å›æœ€å·®æƒ…å†µ
            metrics['power_imbalance_normalized'] = 1.0
        else:
            for i in range(1, num_partitions + 1):
                mask = (partition == i)
                if mask.any():
                    partition_generation = self.node_generation[mask].sum()
                    partition_load = self.node_loads[mask].sum()
                    
                    # æ£€æŸ¥æ¯ä¸ªåˆ†åŒºçš„è®¡ç®—ç»“æœ
                    if (torch.isnan(partition_generation) or torch.isinf(partition_generation) or
                        torch.isnan(partition_load) or torch.isinf(partition_load)):
                        continue  # è·³è¿‡æœ‰é—®é¢˜çš„åˆ†åŒº
                        
                    imbalance = torch.abs(partition_generation - partition_load)
                    if not (torch.isnan(imbalance) or torch.isinf(imbalance)):
                        total_imbalance += imbalance.item()
                    
            # å½’ä¸€åŒ–åŠŸç‡ä¸å¹³è¡¡ï¼Œæ·»åŠ å¤šé‡ä¿æŠ¤
            total_load = self.node_loads.abs().sum().item()
            if total_load <= 0 or np.isnan(total_load) or np.isinf(total_load):
                power_imbalance_normalized = 1.0  # æœ€å·®æƒ…å†µ
            else:
                power_imbalance_normalized = total_imbalance / (total_load + self.epsilon)
                power_imbalance_normalized = np.clip(power_imbalance_normalized, 0.0, 10.0)
                
            metrics['power_imbalance_normalized'] = power_imbalance_normalized
        
        # 4. å…¶ä»–è¾…åŠ©æŒ‡æ ‡
        metrics['num_partitions'] = num_partitions
        
        return metrics

    def compute_incremental_reward(self,
                                 current_partition: torch.Tensor,
                                 action: Tuple[int, int]) -> Tuple[float, Optional[PlateauResult]]:
        """
        è®¡ç®—è‡ªé€‚åº”è´¨é‡å¯¼å‘å³æ—¶å¥–åŠ±

        å®ç°åŸºäºè´¨é‡åˆ†æ•°çš„åŠ¿å‡½æ•°å¥–åŠ±ï¼š
        ä¸»å¥–åŠ± = Î³ * Q(s_{t+1}) - Q(s_t)
        æ•ˆç‡å¥–åŠ± = Î» * (max_steps - current_step) / max_steps (ä»…åœ¨å¹³å°æœŸæ¿€æ´»)

        Args:
            current_partition: å½“å‰åˆ†åŒºçŠ¶æ€
            action: æ‰§è¡Œçš„åŠ¨ä½œ (node_idx, partition_id)

        Returns:
            (æ€»å¥–åŠ±, å¹³å°æœŸæ£€æµ‹ç»“æœ)
        """
        # æ›´æ–°æ­¥æ•°
        self.current_step += 1

        # è®¡ç®—å½“å‰è´¨é‡åˆ†æ•°
        current_quality_score = self._compute_quality_score(current_partition)

        # å¦‚æœæ²¡æœ‰å‰ä¸€æ­¥è´¨é‡åˆ†æ•°ï¼Œåˆå§‹åŒ–å¹¶è¿”å›0
        if self.previous_quality_score is None:
            self.previous_quality_score = current_quality_score
            self.previous_metrics = self._compute_core_metrics(current_partition)  # ä¿æŒå‘åå…¼å®¹

            # æ›´æ–°å¹³å°æœŸæ£€æµ‹å™¨
            plateau_result = self.plateau_detector.update(current_quality_score)
            return 0.0, plateau_result

        try:
            # 1. è®¡ç®—ä¸»å¥–åŠ±ï¼ˆåŠ¿å‡½æ•°å¥–åŠ±ï¼‰
            gamma = 0.99  # æŠ˜æ‰£å› å­
            main_reward = gamma * current_quality_score - self.previous_quality_score

            # æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(main_reward) or np.isinf(main_reward):
                main_reward = 0.0
            else:
                main_reward = np.clip(main_reward, -1.0, 1.0)

            # 2. å¹³å°æœŸæ£€æµ‹å’Œæ•ˆç‡å¥–åŠ±
            efficiency_reward = 0.0

            # æ›´æ–°å¹³å°æœŸæ£€æµ‹å™¨
            plateau_result = self.plateau_detector.update(current_quality_score)

            # å¦‚æœæ£€æµ‹åˆ°å¹³å°æœŸä¸”ç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œæ¿€æ´»æ•ˆç‡å¥–åŠ±
            if (plateau_result.plateau_detected and
                plateau_result.confidence > self.adaptive_quality_config['efficiency_reward']['early_stop_confidence']):

                lambda_efficiency = self.adaptive_quality_config['efficiency_reward']['lambda']
                efficiency_reward = lambda_efficiency * (self.max_steps - self.current_step) / self.max_steps
                efficiency_reward = max(0.0, efficiency_reward)  # ç¡®ä¿éè´Ÿ

            # 3. æ€»å¥–åŠ±
            total_reward = main_reward + efficiency_reward

            # æœ€ç»ˆæ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(total_reward) or np.isinf(total_reward):
                total_reward = 0.0
            else:
                total_reward = np.clip(total_reward, -2.0, 2.0)

        except Exception as e:
            print(f"è­¦å‘Šï¼šè‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±è®¡ç®—å‡ºç°å¼‚å¸¸: {e}")
            total_reward = 0.0
            plateau_result = None

        # æ›´æ–°å‰ä¸€æ­¥çŠ¶æ€
        self.previous_quality_score = current_quality_score
        self.previous_metrics = self._compute_core_metrics(current_partition)  # ä¿æŒå‘åå…¼å®¹

        return total_reward, plateau_result

    def reset_episode(self):
        """é‡ç½®episodeçŠ¶æ€"""
        self.current_step = 0
        self.previous_quality_score = None
        self.previous_metrics = None

        self.plateau_detector.reset()

    def get_current_quality_score(self, partition: torch.Tensor) -> float:
        """è·å–å½“å‰è´¨é‡åˆ†æ•°ï¼ˆç”¨äºå¤–éƒ¨è°ƒç”¨ï¼‰"""
        return self._compute_quality_score(partition)

    def get_plateau_statistics(self) -> Dict[str, Any]:
        """è·å–å¹³å°æœŸæ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        if self.plateau_detector is None:
            return {'enabled': False}

        stats = self.plateau_detector.get_statistics()
        stats['enabled'] = True
        return stats

    def should_early_stop(self, partition: torch.Tensor) -> Tuple[bool, float]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœ

        Returns:
            (æ˜¯å¦æ—©åœ, ç½®ä¿¡åº¦)
        """
        # æ›´æ–°è´¨é‡åˆ†æ•°å¹¶æ£€æµ‹å¹³å°æœŸ
        quality_score = self._compute_quality_score(partition)
        plateau_result = self.plateau_detector.update(quality_score)

        early_stop_threshold = self.adaptive_quality_config['efficiency_reward']['early_stop_confidence']
        should_stop = (plateau_result.plateau_detected and
                      plateau_result.confidence > early_stop_threshold)

        return should_stop, plateau_result.confidence

    def compute_final_reward(self,
                           final_partition: torch.Tensor,
                           termination_type: str = 'natural') -> Tuple[float, Dict[str, float]]:
        """
        è®¡ç®—ç»ˆå±€å¥–åŠ±ï¼ˆRewardï¼‰

        åŸºäºæœ€ç»ˆåˆ†åŒºè´¨é‡çš„ç»¼åˆè¯„ä¼°ï¼ŒåŒ…å«ï¼š
        1. ä¸‰ä¸ªæ ¸å¿ƒå¥–åŠ±ç»„ä»¶ï¼ˆæŒ‰è®¾è®¡è“å›¾å…¬å¼ï¼‰
        2. éçº¿æ€§é˜ˆå€¼å¥–åŠ±
        3. ç»ˆæ­¢æ¡ä»¶æŠ˜æ‰£

        Args:
            final_partition: æœ€ç»ˆåˆ†åŒºæ–¹æ¡ˆ
            termination_type: ç»ˆæ­¢ç±»å‹ ('natural', 'timeout', 'stuck')

        Returns:
            (æ€»ç»ˆå±€å¥–åŠ±, å¥–åŠ±ç»„ä»¶è¯¦æƒ…)
        """
        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        final_metrics = self._compute_core_metrics(final_partition)

        # 1. è®¡ç®—ä¸‰ä¸ªæ ¸å¿ƒå¥–åŠ±ç»„ä»¶
        balance_reward = self._compute_balance_reward(final_metrics['cv'])
        decoupling_reward = self._compute_decoupling_reward(
            final_metrics['edge_decoupling_ratio'],
            final_metrics['coupling_ratio']
        )
        power_reward = self._compute_power_reward(final_metrics['power_imbalance_normalized'])

        # 2. åŠ æƒæ±‚å’Œå¾—åˆ°è´¨é‡å¥–åŠ±
        quality_reward = (
            self.weights['final_balance_weight'] * balance_reward +
            self.weights['final_decoupling_weight'] * decoupling_reward +
            self.weights['final_power_weight'] * power_reward
        )

        # 3. é˜ˆå€¼å¥–åŠ±å·²è¢«è‡ªé€‚åº”è´¨é‡ç³»ç»Ÿæ›¿ä»£ï¼Œè®¾ä¸º0
        threshold_bonus = 0.0

        # 4. åº”ç”¨ç»ˆæ­¢æ¡ä»¶æŠ˜æ‰£
        termination_discount = self._apply_termination_discount(termination_type)

        # 5. è®¡ç®—æœ€ç»ˆå¥–åŠ±
        final_reward = (quality_reward + threshold_bonus) * termination_discount

        # ç»„ä»¶è¯¦æƒ…
        components = {
            'balance_reward': balance_reward,
            'decoupling_reward': decoupling_reward,
            'power_reward': power_reward,
            'quality_reward': quality_reward,
            'threshold_bonus': threshold_bonus,
            'termination_discount': termination_discount,
            'final_reward': final_reward,
            'metrics': final_metrics
        }

        return final_reward, components

    def _compute_balance_reward(self, cv: float) -> float:
        """
        è®¡ç®—è´Ÿè½½å¹³è¡¡å¥–åŠ±

        å…¬å¼ï¼šR_balance = exp(-2.0 * CV)
        CVè¶Šå°ï¼Œå¥–åŠ±è¶Šæ¥è¿‘1.0
        """
        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
        if np.isnan(cv) or np.isinf(cv):
            cv = 1.0  # æœ€å·®æƒ…å†µ
        else:
            cv = max(0.0, min(cv, 10.0))  # ç¡®ä¿CVåœ¨åˆç†èŒƒå›´å†…

        try:
            balance_reward = np.exp(-2.0 * cv)
            # æ£€æŸ¥ç»“æœ
            if np.isnan(balance_reward) or np.isinf(balance_reward):
                balance_reward = 0.0
            else:
                balance_reward = np.clip(balance_reward, 0.0, 1.0)
        except Exception:
            balance_reward = 0.0

        return balance_reward

    def _compute_decoupling_reward(self, edge_decoupling_ratio: float, coupling_ratio: float) -> float:
        """
        è®¡ç®—ç”µæ°”è§£è€¦å¥–åŠ±

        å…¬å¼ï¼šR_decoupling = 0.5 * Ïƒ(5*(r_edge - 0.5)) + 0.5 * Ïƒ(5*(r_admittance - 0.5))
        å…¶ä¸­ Ïƒ æ˜¯sigmoidå‡½æ•°ï¼Œr_admittance = 1 - coupling_ratio
        """
        # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        if np.isnan(edge_decoupling_ratio) or np.isinf(edge_decoupling_ratio):
            edge_decoupling_ratio = 0.5
        else:
            edge_decoupling_ratio = np.clip(edge_decoupling_ratio, 0.0, 1.0)

        if np.isnan(coupling_ratio) or np.isinf(coupling_ratio):
            coupling_ratio = 0.5
        else:
            coupling_ratio = np.clip(coupling_ratio, 0.0, 1.0)

        # è®¡ç®—å¯¼çº³è§£è€¦ç‡
        admittance_decoupling_ratio = 1.0 - coupling_ratio

        try:
            # åº”ç”¨sigmoidå‡½æ•°
            edge_component = self._sigmoid(5.0 * (edge_decoupling_ratio - 0.5))
            admittance_component = self._sigmoid(5.0 * (admittance_decoupling_ratio - 0.5))

            decoupling_reward = 0.5 * edge_component + 0.5 * admittance_component

            # æ£€æŸ¥ç»“æœ
            if np.isnan(decoupling_reward) or np.isinf(decoupling_reward):
                decoupling_reward = 0.5
            else:
                decoupling_reward = np.clip(decoupling_reward, 0.0, 1.0)

        except Exception:
            decoupling_reward = 0.5

        return decoupling_reward

    def _compute_power_reward(self, power_imbalance_normalized: float) -> float:
        """
        è®¡ç®—åŠŸç‡å¹³è¡¡å¥–åŠ±

        å…¬å¼ï¼šR_power = exp(-3.0 * I_normalized)
        I_normalizedè¶Šå°ï¼Œå¥–åŠ±è¶Šæ¥è¿‘1.0
        """
        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
        if np.isnan(power_imbalance_normalized) or np.isinf(power_imbalance_normalized):
            power_imbalance_normalized = 1.0  # æœ€å·®æƒ…å†µ
        else:
            power_imbalance_normalized = max(0.0, min(power_imbalance_normalized, 10.0))

        try:
            # é™åˆ¶æŒ‡æ•°å‚æ•°é¿å…æº¢å‡º
            exp_arg = -3.0 * power_imbalance_normalized
            exp_arg = np.clip(exp_arg, -500, 0)  # é˜²æ­¢expæº¢å‡º

            power_reward = np.exp(exp_arg)

            # æ£€æŸ¥ç»“æœ
            if np.isnan(power_reward) or np.isinf(power_reward):
                power_reward = 0.0
            else:
                power_reward = np.clip(power_reward, 0.0, 1.0)

        except Exception:
            power_reward = 0.0

        return power_reward

    def _compute_threshold_bonus(self, metrics: Dict[str, float]) -> float:
        """
        è®¡ç®—éçº¿æ€§é˜ˆå€¼å¥–åŠ± (å·²åºŸå¼ƒï¼Œè¢«è‡ªé€‚åº”è´¨é‡ç³»ç»Ÿæ›¿ä»£)

        ä¿ç•™æ­¤æ–¹æ³•ä»…ä¸ºå‘åå…¼å®¹ï¼Œå®é™…è¿”å›0
        """
        # å›ºå®šé˜ˆå€¼å¥–åŠ±å·²è¢«è‡ªé€‚åº”è´¨é‡å¯¼å‘ç³»ç»Ÿæ›¿ä»£
        return 0.0

    def _apply_termination_discount(self, termination_type: str) -> float:
        """
        æ ¹æ®ç»ˆæ­¢æ¡ä»¶åº”ç”¨ä¸åŒçš„æŠ˜æ‰£æˆ–æƒ©ç½š

        Args:
            termination_type: 'natural' (è‡ªç„¶å®Œæˆ), 'timeout' (è¶…æ—¶), 'stuck' (å¡ä½)

        Returns:
            æŠ˜æ‰£ç³»æ•°
        """
        if termination_type == 'natural':
            return 1.0      # è‡ªç„¶å®Œæˆï¼Œæ— æŠ˜æ‰£
        elif termination_type == 'timeout':
            return 0.7      # è¶…æ—¶å®Œæˆï¼Œ70%æŠ˜æ‰£
        elif termination_type == 'stuck':
            return 0.3      # æå‰å¡ä½ï¼Œ30%æŠ˜æ‰£
        else:
            return 0.5      # æœªçŸ¥æƒ…å†µï¼Œ50%æŠ˜æ‰£

    def _sigmoid(self, x: float) -> float:
        """æ•°å€¼ç¨³å®šçš„sigmoidå‡½æ•°"""
        # é˜²æ­¢æ•°å€¼æº¢å‡º
        x = np.clip(x, -500, 500)
        return 1.0 / (1.0 + np.exp(-x))

    def get_current_metrics(self, partition: torch.Tensor) -> Dict[str, float]:
        """è·å–å½“å‰åˆ†åŒºçš„æŒ‡æ ‡ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰"""
        return self._compute_core_metrics(partition)

    def update_weights(self, new_weights: Dict[str, float]):
        """åŠ¨æ€æ›´æ–°å¥–åŠ±æƒé‡ï¼ˆç”¨äºæ™ºèƒ½è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ ï¼‰"""
        try:
            # æ›´æ–°å³æ—¶å¥–åŠ±æƒé‡
            if 'balance_weight' in new_weights:
                self.weights['balance_weight'] = new_weights['balance_weight']
            if 'decoupling_weight' in new_weights:
                self.weights['decoupling_weight'] = new_weights['decoupling_weight']
            if 'power_weight' in new_weights:
                self.weights['power_weight'] = new_weights['power_weight']

            # æ›´æ–°ç»ˆå±€å¥–åŠ±æƒé‡ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
            if 'balance_weight' in new_weights:
                self.weights['final_balance_weight'] = new_weights['balance_weight']
            if 'decoupling_weight' in new_weights:
                self.weights['final_decoupling_weight'] = new_weights['decoupling_weight']
            if 'power_weight' in new_weights:
                self.weights['final_power_weight'] = new_weights['power_weight']

            print(f"ğŸ¯ å¥–åŠ±æƒé‡å·²æ›´æ–°: balance={self.weights['balance_weight']:.2f}, "
                  f"decoupling={self.weights['decoupling_weight']:.2f}, "
                  f"power={self.weights['power_weight']:.2f}")

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°å¥–åŠ±æƒé‡å¤±è´¥: {e}")

    def get_current_weights(self) -> Dict[str, float]:
        """è·å–å½“å‰å¥–åŠ±æƒé‡"""
        return {
            'balance_weight': self.weights.get('balance_weight', 1.0),
            'decoupling_weight': self.weights.get('decoupling_weight', 1.0),
            'power_weight': self.weights.get('power_weight', 1.0)
        }





