"""
è‡ªé€‚åº”è´¨é‡å¯¼å‘è®­ç»ƒç³»ç»Ÿ - å¥–åŠ±å‡½æ•°

å®ç°åŸºäºåŠ¿å‡½æ•°ç†è®ºçš„è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±ç³»ç»Ÿï¼š
1. è´¨é‡åˆ†æ•°è®¡ç®—ï¼šç»Ÿä¸€çš„è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œæ”¯æŒè·¨ç½‘ç»œé€‚åº”æ€§
2. åŠ¿å‡½æ•°ä¸»å¥–åŠ±ï¼šåŸºäºè´¨é‡åˆ†æ•°çš„ç›¸å¯¹æ”¹å–„ï¼Œé›¶å›ºå®šé˜ˆå€¼ä¾èµ–
3. å¹³å°æœŸæ£€æµ‹ï¼šæ™ºèƒ½æ£€æµ‹è´¨é‡æ”¹å–„å¹³å°æœŸï¼Œæ”¯æŒæ—©åœæœºåˆ¶
4. æ•ˆç‡å¥–åŠ±ï¼šåœ¨å¹³å°æœŸæ¿€æ´»çš„æ•ˆç‡æ¿€åŠ±ï¼Œé¼“åŠ±å¿«é€Ÿæ”¶æ•›

æ ¸å¿ƒç‰¹æ€§ï¼š
- å®Œå…¨ç›¸å¯¹åŒ–ï¼šè‡ªåŠ¨é€‚åº”ä¸åŒç½‘ç»œçš„è´¨é‡æ°´å¹³
- å¹³å°æœŸæ£€æµ‹ï¼šåŸºäºæ”¹å–„ç‡ã€ç¨³å®šæ€§å’Œå†å²è¡¨ç°çš„ç»¼åˆåˆ¤æ–­
- æ•ˆç‡æ¿€åŠ±ï¼šä»…åœ¨è´¨é‡å¹³å°æœŸæ¿€æ´»ï¼Œé¿å…è´¨é‡ç‰ºç‰²
- æ•°å€¼ç¨³å®šæ€§ï¼šå…¨é¢çš„NaN/infä¿æŠ¤å’Œå¼‚å¸¸å¤„ç†

ä½œè€…ï¼šAugment Agent
æ—¥æœŸï¼š2025-07-01
"""

import torch
import numpy as np
import hashlib
import time
import warnings
from collections import defaultdict, deque
from typing import Dict, List, Tuple, Optional, Any, Union
from torch_geometric.data import HeteroData
from .plateau_detector import QualityPlateauDetector, PlateauResult


class RobustMetricsCalculator:
    """
    é²æ£’çš„æŒ‡æ ‡è®¡ç®—å™¨ï¼Œæä¾›æ™ºèƒ½çš„é”™è¯¯å¤„ç†å’Œè¯Šæ–­
    """

    def __init__(self, config=None):
        self.config = config or {}
        self.error_history = []
        self.metrics_history = defaultdict(list)
        self.fallback_strategy = config.get('fallback_strategy', 'conservative')

    def calculate_coupling_metrics(self, edge_admittance, edge_index, partition):
        """
        è®¡ç®—è€¦åˆæŒ‡æ ‡ï¼Œå¸¦æœ‰å®Œæ•´çš„é”™è¯¯å¤„ç†

        è¿”å›:
            dict: åŒ…å«æŒ‡æ ‡å€¼ã€ç½®ä¿¡åº¦å’Œæ¥æºä¿¡æ¯
        """
        try:
            # è¾“å…¥éªŒè¯
            validation_result = self._validate_coupling_inputs(
                edge_admittance, edge_index, partition
            )

            if not validation_result['valid']:
                return self._handle_invalid_coupling_inputs(validation_result)

            # æ­£å¸¸è®¡ç®—
            cross_partition_admittance = 0.0
            total_admittance = edge_admittance.sum().item()

            for i in range(edge_index.shape[1]):
                node1, node2 = edge_index[:, i]
                if (node1 < len(partition) and node2 < len(partition) and
                    partition[node1] != partition[node2] and
                    partition[node1] > 0 and partition[node2] > 0):
                    cross_partition_admittance += edge_admittance[i].item()

            coupling_ratio = cross_partition_admittance / (total_admittance + 1e-10)
            edge_decoupling_ratio = 1.0 - coupling_ratio

            # ç»“æœéªŒè¯
            if not (0 <= coupling_ratio <= 1):
                return self._handle_out_of_range_coupling(coupling_ratio)

            # è®°å½•æˆåŠŸçš„è®¡ç®—
            self._record_successful_calculation('coupling_ratio', coupling_ratio)
            self._record_successful_calculation('edge_decoupling_ratio', edge_decoupling_ratio)

            return {
                'coupling_ratio': coupling_ratio,
                'edge_decoupling_ratio': edge_decoupling_ratio,
                'confidence': 1.0,
                'source': 'calculated'
            }

        except Exception as e:
            return self._handle_coupling_calculation_error(e)

    def _validate_coupling_inputs(self, edge_admittance, edge_index, partition):
        """éªŒè¯è€¦åˆè®¡ç®—çš„è¾“å…¥"""
        issues = []

        # æ£€æŸ¥å¼ é‡æœ‰æ•ˆæ€§
        if torch.isnan(edge_admittance).any():
            issues.append('edge_admittance contains NaN')
        if torch.isinf(edge_admittance).any():
            issues.append('edge_admittance contains Inf')

        # æ£€æŸ¥ç»´åº¦åŒ¹é…
        if edge_admittance.shape[0] != edge_index.shape[1]:
            issues.append(f'dimension mismatch: admittance {edge_admittance.shape[0]} vs edges {edge_index.shape[1]}')

        # æ£€æŸ¥åˆ†åŒºæœ‰æ•ˆæ€§
        if partition.min() < 0:
            issues.append('negative partition labels')

        # æ£€æŸ¥å¯¼çº³å€¼åˆç†æ€§
        if (edge_admittance <= 0).any():
            issues.append('non-positive admittance values')

        return {
            'valid': len(issues) == 0,
            'issues': issues
        }

    def _handle_invalid_coupling_inputs(self, validation_result):
        """å¤„ç†æ— æ•ˆçš„è€¦åˆè®¡ç®—è¾“å…¥"""
        # è®°å½•é”™è¯¯
        error_entry = {
            'metric': 'coupling_metrics',
            'timestamp': time.time(),
            'issues': validation_result['issues']
        }
        self.error_history.append(error_entry)

        # æ ¹æ®ç­–ç•¥é€‰æ‹©å¤„ç†æ–¹å¼
        if self.fallback_strategy == 'conservative':
            # åŸºäºå†å²æ•°æ®çš„ä¿å®ˆä¼°è®¡
            coupling_estimate = self._get_historical_estimate('coupling_ratio', 0.3)
            edge_decoupling_estimate = 1.0 - coupling_estimate

            return {
                'coupling_ratio': coupling_estimate,
                'edge_decoupling_ratio': edge_decoupling_estimate,
                'confidence': 0.2,  # ä½ç½®ä¿¡åº¦
                'source': 'fallback_historical',
                'issues': validation_result['issues']
            }

        elif self.fallback_strategy == 'abort':
            # æŠ›å‡ºè¯¦ç»†å¼‚å¸¸
            raise ValueError(
                f"æ— æ³•è®¡ç®—è€¦åˆæŒ‡æ ‡:\n" +
                "\n".join(f"  - {issue}" for issue in validation_result['issues'])
            )

        else:  # propagate_nan
            return {
                'coupling_ratio': float('nan'),
                'edge_decoupling_ratio': float('nan'),
                'confidence': 0.0,
                'source': 'error',
                'issues': validation_result['issues']
            }

    def _handle_out_of_range_coupling(self, coupling_ratio):
        """å¤„ç†è¶…å‡ºèŒƒå›´çš„è€¦åˆæ¯”ç‡"""
        # è®°å½•å¼‚å¸¸å€¼
        warning_msg = f"è€¦åˆæ¯”ç‡è¶…å‡ºèŒƒå›´: {coupling_ratio:.3f}, å°†è¢«è£å‰ªåˆ°[0,1]"
        warnings.warn(warning_msg)

        # è£å‰ªåˆ°åˆç†èŒƒå›´
        clipped_ratio = np.clip(coupling_ratio, 0.0, 1.0)

        return {
            'coupling_ratio': clipped_ratio,
            'edge_decoupling_ratio': 1.0 - clipped_ratio,
            'confidence': 0.7,  # ä¸­ç­‰ç½®ä¿¡åº¦
            'source': 'clipped',
            'warning': warning_msg
        }

    def _handle_coupling_calculation_error(self, exception):
        """å¤„ç†è€¦åˆè®¡ç®—å¼‚å¸¸"""
        error_entry = {
            'metric': 'coupling_metrics',
            'timestamp': time.time(),
            'exception': str(exception),
            'exception_type': type(exception).__name__
        }
        self.error_history.append(error_entry)

        # ä½¿ç”¨å†å²æ•°æ®å›é€€
        coupling_estimate = self._get_historical_estimate('coupling_ratio', 0.4)

        return {
            'coupling_ratio': coupling_estimate,
            'edge_decoupling_ratio': 1.0 - coupling_estimate,
            'confidence': 0.1,  # å¾ˆä½çš„ç½®ä¿¡åº¦
            'source': 'exception_fallback',
            'exception': str(exception)
        }

    def _get_historical_estimate(self, metric_name, default_value):
        """åŸºäºå†å²æ•°æ®è·å–ä¼°è®¡å€¼"""
        if metric_name in self.metrics_history:
            valid_history = [
                entry['value'] for entry in self.metrics_history[metric_name][-10:]
                if entry['confidence'] > 0.8
            ]
            if valid_history:
                return np.mean(valid_history)

        return default_value

    def _record_successful_calculation(self, metric_name, value):
        """è®°å½•æˆåŠŸçš„è®¡ç®—ç»“æœ"""
        self.metrics_history[metric_name].append({
            'value': value,
            'confidence': 1.0,
            'timestamp': time.time()
        })

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.metrics_history[metric_name]) > 50:
            self.metrics_history[metric_name] = self.metrics_history[metric_name][-50:]


class DataIntegrityManager:
    """
    æ•°æ®å®Œæ•´æ€§ç®¡ç†å™¨ï¼Œç¡®ä¿æ•°æ®è´¨é‡å’Œç³»ç»Ÿé²æ£’æ€§
    """

    def __init__(self, config=None):
        self.config = config or {}
        self.missing_data_policy = config.get('missing_data_policy', 'adaptive')
        self.validation_rules = self._setup_validation_rules()
        self.completion_log = []

    def validate_hetero_data(self, hetero_data):
        """
        å…¨é¢éªŒè¯å¼‚æ„å›¾æ•°æ®
        """
        validation_report = {
            'valid': True,
            'errors': [],
            'warnings': [],
            'data_quality_score': 1.0,
            'missing_features': []
        }

        # æ£€æŸ¥å¿…éœ€çš„èŠ‚ç‚¹ç±»å‹
        required_node_types = self.config.get('required_node_types', ['bus'])
        for node_type in required_node_types:
            if node_type not in hetero_data.x_dict:
                validation_report['errors'].append(
                    f"ç¼ºå°‘å¿…éœ€çš„èŠ‚ç‚¹ç±»å‹: {node_type}"
                )
                validation_report['valid'] = False

        # æ£€æŸ¥èŠ‚ç‚¹ç‰¹å¾å®Œæ•´æ€§
        if 'bus' in hetero_data.x_dict:
            feature_report = self._validate_bus_features(hetero_data.x_dict['bus'])
            validation_report['warnings'].extend(feature_report['warnings'])
            validation_report['missing_features'].extend(feature_report['missing_features'])
            validation_report['data_quality_score'] *= feature_report['quality_score']

        # æ£€æŸ¥è¾¹æ•°æ®
        edge_report = self._validate_edge_data(hetero_data)
        validation_report['warnings'].extend(edge_report['warnings'])
        validation_report['data_quality_score'] *= edge_report['quality_score']

        return validation_report

    def handle_missing_data(self, hetero_data, validation_report):
        """
        æ ¹æ®ç­–ç•¥å¤„ç†ç¼ºå¤±æ•°æ®
        """
        if validation_report['valid'] and validation_report['data_quality_score'] > 0.8:
            # æ•°æ®è´¨é‡è‰¯å¥½ï¼Œç›´æ¥è¿”å›
            return hetero_data, 'original'

        if self.missing_data_policy == 'strict':
            # ä¸¥æ ¼æ¨¡å¼ï¼šæ‹’ç»å¤„ç†
            raise ValueError(
                "æ•°æ®è´¨é‡ä¸æ»¡è¶³è¦æ±‚:\n" +
                "\n".join(validation_report['errors']) +
                "\nå»ºè®®ï¼šæ£€æŸ¥è¾“å…¥æ•°æ®æˆ–ä½¿ç”¨ 'adaptive' ç­–ç•¥"
            )

        elif self.missing_data_policy == 'adaptive':
            # è‡ªé€‚åº”æ¨¡å¼ï¼šæ™ºèƒ½è¡¥å…¨
            return self._intelligent_data_completion(hetero_data, validation_report)

        elif self.missing_data_policy == 'fallback':
            # å›é€€æ¨¡å¼ï¼šä½¿ç”¨å¤‡é€‰æ•°æ®æº
            return self._use_fallback_data(hetero_data, validation_report)

    def _intelligent_data_completion(self, hetero_data, validation_report):
        """
        æ™ºèƒ½æ•°æ®è¡¥å…¨
        """
        completed_data = hetero_data.clone() if hasattr(hetero_data, 'clone') else hetero_data
        completion_log = []

        # å¤„ç†ç¼ºå¤±çš„è´Ÿè·æ•°æ®
        if 'active_load' in validation_report['missing_features']:
            completed_data, log = self._estimate_missing_loads(completed_data)
            completion_log.extend(log)

        # å¤„ç†ç¼ºå¤±çš„å‘ç”µæ•°æ®
        if 'active_generation' in validation_report['missing_features']:
            completed_data, log = self._estimate_missing_generation(completed_data)
            completion_log.extend(log)

        # ç”Ÿæˆè¡¥å…¨æŠ¥å‘Š
        self._generate_completion_report(completion_log)

        return completed_data, 'completed'

    def _validate_bus_features(self, bus_features):
        """éªŒè¯æ¯çº¿ç‰¹å¾æ•°æ®"""
        report = {
            'warnings': [],
            'missing_features': [],
            'quality_score': 1.0
        }

        expected_features = {
            0: 'active_load',      # æœ‰åŠŸè´Ÿè½½
            1: 'reactive_load',    # æ— åŠŸè´Ÿè½½
            2: 'active_generation', # æœ‰åŠŸå‘ç”µ
        }

        # æ£€æŸ¥ç‰¹å¾ç»´åº¦
        if bus_features.shape[1] < 3:
            report['warnings'].append(
                f"æ¯çº¿ç‰¹å¾ç»´åº¦ä¸è¶³: {bus_features.shape[1]} < 3"
            )
            report['quality_score'] *= 0.7

        # æ£€æŸ¥æ¯ä¸ªç‰¹å¾çš„è´¨é‡
        for col_idx, feature_name in expected_features.items():
            if col_idx < bus_features.shape[1]:
                feature_data = bus_features[:, col_idx]

                # æ£€æŸ¥æ˜¯å¦å…¨ä¸ºé›¶ï¼ˆå¯èƒ½è¡¨ç¤ºç¼ºå¤±ï¼‰
                if torch.all(feature_data == 0):
                    report['missing_features'].append(feature_name)
                    report['warnings'].append(f"{feature_name}: æ‰€æœ‰å€¼ä¸ºé›¶ï¼Œå¯èƒ½ç¼ºå¤±")
                    report['quality_score'] *= 0.5

                # æ£€æŸ¥NaNå€¼
                nan_count = torch.isnan(feature_data).sum().item()
                if nan_count > 0:
                    report['warnings'].append(
                        f"{feature_name}: {nan_count}/{len(feature_data)} ä¸ªNaNå€¼"
                    )
                    report['quality_score'] *= (1 - nan_count / len(feature_data))
            else:
                report['missing_features'].append(feature_name)
                report['quality_score'] *= 0.8

        return report

    def _validate_edge_data(self, hetero_data):
        """éªŒè¯è¾¹æ•°æ®"""
        report = {
            'warnings': [],
            'quality_score': 1.0
        }

        edge_type = ('bus', 'connects', 'bus')

        # æ£€æŸ¥è¾¹ç´¢å¼•
        if edge_type not in hetero_data.edge_index_dict:
            report['warnings'].append("ç¼ºå°‘è¾¹ç´¢å¼•æ•°æ®")
            report['quality_score'] = 0.1
            return report

        # æ£€æŸ¥è¾¹å±æ€§
        if edge_type not in hetero_data.edge_attr_dict:
            report['warnings'].append("ç¼ºå°‘è¾¹å±æ€§æ•°æ®")
            report['quality_score'] *= 0.5

        return report

    def _estimate_missing_loads(self, hetero_data):
        """åŸºäºç»Ÿè®¡æ¨¡å‹ä¼°ç®—ç¼ºå¤±çš„è´Ÿè·æ•°æ®"""
        completion_log = []

        if 'bus' in hetero_data.x_dict:
            bus_features = hetero_data.x_dict['bus']
            num_buses = bus_features.shape[0]

            # åŸºäºèŠ‚ç‚¹åº¦æ•°ä¼°ç®—è´Ÿè·
            node_degrees = self._calculate_node_degrees(hetero_data)

            # å…¸å‹è´Ÿè·å¯†åº¦ï¼š10-50 MW per node
            base_load = 20.0  # MW

            # åŸºäºåº¦æ•°çš„è´Ÿè·åˆ†é…
            estimated_loads = base_load * (node_degrees / node_degrees.mean())

            # æ·»åŠ éšæœºæ‰°åŠ¨
            noise = torch.randn_like(estimated_loads) * 5.0
            estimated_loads = torch.clamp(estimated_loads + noise, 5.0, 100.0)

            # æ›´æ–°ç‰¹å¾
            if bus_features.shape[1] > 0:
                bus_features[:, 0] = estimated_loads

            completion_log.append({
                'type': 'load_estimation',
                'method': 'degree_based',
                'count': num_buses,
                'mean_value': estimated_loads.mean().item()
            })

        return hetero_data, completion_log

    def _estimate_missing_generation(self, hetero_data):
        """ä¼°ç®—ç¼ºå¤±çš„å‘ç”µæ•°æ®"""
        completion_log = []

        if 'bus' in hetero_data.x_dict:
            bus_features = hetero_data.x_dict['bus']
            num_buses = bus_features.shape[0]

            # å‡è®¾20%çš„èŠ‚ç‚¹æœ‰å‘ç”µæœº
            num_generators = max(1, num_buses // 5)

            # éšæœºé€‰æ‹©å‘ç”µæœºèŠ‚ç‚¹
            generator_indices = torch.randperm(num_buses)[:num_generators]

            # ä¼°ç®—å‘ç”µå®¹é‡
            total_load = bus_features[:, 0].sum() if bus_features.shape[1] > 0 else num_buses * 20.0
            total_generation = total_load * 1.2  # 120%çš„è´Ÿè·è¦†ç›–

            generation_per_unit = total_generation / num_generators

            # åˆå§‹åŒ–å‘ç”µæ•°æ®
            if bus_features.shape[1] > 2:
                bus_features[:, 2] = 0.0  # æ¸…é›¶
                bus_features[generator_indices, 2] = generation_per_unit

            completion_log.append({
                'type': 'generation_estimation',
                'method': 'random_allocation',
                'generator_count': num_generators,
                'total_generation': total_generation.item() if hasattr(total_generation, 'item') else total_generation
            })

        return hetero_data, completion_log

    def _calculate_node_degrees(self, hetero_data):
        """è®¡ç®—èŠ‚ç‚¹åº¦æ•°"""
        edge_type = ('bus', 'connects', 'bus')

        if edge_type not in hetero_data.edge_index_dict:
            # å¦‚æœæ²¡æœ‰è¾¹æ•°æ®ï¼Œè¿”å›å‡åŒ€åº¦æ•°
            num_nodes = hetero_data.x_dict['bus'].shape[0]
            return torch.ones(num_nodes) * 2.0

        edge_index = hetero_data.edge_index_dict[edge_type]
        num_nodes = hetero_data.x_dict['bus'].shape[0]

        degrees = torch.zeros(num_nodes)
        for i in range(edge_index.shape[1]):
            degrees[edge_index[0, i]] += 1
            degrees[edge_index[1, i]] += 1

        return degrees

    def _generate_completion_report(self, completion_log):
        """ç”Ÿæˆæ•°æ®è¡¥å…¨æŠ¥å‘Š"""
        if not completion_log:
            return

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç®€æ´æ¨¡å¼
        try:
            from code.src.rich_output import rich_debug
            rich_debug("æ•°æ®è¡¥å…¨æŠ¥å‘Š:", category="scenario")
            for entry in completion_log:
                rich_debug(f"  - {entry['type']}: {entry['method']}", category="scenario")
                if 'count' in entry:
                    rich_debug(f"    å¤„ç†èŠ‚ç‚¹æ•°: {entry['count']}", category="scenario")
                if 'mean_value' in entry:
                    rich_debug(f"    å¹³å‡å€¼: {entry['mean_value']:.2f}", category="scenario")
        except ImportError:
            # å¤‡ç”¨æ ‡å‡†è¾“å‡º
            print("ğŸ“‹ æ•°æ®è¡¥å…¨æŠ¥å‘Š:")
            for entry in completion_log:
                print(f"  - {entry['type']}: {entry['method']}")
                if 'count' in entry:
                    print(f"    å¤„ç†èŠ‚ç‚¹æ•°: {entry['count']}")
                if 'mean_value' in entry:
                    print(f"    å¹³å‡å€¼: {entry['mean_value']:.2f}")

    def _setup_validation_rules(self):
        """è®¾ç½®éªŒè¯è§„åˆ™"""
        return {
            'min_data_quality_score': self.config.get('min_data_quality_score', 0.5),
            'required_features': self.config.get('required_features', ['active_load']),
            'allow_missing_generation': self.config.get('allow_missing_generation', True)
        }


class RewardFunction:
    """
    è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±å‡½æ•°ç³»ç»Ÿ

    å®ç°åŸºäºåŠ¿å‡½æ•°ç†è®ºçš„è‡ªé€‚åº”è´¨é‡å¯¼å‘æ¿€åŠ±ç»“æ„ï¼š
    1. è´¨é‡åˆ†æ•°è®¡ç®—ï¼šç»Ÿä¸€çš„è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œæ”¯æŒè·¨ç½‘ç»œé€‚åº”æ€§
    2. åŠ¿å‡½æ•°ä¸»å¥–åŠ±ï¼šåŸºäºè´¨é‡åˆ†æ•°çš„ç›¸å¯¹æ”¹å–„ï¼Œé›¶å›ºå®šé˜ˆå€¼ä¾èµ–
    3. å¹³å°æœŸæ£€æµ‹ï¼šæ™ºèƒ½æ£€æµ‹è´¨é‡æ”¹å–„å¹³å°æœŸï¼Œæ”¯æŒæ—©åœæœºåˆ¶
    4. æ•ˆç‡å¥–åŠ±ï¼šåœ¨å¹³å°æœŸæ¿€æ´»çš„æ•ˆç‡æ¿€åŠ±ï¼Œé¼“åŠ±å¿«é€Ÿæ”¶æ•›

    æ ¸å¿ƒç»„ä»¶ï¼š
    - _compute_quality_score(): ç»Ÿä¸€è´¨é‡åˆ†æ•°è®¡ç®—
    - plateau_detector: å¹³å°æœŸæ£€æµ‹å™¨
    - previous_quality_score: å‰ä¸€æ­¥è´¨é‡åˆ†æ•°ç¼“å­˜
    - æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤ï¼šæ‰€æœ‰æ•°å­¦è¿ç®—éƒ½æœ‰epsilonä¿æŠ¤
    """

    def __init__(self,
                 hetero_data: HeteroData,
                 config: Dict[str, Any] = None,
                 device: torch.device = None):
        """
        åˆå§‹åŒ–è‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±å‡½æ•°

        Args:
            hetero_data: å¼‚æ„å›¾æ•°æ®
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æƒé‡ã€é˜ˆå€¼ç­‰å‚æ•°
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device or torch.device('cpu')
        self.config = config or {}

        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å’Œå¤„ç†
        self.data_manager = DataIntegrityManager(
            config=self.config.get('data_integrity', {
                'missing_data_policy': 'adaptive',
                'min_data_quality_score': 0.3
            })
        )

        # éªŒè¯å’Œå¤„ç†æ•°æ®
        validation_report = self.data_manager.validate_hetero_data(hetero_data)

        if validation_report['data_quality_score'] < 0.2:
            raise ValueError(
                f"æ•°æ®è´¨é‡åˆ†æ•° {validation_report['data_quality_score']:.2f} è¿‡ä½\n"
                f"é”™è¯¯: {validation_report['errors']}\n"
                f"è­¦å‘Š: {validation_report['warnings']}"
            )

        # å¤„ç†ç¼ºå¤±æ•°æ®
        self.hetero_data, data_source = self.data_manager.handle_missing_data(
            hetero_data, validation_report
        )
        self.hetero_data = self.hetero_data.to(self.device)

        # è®°å½•æ•°æ®æ¥æº
        if data_source != 'original':
            warning_msg = (
                f"ä½¿ç”¨ {data_source} æ•°æ®æºï¼Œ"
                f"è´¨é‡åˆ†æ•°: {validation_report['data_quality_score']:.2f}"
            )
            warnings.warn(warning_msg)

        # ä»é…ç½®ä¸­è·å–æƒé‡å’Œè‡ªé€‚åº”è´¨é‡é…ç½®
        self.weights = self._load_weights()
        self.adaptive_quality_config = self._load_adaptive_quality_config()

        # åˆå§‹åŒ–å¹³å°æœŸæ£€æµ‹å™¨
        self.plateau_detector = self._create_plateau_detector()

        # å‰ä¸€æ­¥è´¨é‡åˆ†æ•°ç¼“å­˜
        self.previous_quality_score = None
        self.previous_metrics = None  # ä¿æŒå‘åå…¼å®¹

        # å½“å‰æ­¥æ•°ï¼ˆç”¨äºæ•ˆç‡å¥–åŠ±è®¡ç®—ï¼‰
        self.current_step = 0
        self.max_steps = self.config.get('max_steps', 200)

        # é²æ£’æŒ‡æ ‡è®¡ç®—å™¨
        self.metrics_calculator = RobustMetricsCalculator(
            config=self.config.get('error_handling', {
                'fallback_strategy': 'conservative'
            })
        )

        # é¢„è®¡ç®—å¸¸ç”¨æ•°æ®
        self._setup_cached_data()

        # æ•°å€¼ç¨³å®šæ€§å‚æ•°
        self.epsilon = 1e-9
        
    def _load_weights(self) -> Dict[str, float]:
        """ä»é…ç½®åŠ è½½æƒé‡å‚æ•°"""
        default_weights = {
            # è´¨é‡åˆ†æ•°æƒé‡ï¼ˆæ›¿ä»£åŸæœ‰å›ºå®šé˜ˆå€¼ï¼‰
            'cv_weight': 0.4,
            'coupling_weight': 0.3,
            'power_weight': 0.3,
            # ä¿ç•™ç»ˆå±€å¥–åŠ±æƒé‡ä»¥å‘åå…¼å®¹
            'final_balance_weight': 0.4,
            'final_decoupling_weight': 0.4,
            'final_power_weight': 0.2,
        }

        adaptive_quality_config = self.config.get('adaptive_quality', {})
        quality_weights = adaptive_quality_config.get('quality_weights', {})

        # åˆå¹¶é…ç½®ï¼Œä¼˜å…ˆçº§ï¼šadaptive_quality > default
        return {**default_weights, **quality_weights}

    def _load_adaptive_quality_config(self) -> Dict[str, Any]:
        """ä»é…ç½®åŠ è½½è‡ªé€‚åº”è´¨é‡é…ç½®"""
        default_config = {
            'plateau_detection': {
                'window_size': 15,
                'min_improvement_rate': 0.005,
                'stability_threshold': 0.8,
                'min_percentile': 0.7,
                'confidence_threshold': 0.8
            },
            'efficiency_reward': {
                'lambda': 0.5,
                'early_stop_confidence': 0.85
            }
        }

        config_adaptive = self.config.get('adaptive_quality', {})

        # æ·±åº¦åˆå¹¶é…ç½®
        result = default_config.copy()
        if config_adaptive:
            if 'plateau_detection' in config_adaptive:
                result['plateau_detection'].update(config_adaptive['plateau_detection'])

            if 'efficiency_reward' in config_adaptive:
                result['efficiency_reward'].update(config_adaptive['efficiency_reward'])

        return result

    def _create_plateau_detector(self) -> QualityPlateauDetector:
        """åˆ›å»ºå¹³å°æœŸæ£€æµ‹å™¨"""
        plateau_config = self.adaptive_quality_config['plateau_detection']
        return QualityPlateauDetector(
            window_size=plateau_config['window_size'],
            min_improvement_rate=plateau_config['min_improvement_rate'],
            stability_threshold=plateau_config['stability_threshold'],
            min_percentile=plateau_config['min_percentile'],
            confidence_threshold=plateau_config['confidence_threshold']
        )
        
    def _setup_cached_data(self):
        """é¢„è®¡ç®—é¢‘ç¹ä½¿ç”¨çš„æ•°æ® - æ”¹è¿›çš„æ•°æ®å¤„ç†"""
        # å®‰å…¨æå–èŠ‚ç‚¹è´Ÿè½½å’Œå‘ç”µæ•°æ®
        self._safe_extract_power_data()

        # è¾¹ä¿¡æ¯ï¼ˆç”¨äºè®¡ç®—å¯¼çº³ï¼‰
        self._extract_edge_info()

    def _safe_extract_power_data(self):
        """å®‰å…¨æå–åŠŸç‡æ•°æ®ï¼Œé¿å…åˆ›å»ºè™šå‡é»˜è®¤æ•°æ®"""
        if 'bus' not in self.hetero_data.x_dict:
            raise ValueError(
                "ç¼ºå°‘å¿…éœ€çš„'bus'èŠ‚ç‚¹æ•°æ®ã€‚"
                "æ•°æ®å®Œæ•´æ€§æ£€æŸ¥åº”è¯¥åœ¨æ­¤ä¹‹å‰æ•è·æ­¤é—®é¢˜ã€‚"
            )

        bus_features = self.hetero_data.x_dict['bus']
        num_nodes = bus_features.shape[0]

        # æå–æœ‰åŠŸè´Ÿè½½ï¼ˆç¬¬0åˆ—ï¼‰
        if bus_features.shape[1] > 0:
            self.node_loads = bus_features[:, 0]

            # éªŒè¯è´Ÿè½½æ•°æ®çš„åˆç†æ€§
            if torch.all(self.node_loads == 0):
                warnings.warn(
                    "æ‰€æœ‰èŠ‚ç‚¹è´Ÿè½½ä¸ºé›¶ï¼Œè¿™å¯èƒ½è¡¨ç¤ºæ•°æ®ç¼ºå¤±ã€‚"
                    "å»ºè®®æ£€æŸ¥æ•°æ®æºæˆ–ä½¿ç”¨æ•°æ®è¡¥å…¨åŠŸèƒ½ã€‚"
                )
        else:
            raise ValueError("æ¯çº¿ç‰¹å¾æ•°æ®ä¸ºç©ºï¼Œæ— æ³•æå–è´Ÿè½½ä¿¡æ¯")

        # æå–æœ‰åŠŸå‘ç”µï¼ˆç¬¬2åˆ—ï¼Œå¦‚æœå­˜åœ¨ï¼‰
        if bus_features.shape[1] > 2:
            self.node_generation = bus_features[:, 2]
        else:
            # æ™ºèƒ½ä¼°ç®—å‘ç”µæ•°æ®è€Œä¸æ˜¯ç®€å•ä½¿ç”¨é›¶å€¼
            self.node_generation = self._estimate_missing_generation_data()
            warnings.warn(
                "ç¼ºå°‘å‘ç”µæ•°æ®ï¼Œä½¿ç”¨æ™ºèƒ½ä¼°ç®—å€¼ã€‚å»ºè®®æä¾›å®Œæ•´çš„å‘ç”µæ•°æ®ä»¥æé«˜å‡†ç¡®æ€§ã€‚"
            )

        # æ•°æ®è´¨é‡æ£€æŸ¥
        self._validate_power_data_quality()

    def _validate_power_data_quality(self):
        """éªŒè¯åŠŸç‡æ•°æ®è´¨é‡"""
        quality_issues = []

        # æ£€æŸ¥è´Ÿè½½æ•°æ®
        load_nan_count = torch.isnan(self.node_loads).sum().item()
        if load_nan_count > 0:
            quality_issues.append(f"è´Ÿè½½æ•°æ®åŒ…å« {load_nan_count} ä¸ªNaNå€¼")

        load_inf_count = torch.isinf(self.node_loads).sum().item()
        if load_inf_count > 0:
            quality_issues.append(f"è´Ÿè½½æ•°æ®åŒ…å« {load_inf_count} ä¸ªInfå€¼")

        # æ£€æŸ¥å‘ç”µæ•°æ®
        gen_nan_count = torch.isnan(self.node_generation).sum().item()
        if gen_nan_count > 0:
            quality_issues.append(f"å‘ç”µæ•°æ®åŒ…å« {gen_nan_count} ä¸ªNaNå€¼")

        # æ£€æŸ¥åŠŸç‡å¹³è¡¡
        total_load = self.node_loads.sum().item()
        total_generation = self.node_generation.sum().item()

        if total_load > 0 and total_generation > 0:
            imbalance_ratio = abs(total_generation - total_load) / total_load
            if imbalance_ratio > 0.5:  # 50%ä»¥ä¸Šçš„ä¸å¹³è¡¡
                quality_issues.append(
                    f"åŠŸç‡ä¸¥é‡ä¸å¹³è¡¡: è´Ÿè½½={total_load:.1f}, å‘ç”µ={total_generation:.1f}, "
                    f"ä¸å¹³è¡¡ç‡={imbalance_ratio:.1%}"
                )

        # è®°å½•è´¨é‡é—®é¢˜
        if quality_issues:
            warning_msg = "åŠŸç‡æ•°æ®è´¨é‡é—®é¢˜:\n" + "\n".join(f"  - {issue}" for issue in quality_issues)
            warnings.warn(warning_msg)

            # è®°å½•åˆ°æ•°æ®ç®¡ç†å™¨
            if hasattr(self.data_manager, 'completion_log'):
                self.data_manager.completion_log.append({
                    'type': 'power_data_quality_check',
                    'issues': quality_issues,
                    'total_load': total_load,
                    'total_generation': total_generation
                })

    def _estimate_missing_generation_data(self) -> torch.Tensor:
        """
        æ™ºèƒ½ä¼°ç®—ç¼ºå¤±çš„å‘ç”µæ•°æ®

        ä½¿ç”¨å¤šç§ç­–ç•¥æ¥ä¼°ç®—å‘ç”µæ•°æ®ï¼Œè€Œä¸æ˜¯ç®€å•çš„é›¶å‘é‡ï¼š
        1. åŸºäºè´Ÿè½½åˆ†å¸ƒçš„æ¯”ä¾‹ä¼°ç®—
        2. åŸºäºèŠ‚ç‚¹ç±»å‹çš„å¯å‘å¼ä¼°ç®—
        3. åŸºäºç½‘ç»œæ‹“æ‰‘çš„ä¼°ç®—

        Returns:
            ä¼°ç®—çš„å‘ç”µæ•°æ®å¼ é‡
        """
        num_nodes = self.node_loads.shape[0]

        # ç­–ç•¥1: åŸºäºè´Ÿè½½åˆ†å¸ƒä¼°ç®—
        total_load = torch.sum(torch.abs(self.node_loads))

        if total_load > 0:
            # å‡è®¾æ€»å‘ç”µé‡ç•¥å¤§äºæ€»è´Ÿè½½ï¼ˆè€ƒè™‘æŸè€—ï¼‰
            total_generation_estimate = total_load * 1.05  # 5%çš„æŸè€—ä½™é‡

            # åŸºäºè´Ÿè½½åˆ†å¸ƒåˆ†é…å‘ç”µ
            load_weights = torch.abs(self.node_loads) / total_load

            # è¯†åˆ«å¯èƒ½çš„å‘ç”µèŠ‚ç‚¹ï¼ˆé«˜è´Ÿè½½èŠ‚ç‚¹æ›´å¯èƒ½æœ‰å‘ç”µæœºï¼‰
            load_percentile_80 = torch.quantile(torch.abs(self.node_loads), 0.8)
            potential_gen_mask = torch.abs(self.node_loads) >= load_percentile_80

            # åˆå§‹åŒ–å‘ç”µæ•°æ®
            estimated_generation = torch.zeros_like(self.node_loads)

            if potential_gen_mask.any():
                # åœ¨æ½œåœ¨å‘ç”µèŠ‚ç‚¹ä¸­åˆ†é…å‘ç”µé‡
                gen_weights = load_weights[potential_gen_mask]
                gen_weights = gen_weights / gen_weights.sum()

                estimated_generation[potential_gen_mask] = total_generation_estimate * gen_weights
            else:
                # å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„å‘ç”µèŠ‚ç‚¹ï¼Œå‡åŒ€åˆ†é…åˆ°è´Ÿè½½è¾ƒå¤§çš„èŠ‚ç‚¹
                top_load_indices = torch.topk(torch.abs(self.node_loads),
                                            min(3, num_nodes)).indices
                estimated_generation[top_load_indices] = total_generation_estimate / len(top_load_indices)

        else:
            # å¦‚æœæ²¡æœ‰è´Ÿè½½æ•°æ®ï¼Œä½¿ç”¨åŸºäºæ‹“æ‰‘çš„ä¼°ç®—
            estimated_generation = self._estimate_generation_from_topology()

        # ç­–ç•¥2: åŸºäºèŠ‚ç‚¹ç‰¹å¾çš„è°ƒæ•´ï¼ˆå¦‚æœæœ‰èŠ‚ç‚¹ç±»å‹ä¿¡æ¯ï¼‰
        if hasattr(self.hetero_data, 'x_dict') and 'bus' in self.hetero_data.x_dict:
            bus_features = self.hetero_data.x_dict['bus']

            # æ£€æŸ¥æ˜¯å¦æœ‰èŠ‚ç‚¹ç±»å‹ä¿¡æ¯ï¼ˆé€šå¸¸åœ¨ç‰¹å¾çš„åå‡ åˆ—ï¼‰
            if bus_features.shape[1] > 10:  # å‡è®¾æœ‰è¶³å¤Ÿçš„ç‰¹å¾åˆ—
                # å°è¯•è¯†åˆ«PVèŠ‚ç‚¹å’Œå¹³è¡¡èŠ‚ç‚¹ï¼ˆå®ƒä»¬é€šå¸¸æœ‰å‘ç”µæœºï¼‰
                # è¿™æ˜¯ä¸€ä¸ªå¯å‘å¼æ–¹æ³•ï¼ŒåŸºäºç‰¹å¾æ¨¡å¼
                for i in range(max(0, bus_features.shape[1] - 5), bus_features.shape[1]):
                    feature_col = bus_features[:, i]

                    # æ£€æŸ¥æ˜¯å¦æ˜¯äºŒè¿›åˆ¶ç‰¹å¾ï¼ˆå¯èƒ½è¡¨ç¤ºèŠ‚ç‚¹ç±»å‹ï¼‰
                    unique_values = torch.unique(feature_col)
                    if len(unique_values) <= 3 and torch.all((unique_values >= 0) & (unique_values <= 3)):
                        # å¯èƒ½æ˜¯èŠ‚ç‚¹ç±»å‹ç‰¹å¾
                        # PVèŠ‚ç‚¹(2)å’Œå¹³è¡¡èŠ‚ç‚¹(3)é€šå¸¸æœ‰å‘ç”µæœº
                        gen_node_mask = (feature_col == 2) | (feature_col == 3)

                        if gen_node_mask.any():
                            # è°ƒæ•´è¿™äº›èŠ‚ç‚¹çš„å‘ç”µé‡
                            boost_factor = 1.5
                            estimated_generation[gen_node_mask] *= boost_factor

        # ç­–ç•¥3: æ•°å€¼åˆç†æ€§æ£€æŸ¥å’Œè°ƒæ•´
        estimated_generation = self._validate_and_adjust_generation(estimated_generation)

        return estimated_generation

    def _estimate_generation_from_topology(self) -> torch.Tensor:
        """åŸºäºç½‘ç»œæ‹“æ‰‘ä¼°ç®—å‘ç”µåˆ†å¸ƒ"""
        num_nodes = self.node_loads.shape[0]

        if hasattr(self, 'edge_index') and self.edge_index.shape[1] > 0:
            # è®¡ç®—èŠ‚ç‚¹åº¦æ•°
            node_degrees = torch.zeros(num_nodes, device=self.device)

            for i in range(self.edge_index.shape[1]):
                node1, node2 = self.edge_index[:, i]
                if node1 < num_nodes:
                    node_degrees[node1] += 1
                if node2 < num_nodes:
                    node_degrees[node2] += 1

            # é«˜åº¦æ•°èŠ‚ç‚¹æ›´å¯èƒ½æ˜¯å‘ç”µèŠ‚ç‚¹
            degree_percentile_70 = torch.quantile(node_degrees, 0.7)
            high_degree_mask = node_degrees >= degree_percentile_70

            estimated_generation = torch.zeros_like(self.node_loads)

            if high_degree_mask.any():
                # åŸºäºåº¦æ•°åˆ†é…å‘ç”µé‡
                degree_weights = node_degrees[high_degree_mask]
                degree_weights = degree_weights / degree_weights.sum()

                # å‡è®¾é€‚åº¦çš„æ€»å‘ç”µé‡
                total_gen_estimate = num_nodes * 0.1  # æ¯ä¸ªèŠ‚ç‚¹å¹³å‡0.1 p.u.
                estimated_generation[high_degree_mask] = total_gen_estimate * degree_weights

            return estimated_generation
        else:
            # æ²¡æœ‰æ‹“æ‰‘ä¿¡æ¯ï¼Œä½¿ç”¨æœ€ä¿å®ˆçš„ä¼°ç®—
            return torch.zeros(num_nodes, device=self.device)

    def _validate_and_adjust_generation(self, generation: torch.Tensor) -> torch.Tensor:
        """éªŒè¯å’Œè°ƒæ•´å‘ç”µæ•°æ®çš„åˆç†æ€§"""
        # 1. ç¡®ä¿éè´Ÿå€¼
        generation = torch.clamp(generation, min=0.0)

        # 2. æ£€æŸ¥æ€»å‘ç”µé‡æ˜¯å¦åˆç†
        total_load = torch.sum(torch.abs(self.node_loads))
        total_generation = torch.sum(generation)

        if total_load > 0:
            # å‘ç”µé‡åº”è¯¥åœ¨è´Ÿè½½çš„90%-120%ä¹‹é—´
            min_gen = total_load * 0.9
            max_gen = total_load * 1.2

            if total_generation < min_gen:
                # å‘ç”µé‡å¤ªå°‘ï¼ŒæŒ‰æ¯”ä¾‹å¢åŠ 
                scale_factor = min_gen / (total_generation + 1e-9)
                generation = generation * scale_factor
            elif total_generation > max_gen:
                # å‘ç”µé‡å¤ªå¤šï¼ŒæŒ‰æ¯”ä¾‹å‡å°‘
                scale_factor = max_gen / total_generation
                generation = generation * scale_factor

        # 3. é™åˆ¶å•ä¸ªèŠ‚ç‚¹çš„å‘ç”µé‡
        max_single_gen = torch.sum(generation) * 0.4  # å•ä¸ªèŠ‚ç‚¹æœ€å¤š40%çš„æ€»å‘ç”µé‡
        generation = torch.clamp(generation, max=max_single_gen)

        # 4. ç¡®ä¿æ•°å€¼ç¨³å®šæ€§
        generation = torch.where(torch.isnan(generation),
                               torch.zeros_like(generation),
                               generation)
        generation = torch.where(torch.isinf(generation),
                               torch.zeros_like(generation),
                               generation)

        return generation

    def _extract_edge_info(self):
        """æ™ºèƒ½æå–è¾¹ä¿¡æ¯ç”¨äºå¯¼çº³è®¡ç®—"""
        if ('bus', 'connects', 'bus') in self.hetero_data.edge_index_dict:
            self.edge_index = self.hetero_data.edge_index_dict[('bus', 'connects', 'bus')]

            # æ™ºèƒ½æå–å¯¼çº³æ•°æ®
            self.edge_admittance, admittance_source = self._extract_admittance_data()

            # è®°å½•æ•°æ®æ¥æº
            if hasattr(self, 'logger'):
                if admittance_source != 'extracted':
                    self.logger.warning(f"å¯¼çº³æ•°æ®æ¥æº: {admittance_source}")
            elif admittance_source != 'extracted':
                print(f"âš ï¸ å¯¼çº³æ•°æ®æ¥æº: {admittance_source}")

        else:
            # å¦‚æœæ²¡æœ‰è¾¹ä¿¡æ¯ï¼Œåˆ›å»ºç©ºçš„
            self.edge_index = torch.empty((2, 0), dtype=torch.long, device=self.device)
            self.edge_admittance = torch.empty(0, device=self.device)

    def _extract_admittance_data(self):
        """
        æ™ºèƒ½æå–å¯¼çº³æ•°æ®ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•å¤šç§æ–¹æ³•

        è¿”å›:
            admittance: å¯¼çº³å¼ é‡
            source: æ•°æ®æ¥æºæ ‡è¯†
        """
        edge_type = ('bus', 'connects', 'bus')

        # æ–¹æ³•1: ä»è¾¹å±æ€§ç›´æ¥æå–
        if edge_type in self.hetero_data.edge_attr_dict:
            edge_attr = self.hetero_data.edge_attr_dict[edge_type]

            # å°è¯•è¯†åˆ«å¯¼çº³æ•°æ®
            admittance = self._identify_admittance_from_attributes(edge_attr)
            if admittance is not None:
                return admittance, 'extracted'

        # æ–¹æ³•2: ä»é˜»æŠ—è®¡ç®—å¯¼çº³
        if edge_type in self.hetero_data.edge_attr_dict:
            edge_attr = self.hetero_data.edge_attr_dict[edge_type]
            admittance = self._calculate_admittance_from_impedance(edge_attr)
            if admittance is not None:
                return admittance, 'calculated'

        # æ–¹æ³•3: åŸºäºç‰©ç†æ¨¡å‹ä¼°ç®—
        admittance = self._estimate_admittance_from_topology()
        if admittance is not None:
            return admittance, 'estimated'

        # æ–¹æ³•4: ä¿å®ˆé»˜è®¤å€¼ï¼ˆå¸¦è­¦å‘Šï¼‰
        return self._get_conservative_admittance_defaults(), 'default'

    def _identify_admittance_from_attributes(self, edge_attr):
        """
        ä»è¾¹å±æ€§ä¸­æ™ºèƒ½è¯†åˆ«å¯¼çº³æ•°æ®

        æ ¹æ®data_processing.pyä¸­çš„ç‰¹å¾é¡ºåºï¼š
        [r, x, b, z_magnitude, y, rateA, angle_diff, is_transformer, status]
        å¯¼çº³yåœ¨ç¬¬4åˆ—ï¼ˆç´¢å¼•4ï¼‰
        """
        if edge_attr.shape[1] <= 4:
            return None

        # æå–å¯¼çº³åˆ—ï¼ˆç¬¬4åˆ—ï¼‰
        admittance_candidate = edge_attr[:, 4]

        # æ£€æŸ¥å¯¼çº³å€¼çš„åˆç†æ€§
        # å¯¼çº³åº”è¯¥æ˜¯æ­£å€¼ï¼Œä¸”åœ¨åˆç†èŒƒå›´å†…
        if self._validate_admittance_values(admittance_candidate):
            # å–ç»å¯¹å€¼ç¡®ä¿ä¸ºæ­£
            return torch.abs(admittance_candidate)

        # å¦‚æœç¬¬4åˆ—ä¸åˆç†ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„åˆ—
        for col_idx in [3, 5]:  # z_magnitude, rateA
            if edge_attr.shape[1] > col_idx:
                candidate = edge_attr[:, col_idx]
                if self._validate_admittance_values(candidate):
                    return torch.abs(candidate)

        return None

    def _calculate_admittance_from_impedance(self, edge_attr):
        """
        ä»é˜»æŠ—å‚æ•°è®¡ç®—å¯¼çº³

        ç‰¹å¾é¡ºåºï¼š[r, x, b, z_magnitude, y, ...]
        """
        if edge_attr.shape[1] < 2:
            return None

        # æå–ç”µé˜»å’Œç”µæŠ—
        r = edge_attr[:, 0]  # ç”µé˜»
        x = edge_attr[:, 1]  # ç”µæŠ—

        # è®¡ç®—é˜»æŠ—æ¨¡é•¿
        z_squared = r**2 + x**2

        # é¿å…é™¤é›¶ï¼Œè®¾ç½®æœ€å°é˜»æŠ—å€¼
        min_impedance = 1e-6
        z_magnitude = torch.sqrt(z_squared.clamp(min=min_impedance**2))

        # è®¡ç®—å¯¼çº³ Y = 1/Z
        admittance = 1.0 / z_magnitude

        # éªŒè¯ç»“æœ
        if self._validate_admittance_values(admittance):
            return admittance

        return None

    def _estimate_admittance_from_topology(self):
        """
        åŸºäºç½‘ç»œæ‹“æ‰‘ä¼°ç®—å¯¼çº³
        """
        num_edges = self.edge_index.shape[1]
        if num_edges == 0:
            return torch.empty(0, device=self.device)

        # è®¡ç®—èŠ‚ç‚¹åº¦æ•°
        node_degrees = self._calculate_node_degrees()

        # åŸºäºè¿æ¥çš„èŠ‚ç‚¹åº¦æ•°ä¼°ç®—å¯¼çº³
        admittance_estimates = torch.zeros(num_edges, device=self.device)

        for i in range(num_edges):
            node1, node2 = self.edge_index[:, i]

            # åŸºäºèŠ‚ç‚¹åº¦æ•°çš„å¯å‘å¼ä¼°ç®—
            # é«˜åº¦æ•°èŠ‚ç‚¹é—´çš„è¿æ¥é€šå¸¸æœ‰æ›´é«˜çš„å¯¼çº³
            avg_degree = (node_degrees[node1] + node_degrees[node2]) / 2.0

            # å…¸å‹å¯¼çº³èŒƒå›´ï¼š0.5-5.0ï¼ŒåŸºäºåº¦æ•°è°ƒæ•´
            base_admittance = 2.0
            degree_factor = torch.clamp(avg_degree / 3.0, 0.5, 2.0)

            admittance_estimates[i] = base_admittance * degree_factor

        # æ·»åŠ éšæœºæ‰°åŠ¨ä»¥é¿å…å®Œå…¨ç›¸åŒçš„å€¼
        noise = torch.randn_like(admittance_estimates) * 0.1
        admittance_estimates = torch.clamp(admittance_estimates + noise, 0.5, 5.0)

        return admittance_estimates

    def _calculate_node_degrees(self):
        """è®¡ç®—èŠ‚ç‚¹åº¦æ•°"""
        num_nodes = max(self.edge_index.max().item() + 1,
                       len(self.hetero_data.x_dict.get('bus', torch.empty(0))))

        degrees = torch.zeros(num_nodes, device=self.device)

        for i in range(self.edge_index.shape[1]):
            node1, node2 = self.edge_index[:, i]
            degrees[node1] += 1
            degrees[node2] += 1

        return degrees

    def _get_conservative_admittance_defaults(self):
        """
        è·å–ä¿å®ˆçš„é»˜è®¤å¯¼çº³å€¼ï¼Œå¹¶è®°å½•è¯¦ç»†è­¦å‘Š
        """
        num_edges = self.edge_index.shape[1]

        # è®°å½•è¯¦ç»†è­¦å‘Š
        warning_msg = (
            f"æ— æ³•æå–æˆ–è®¡ç®—å¯¼çº³æ•°æ®ï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼ã€‚"
            f"è¾¹æ•°: {num_edges}ã€‚"
            f"è¿™å¯èƒ½å½±å“ç”µæ°”è§£è€¦è®¡ç®—çš„å‡†ç¡®æ€§ã€‚"
            f"å»ºè®®æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼æˆ–æä¾›å¯¼çº³ä¿¡æ¯ã€‚"
        )

        if hasattr(self, 'logger'):
            self.logger.warning(warning_msg)
        else:
            print(f"âš ï¸ {warning_msg}")

        if num_edges == 0:
            return torch.empty(0, device=self.device)

        # ä½¿ç”¨åŸºäºç½‘ç»œè§„æ¨¡çš„åˆç†é»˜è®¤å€¼
        # å…¸å‹è¾“ç”µçº¿è·¯å¯¼çº³èŒƒå›´ï¼š1-3 S
        mean_admittance = 2.0
        std_admittance = 0.3

        # ç”Ÿæˆæ­£æ€åˆ†å¸ƒçš„å¯¼çº³å€¼
        admittance = torch.normal(
            mean=mean_admittance,
            std=std_admittance,
            size=(num_edges,),
            device=self.device
        )

        # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        admittance = torch.clamp(torch.abs(admittance), 0.8, 4.0)

        return admittance

    def _validate_admittance_values(self, admittance):
        """
        éªŒè¯å¯¼çº³å€¼çš„ç‰©ç†åˆç†æ€§
        """
        # æ£€æŸ¥NaNå’ŒInf
        if torch.isnan(admittance).any() or torch.isinf(admittance).any():
            return False

        # æ£€æŸ¥æ˜¯å¦å…¨ä¸ºé›¶
        if torch.all(admittance == 0):
            return False

        # å–ç»å¯¹å€¼è¿›è¡ŒèŒƒå›´æ£€æŸ¥
        abs_admittance = torch.abs(admittance)

        # æ£€æŸ¥ç‰©ç†åˆç†èŒƒå›´ï¼ˆæ”¾å®½èŒƒå›´ä»¥é€‚åº”ä¸åŒçš„æ ‡å¹ºåŒ–ï¼‰
        # å…è®¸æ›´å¤§çš„èŒƒå›´ï¼š0.001-1000
        if (abs_admittance < 0.001).any() or (abs_admittance > 1000).any():
            return False

        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éé›¶å€¼
        non_zero_count = torch.sum(abs_admittance > 0.001).item()
        if non_zero_count < len(admittance) * 0.5:  # è‡³å°‘50%çš„å€¼åº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„
            return False

        return True

    def _compute_quality_score(self, partition: torch.Tensor) -> float:
        """
        è®¡ç®—ç»Ÿä¸€è´¨é‡åˆ†æ•°

        åŸºäºæŠ€æœ¯æ–¹æ¡ˆä¸­çš„å…¬å¼ï¼š
        Q(s) = 1 - normalize(wâ‚Â·CV + wâ‚‚Â·coupling_ratio + wâ‚ƒÂ·power_imbalance)

        Args:
            partition: å½“å‰åˆ†åŒºæ–¹æ¡ˆ [num_nodes]

        Returns:
            è´¨é‡åˆ†æ•° [0, 1]ï¼Œè¶Šå¤§è¶Šå¥½
        """
        try:
            # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
            metrics = self._compute_core_metrics(partition)

            cv = metrics.get('cv', 1.0)
            coupling_ratio = metrics.get('coupling_ratio', 1.0)
            power_imbalance = metrics.get('power_imbalance_normalized', 1.0)

            # å½’ä¸€åŒ–å¤„ç†
            normalized_cv = cv / (1 + cv)  # æ˜ å°„åˆ° [0, 1)
            normalized_coupling = coupling_ratio  # å·²ç»åœ¨ [0, 1]
            normalized_power = power_imbalance / (1 + power_imbalance)  # æ˜ å°„åˆ° [0, 1)

            # åŠ æƒç»„åˆï¼ˆè¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ï¼‰
            composite_badness = (
                self.weights['cv_weight'] * normalized_cv +
                self.weights['coupling_weight'] * normalized_coupling +
                self.weights['power_weight'] * normalized_power
            )

            # å½’ä¸€åŒ–åˆ°æƒé‡æ€»å’Œ
            total_weight = (
                self.weights['cv_weight'] +
                self.weights['coupling_weight'] +
                self.weights['power_weight']
            )

            if total_weight > 0:
                composite_badness = composite_badness / total_weight

            # è½¬æ¢ä¸ºè´¨é‡åˆ†æ•°ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
            quality_score = 1.0 - composite_badness

            # æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(quality_score) or np.isinf(quality_score):
                quality_score = 0.0

            return np.clip(quality_score, 0.0, 1.0)

        except Exception as e:
            print(f"è­¦å‘Šï¼šè´¨é‡åˆ†æ•°è®¡ç®—å‡ºç°å¼‚å¸¸: {e}")
            return 0.0

    def _compute_simple_relative_reward(self, prev_quality: float, curr_quality: float) -> float:
        """
        ç®€å•ç›¸å¯¹æ”¹è¿›å¥–åŠ± - è§£å†³è·¨åœºæ™¯è®­ç»ƒåå‘é—®é¢˜

        æ ¸å¿ƒæ€æƒ³ï¼šç›¸åŒçš„ç›¸å¯¹åŠªåŠ›åº”è¯¥è·å¾—ç›¸åŒçš„å¥–åŠ±å¹…åº¦
        - æ•…éšœåœºæ™¯: (0.42-0.40)/0.40 = 5%æ”¹è¿› â†’ å¥–åŠ±+0.05
        - æ­£å¸¸åœºæ™¯: (0.714-0.68)/0.68 = 5%æ”¹è¿› â†’ å¥–åŠ±+0.05

        è¿™ç¡®ä¿ç®—æ³•ä¸ä¼šåå‘ç®€å•åœºæ™¯ï¼Œåœ¨å›°éš¾åœºæ™¯(æ•…éšœã€é«˜è´Ÿè·)ä¸‹ä¹Ÿèƒ½è·å¾—å…¬å¹³æ¿€åŠ±

        Args:
            prev_quality: å‰ä¸€æ­¥è´¨é‡åˆ†æ•°
            curr_quality: å½“å‰è´¨é‡åˆ†æ•°

        Returns:
            ç›¸å¯¹æ”¹è¿›å¥–åŠ± [-1.0, 1.0]
        """
        try:
            if prev_quality > 0.01:  # é¿å…é™¤é›¶ï¼Œå¤„ç†è¾¹ç•Œæƒ…å†µ
                relative_improvement = (curr_quality - prev_quality) / prev_quality
            else:
                # ä»é›¶å¼€å§‹çš„æƒ…å†µï¼Œç›´æ¥ç”¨ç»å¯¹æ”¹è¿›
                relative_improvement = curr_quality - prev_quality

            # è½»å¾®è£å‰ªé¿å…æç«¯å€¼ï¼Œä¿æŒè®­ç»ƒç¨³å®šæ€§
            return np.clip(relative_improvement, -1.0, 1.0)

        except Exception as e:
            print(f"è­¦å‘Šï¼šç›¸å¯¹å¥–åŠ±è®¡ç®—å‡ºç°å¼‚å¸¸: {e}")
            return 0.0

    def _compute_core_metrics(self, partition: torch.Tensor) -> Dict[str, float]:
        """
        ä¸­å¿ƒåŒ–çš„æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—æ–¹æ³•
        
        é«˜æ•ˆè®¡ç®—æ‰€æœ‰åç»­å¥–åŠ±æ‰€éœ€çš„åŸºç¡€ç‰©ç†é‡ï¼Œé¿å…é‡å¤è®¡ç®—ï¼š
        - CV (å˜å¼‚ç³»æ•°): è´Ÿè½½å¹³è¡¡æŒ‡æ ‡
        - coupling: ç”µæ°”è€¦åˆåº¦æŒ‡æ ‡  
        - power_imbalance: åŠŸç‡ä¸å¹³è¡¡æŒ‡æ ‡
        - å…¶ä»–è¾…åŠ©æŒ‡æ ‡
        
        Args:
            partition: å½“å‰åˆ†åŒºæ–¹æ¡ˆ [num_nodes]
            
        Returns:
            åŒ…å«æ‰€æœ‰æ ¸å¿ƒæŒ‡æ ‡çš„å­—å…¸
        """
        metrics = {}
        
        # è·å–åˆ†åŒºæ•°é‡
        num_partitions = partition.max().item()
        if num_partitions <= 0:
            # å¦‚æœæ²¡æœ‰åˆ†åŒºï¼Œè¿”å›æœ€å·®æŒ‡æ ‡
            return {
                'cv': 1.0,
                'coupling_ratio': 1.0, 
                'power_imbalance_normalized': 1.0,
                'num_partitions': 0
            }
            
        # 1. è®¡ç®—è´Ÿè½½å¹³è¡¡æŒ‡æ ‡ (CV)
        partition_loads = torch.zeros(num_partitions, device=self.device)
        for i in range(1, num_partitions + 1):
            mask = (partition == i)
            if mask.any():
                partition_loads[i-1] = self.node_loads[mask].abs().sum()
                
        # è®¡ç®—å˜å¼‚ç³»æ•°ï¼Œæ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
        mean_load = partition_loads.mean()
        std_load = partition_loads.std()
        
        # å¤šé‡ä¿æŠ¤ï¼šé˜²æ­¢é™¤é›¶ã€NaNå’Œinf
        if torch.isnan(mean_load) or torch.isinf(mean_load) or mean_load <= 0:
            cv = 1.0  # æœ€å·®æƒ…å†µ
        elif torch.isnan(std_load) or torch.isinf(std_load):
            cv = 1.0
        else:
            cv = std_load / (mean_load + self.epsilon)
            cv = torch.clamp(cv, 0.0, 10.0)  # é™åˆ¶CVåœ¨åˆç†èŒƒå›´å†…
            
        metrics['cv'] = cv.item() if torch.is_tensor(cv) else cv
        
        # 2. è®¡ç®—ç”µæ°”è§£è€¦æŒ‡æ ‡ - ä½¿ç”¨é²æ£’è®¡ç®—å™¨
        if self.edge_index.shape[1] > 0:
            # ä½¿ç”¨é²æ£’æŒ‡æ ‡è®¡ç®—å™¨
            coupling_result = self.metrics_calculator.calculate_coupling_metrics(
                self.edge_admittance, self.edge_index, partition
            )

            # æå–ç»“æœ
            metrics['coupling_ratio'] = coupling_result['coupling_ratio']
            metrics['edge_decoupling_ratio'] = coupling_result['edge_decoupling_ratio']

            # è®°å½•ç½®ä¿¡åº¦å’Œæ¥æºä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if hasattr(self, 'logger'):
                if coupling_result['confidence'] < 0.8:
                    self.logger.warning(
                        f"è€¦åˆæŒ‡æ ‡ç½®ä¿¡åº¦è¾ƒä½: {coupling_result['confidence']:.2f}, "
                        f"æ¥æº: {coupling_result['source']}"
                    )
            elif coupling_result['confidence'] < 0.8:
                print(f"âš ï¸ è€¦åˆæŒ‡æ ‡ç½®ä¿¡åº¦è¾ƒä½: {coupling_result['confidence']:.2f}, "
                      f"æ¥æº: {coupling_result['source']}")
        else:
            # æ²¡æœ‰è¾¹çš„æƒ…å†µ
            metrics['coupling_ratio'] = 0.0
            metrics['edge_decoupling_ratio'] = 1.0
            
        # 3. è®¡ç®—åŠŸç‡å¹³è¡¡æŒ‡æ ‡
        total_imbalance = 0.0
        
        # æ£€æŸ¥èŠ‚ç‚¹æ•°æ®çš„æ•°å€¼ç¨³å®šæ€§
        if (torch.isnan(self.node_generation).any() or torch.isinf(self.node_generation).any() or
            torch.isnan(self.node_loads).any() or torch.isinf(self.node_loads).any()):
            # å¦‚æœæ•°æ®æœ‰é—®é¢˜ï¼Œè¿”å›æœ€å·®æƒ…å†µ
            metrics['power_imbalance_normalized'] = 1.0
        else:
            for i in range(1, num_partitions + 1):
                mask = (partition == i)
                if mask.any():
                    partition_generation = self.node_generation[mask].sum()
                    partition_load = self.node_loads[mask].sum()
                    
                    # æ£€æŸ¥æ¯ä¸ªåˆ†åŒºçš„è®¡ç®—ç»“æœ
                    if (torch.isnan(partition_generation) or torch.isinf(partition_generation) or
                        torch.isnan(partition_load) or torch.isinf(partition_load)):
                        continue  # è·³è¿‡æœ‰é—®é¢˜çš„åˆ†åŒº
                        
                    imbalance = torch.abs(partition_generation - partition_load)
                    if not (torch.isnan(imbalance) or torch.isinf(imbalance)):
                        total_imbalance += imbalance.item()
                    
            # å½’ä¸€åŒ–åŠŸç‡ä¸å¹³è¡¡ï¼Œæ·»åŠ å¤šé‡ä¿æŠ¤
            total_load = self.node_loads.abs().sum().item()
            if total_load <= 0 or np.isnan(total_load) or np.isinf(total_load):
                power_imbalance_normalized = 1.0  # æœ€å·®æƒ…å†µ
            else:
                power_imbalance_normalized = total_imbalance / (total_load + self.epsilon)
                power_imbalance_normalized = np.clip(power_imbalance_normalized, 0.0, 10.0)
                
            metrics['power_imbalance_normalized'] = power_imbalance_normalized
        
        # 4. å…¶ä»–è¾…åŠ©æŒ‡æ ‡
        metrics['num_partitions'] = num_partitions
        
        return metrics

    def compute_incremental_reward(self,
                                 current_partition: torch.Tensor,
                                 action: Tuple[int, int]) -> Tuple[float, Optional[PlateauResult]]:
        """
        è®¡ç®—è‡ªé€‚åº”è´¨é‡å¯¼å‘å³æ—¶å¥–åŠ±

        å®ç°åŸºäºç›¸å¯¹æ”¹è¿›çš„å¥–åŠ±ç³»ç»Ÿï¼Œè§£å†³è·¨åœºæ™¯è®­ç»ƒåå‘é—®é¢˜ï¼š
        ä¸»å¥–åŠ± = ç›¸å¯¹æ”¹è¿›å¥–åŠ± = (Q(s_{t+1}) - Q(s_t)) / Q(s_t)
        æ•ˆç‡å¥–åŠ± = Î» * (max_steps - current_step) / max_steps (ä»…åœ¨å¹³å°æœŸæ¿€æ´»)

        Args:
            current_partition: å½“å‰åˆ†åŒºçŠ¶æ€
            action: æ‰§è¡Œçš„åŠ¨ä½œ (node_idx, partition_id)

        Returns:
            (æ€»å¥–åŠ±, å¹³å°æœŸæ£€æµ‹ç»“æœ)
        """
        # æ›´æ–°æ­¥æ•°
        self.current_step += 1

        # è®¡ç®—å½“å‰è´¨é‡åˆ†æ•°
        current_quality_score = self._compute_quality_score(current_partition)

        # å¦‚æœæ²¡æœ‰å‰ä¸€æ­¥è´¨é‡åˆ†æ•°ï¼Œåˆå§‹åŒ–å¹¶è¿”å›0
        if self.previous_quality_score is None:
            self.previous_quality_score = current_quality_score
            self.previous_metrics = self._compute_core_metrics(current_partition)  # ä¿æŒå‘åå…¼å®¹

            # æ›´æ–°å¹³å°æœŸæ£€æµ‹å™¨
            plateau_result = self.plateau_detector.update(current_quality_score)
            return 0.0, plateau_result

        try:
            # 1. è®¡ç®—ä¸»å¥–åŠ±ï¼ˆç›¸å¯¹æ”¹è¿›å¥–åŠ±ï¼‰
            main_reward = self._compute_simple_relative_reward(
                self.previous_quality_score,
                current_quality_score
            )

            # æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(main_reward) or np.isinf(main_reward):
                main_reward = 0.0
            else:
                main_reward = np.clip(main_reward, -1.0, 1.0)

            # 2. å¹³å°æœŸæ£€æµ‹å’Œæ•ˆç‡å¥–åŠ±
            efficiency_reward = 0.0

            # æ›´æ–°å¹³å°æœŸæ£€æµ‹å™¨
            plateau_result = self.plateau_detector.update(current_quality_score)

            # å¦‚æœæ£€æµ‹åˆ°å¹³å°æœŸä¸”ç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œæ¿€æ´»æ•ˆç‡å¥–åŠ±
            if (plateau_result.plateau_detected and
                plateau_result.confidence > self.adaptive_quality_config['efficiency_reward']['early_stop_confidence']):

                lambda_efficiency = self.adaptive_quality_config['efficiency_reward']['lambda']
                efficiency_reward = lambda_efficiency * (self.max_steps - self.current_step) / self.max_steps
                efficiency_reward = max(0.0, efficiency_reward)  # ç¡®ä¿éè´Ÿ

            # 3. æ€»å¥–åŠ±
            total_reward = main_reward + efficiency_reward

            # æœ€ç»ˆæ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(total_reward) or np.isinf(total_reward):
                total_reward = 0.0
            else:
                total_reward = np.clip(total_reward, -2.0, 2.0)

        except Exception as e:
            print(f"è­¦å‘Šï¼šè‡ªé€‚åº”è´¨é‡å¯¼å‘å¥–åŠ±è®¡ç®—å‡ºç°å¼‚å¸¸: {e}")
            total_reward = 0.0
            plateau_result = None

        # æ›´æ–°å‰ä¸€æ­¥çŠ¶æ€
        self.previous_quality_score = current_quality_score
        self.previous_metrics = self._compute_core_metrics(current_partition)  # ä¿æŒå‘åå…¼å®¹

        return total_reward, plateau_result

    def reset_episode(self):
        """é‡ç½®episodeçŠ¶æ€"""
        self.current_step = 0
        self.previous_quality_score = None
        self.previous_metrics = None

        self.plateau_detector.reset()

    def get_current_quality_score(self, partition: torch.Tensor) -> float:
        """è·å–å½“å‰è´¨é‡åˆ†æ•°ï¼ˆç”¨äºå¤–éƒ¨è°ƒç”¨ï¼‰"""
        return self._compute_quality_score(partition)

    def get_plateau_statistics(self) -> Dict[str, Any]:
        """è·å–å¹³å°æœŸæ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        if self.plateau_detector is None:
            return {'enabled': False}

        stats = self.plateau_detector.get_statistics()
        stats['enabled'] = True
        return stats

    def should_early_stop(self, partition: torch.Tensor) -> Tuple[bool, float]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœ

        Returns:
            (æ˜¯å¦æ—©åœ, ç½®ä¿¡åº¦)
        """
        # æ›´æ–°è´¨é‡åˆ†æ•°å¹¶æ£€æµ‹å¹³å°æœŸ
        quality_score = self._compute_quality_score(partition)
        plateau_result = self.plateau_detector.update(quality_score)

        early_stop_threshold = self.adaptive_quality_config['efficiency_reward']['early_stop_confidence']
        should_stop = (plateau_result.plateau_detected and
                      plateau_result.confidence > early_stop_threshold)

        return should_stop, plateau_result.confidence

    def compute_final_reward(self,
                           final_partition: torch.Tensor,
                           termination_type: str = 'natural') -> Tuple[float, Dict[str, float]]:
        """
        è®¡ç®—ç»ˆå±€å¥–åŠ±ï¼ˆRewardï¼‰

        åŸºäºæœ€ç»ˆåˆ†åŒºè´¨é‡çš„ç»¼åˆè¯„ä¼°ï¼ŒåŒ…å«ï¼š
        1. ä¸‰ä¸ªæ ¸å¿ƒå¥–åŠ±ç»„ä»¶ï¼ˆæŒ‰è®¾è®¡è“å›¾å…¬å¼ï¼‰
        2. éçº¿æ€§é˜ˆå€¼å¥–åŠ±
        3. ç»ˆæ­¢æ¡ä»¶æŠ˜æ‰£

        Args:
            final_partition: æœ€ç»ˆåˆ†åŒºæ–¹æ¡ˆ
            termination_type: ç»ˆæ­¢ç±»å‹ ('natural', 'timeout', 'stuck')

        Returns:
            (æ€»ç»ˆå±€å¥–åŠ±, å¥–åŠ±ç»„ä»¶è¯¦æƒ…)
        """
        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        final_metrics = self._compute_core_metrics(final_partition)

        # 1. è®¡ç®—ä¸‰ä¸ªæ ¸å¿ƒå¥–åŠ±ç»„ä»¶
        balance_reward = self._compute_balance_reward(final_metrics['cv'])
        decoupling_reward = self._compute_decoupling_reward(
            final_metrics['edge_decoupling_ratio'],
            final_metrics['coupling_ratio']
        )
        power_reward = self._compute_power_reward(final_metrics['power_imbalance_normalized'])

        # 2. åŠ æƒæ±‚å’Œå¾—åˆ°è´¨é‡å¥–åŠ±
        quality_reward = (
            self.weights['final_balance_weight'] * balance_reward +
            self.weights['final_decoupling_weight'] * decoupling_reward +
            self.weights['final_power_weight'] * power_reward
        )

        # 3. é˜ˆå€¼å¥–åŠ±å·²è¢«è‡ªé€‚åº”è´¨é‡ç³»ç»Ÿæ›¿ä»£ï¼Œè®¾ä¸º0
        threshold_bonus = 0.0

        # 4. åº”ç”¨ç»ˆæ­¢æ¡ä»¶æŠ˜æ‰£
        termination_discount = self._apply_termination_discount(termination_type)

        # 5. è®¡ç®—æœ€ç»ˆå¥–åŠ±
        final_reward = (quality_reward + threshold_bonus) * termination_discount

        # ç»„ä»¶è¯¦æƒ…
        components = {
            'balance_reward': balance_reward,
            'decoupling_reward': decoupling_reward,
            'power_reward': power_reward,
            'quality_reward': quality_reward,
            'threshold_bonus': threshold_bonus,
            'termination_discount': termination_discount,
            'final_reward': final_reward,
            'metrics': final_metrics
        }

        return final_reward, components

    def _compute_balance_reward(self, cv: float) -> float:
        """
        è®¡ç®—è´Ÿè½½å¹³è¡¡å¥–åŠ±

        å…¬å¼ï¼šR_balance = exp(-2.0 * CV)
        CVè¶Šå°ï¼Œå¥–åŠ±è¶Šæ¥è¿‘1.0
        """
        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
        if np.isnan(cv) or np.isinf(cv):
            cv = 1.0  # æœ€å·®æƒ…å†µ
        else:
            cv = max(0.0, min(cv, 10.0))  # ç¡®ä¿CVåœ¨åˆç†èŒƒå›´å†…

        try:
            balance_reward = np.exp(-2.0 * cv)
            # æ£€æŸ¥ç»“æœ
            if np.isnan(balance_reward) or np.isinf(balance_reward):
                balance_reward = 0.0
            else:
                balance_reward = np.clip(balance_reward, 0.0, 1.0)
        except Exception:
            balance_reward = 0.0

        return balance_reward

    def _compute_decoupling_reward(self, edge_decoupling_ratio: float, coupling_ratio: float) -> float:
        """
        è®¡ç®—ç”µæ°”è§£è€¦å¥–åŠ± - æ”¹è¿›çš„é”™è¯¯å¤„ç†

        å…¬å¼ï¼šR_decoupling = 0.5 * Ïƒ(5*(r_edge - 0.5)) + 0.5 * Ïƒ(5*(r_admittance - 0.5))
        å…¶ä¸­ Ïƒ æ˜¯sigmoidå‡½æ•°ï¼Œr_admittance = 1 - coupling_ratio
        """
        # æ™ºèƒ½æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        edge_decoupling_ratio = self._robust_value_check(
            edge_decoupling_ratio, 'edge_decoupling_ratio',
            expected_range=(0.0, 1.0), default_strategy='historical'
        )

        coupling_ratio = self._robust_value_check(
            coupling_ratio, 'coupling_ratio',
            expected_range=(0.0, 1.0), default_strategy='historical'
        )

        # è®¡ç®—å¯¼çº³è§£è€¦ç‡
        admittance_decoupling_ratio = 1.0 - coupling_ratio

        try:
            # åº”ç”¨sigmoidå‡½æ•°
            edge_component = self._sigmoid(5.0 * (edge_decoupling_ratio - 0.5))
            admittance_component = self._sigmoid(5.0 * (admittance_decoupling_ratio - 0.5))

            decoupling_reward = 0.5 * edge_component + 0.5 * admittance_component

            # æ£€æŸ¥ç»“æœ
            if np.isnan(decoupling_reward) or np.isinf(decoupling_reward):
                # ä½¿ç”¨å†å²æ•°æ®å›é€€
                decoupling_reward = self._get_historical_reward_estimate('decoupling_reward', 0.5)
            else:
                decoupling_reward = np.clip(decoupling_reward, 0.0, 1.0)
                # è®°å½•æˆåŠŸçš„è®¡ç®—
                self._record_reward_calculation('decoupling_reward', decoupling_reward)

        except Exception as e:
            # è®°å½•å¼‚å¸¸å¹¶ä½¿ç”¨æ™ºèƒ½å›é€€
            self._record_calculation_error('decoupling_reward', e)
            decoupling_reward = self._get_historical_reward_estimate('decoupling_reward', 0.4)

        return decoupling_reward

    def _robust_value_check(self, value, value_name, expected_range, default_strategy='historical'):
        """
        é²æ£’çš„æ•°å€¼æ£€æŸ¥ï¼Œæ”¯æŒå¤šç§å›é€€ç­–ç•¥
        """
        # æ£€æŸ¥NaNå’ŒInf
        if np.isnan(value) or np.isinf(value):
            if default_strategy == 'historical':
                return self._get_historical_value_estimate(value_name, expected_range[0] + 0.5 * (expected_range[1] - expected_range[0]))
            else:
                return expected_range[0] + 0.5 * (expected_range[1] - expected_range[0])  # ä¸­ç‚¹

        # æ£€æŸ¥èŒƒå›´
        if not (expected_range[0] <= value <= expected_range[1]):
            # è®°å½•è¶…å‡ºèŒƒå›´çš„è­¦å‘Š
            if hasattr(self, 'logger'):
                self.logger.warning(f"{value_name} è¶…å‡ºèŒƒå›´ {expected_range}: {value:.3f}")

            # è£å‰ªåˆ°åˆç†èŒƒå›´
            return np.clip(value, expected_range[0], expected_range[1])

        return value

    def _get_historical_value_estimate(self, value_name, default_value):
        """è·å–å†å²æ•°å€¼ä¼°è®¡"""
        if hasattr(self.metrics_calculator, 'metrics_history') and value_name in self.metrics_calculator.metrics_history:
            valid_history = [
                entry['value'] for entry in self.metrics_calculator.metrics_history[value_name][-5:]
                if entry['confidence'] > 0.7
            ]
            if valid_history:
                return np.mean(valid_history)

        return default_value

    def _get_historical_reward_estimate(self, reward_name, default_value):
        """è·å–å†å²å¥–åŠ±ä¼°è®¡"""
        if hasattr(self, 'reward_history') and reward_name in self.reward_history:
            recent_rewards = self.reward_history[reward_name][-5:]
            if recent_rewards:
                return np.mean(recent_rewards)

        return default_value

    def _record_reward_calculation(self, reward_name, value):
        """è®°å½•æˆåŠŸçš„å¥–åŠ±è®¡ç®—"""
        if not hasattr(self, 'reward_history'):
            self.reward_history = defaultdict(list)

        self.reward_history[reward_name].append(value)

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.reward_history[reward_name]) > 20:
            self.reward_history[reward_name] = self.reward_history[reward_name][-20:]

    def _record_calculation_error(self, calculation_name, exception):
        """è®°å½•è®¡ç®—é”™è¯¯"""
        if not hasattr(self, 'calculation_errors'):
            self.calculation_errors = []

        self.calculation_errors.append({
            'name': calculation_name,
            'exception': str(exception),
            'timestamp': time.time()
        })

        # é™åˆ¶é”™è¯¯å†å²é•¿åº¦
        if len(self.calculation_errors) > 50:
            self.calculation_errors = self.calculation_errors[-50:]

    def _compute_power_reward(self, power_imbalance_normalized: float) -> float:
        """
        è®¡ç®—åŠŸç‡å¹³è¡¡å¥–åŠ±

        å…¬å¼ï¼šR_power = exp(-3.0 * I_normalized)
        I_normalizedè¶Šå°ï¼Œå¥–åŠ±è¶Šæ¥è¿‘1.0
        """
        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
        if np.isnan(power_imbalance_normalized) or np.isinf(power_imbalance_normalized):
            power_imbalance_normalized = 1.0  # æœ€å·®æƒ…å†µ
        else:
            power_imbalance_normalized = max(0.0, min(power_imbalance_normalized, 10.0))

        try:
            # é™åˆ¶æŒ‡æ•°å‚æ•°é¿å…æº¢å‡º
            exp_arg = -3.0 * power_imbalance_normalized
            exp_arg = np.clip(exp_arg, -500, 0)  # é˜²æ­¢expæº¢å‡º

            power_reward = np.exp(exp_arg)

            # æ£€æŸ¥ç»“æœ
            if np.isnan(power_reward) or np.isinf(power_reward):
                power_reward = 0.0
            else:
                power_reward = np.clip(power_reward, 0.0, 1.0)

        except Exception:
            power_reward = 0.0

        return power_reward

    def _compute_threshold_bonus(self, metrics: Dict[str, float]) -> float:
        """
        è®¡ç®—éçº¿æ€§é˜ˆå€¼å¥–åŠ± (å·²åºŸå¼ƒï¼Œè¢«è‡ªé€‚åº”è´¨é‡ç³»ç»Ÿæ›¿ä»£)

        ä¿ç•™æ­¤æ–¹æ³•ä»…ä¸ºå‘åå…¼å®¹ï¼Œå®é™…è¿”å›0
        """
        # å›ºå®šé˜ˆå€¼å¥–åŠ±å·²è¢«è‡ªé€‚åº”è´¨é‡å¯¼å‘ç³»ç»Ÿæ›¿ä»£
        return 0.0

    def _apply_termination_discount(self, termination_type: str) -> float:
        """
        æ ¹æ®ç»ˆæ­¢æ¡ä»¶åº”ç”¨ä¸åŒçš„æŠ˜æ‰£æˆ–æƒ©ç½š

        Args:
            termination_type: 'natural' (è‡ªç„¶å®Œæˆ), 'timeout' (è¶…æ—¶), 'stuck' (å¡ä½)

        Returns:
            æŠ˜æ‰£ç³»æ•°
        """
        if termination_type == 'natural':
            return 1.0      # è‡ªç„¶å®Œæˆï¼Œæ— æŠ˜æ‰£
        elif termination_type == 'timeout':
            return 0.7      # è¶…æ—¶å®Œæˆï¼Œ70%æŠ˜æ‰£
        elif termination_type == 'stuck':
            return 0.3      # æå‰å¡ä½ï¼Œ30%æŠ˜æ‰£
        else:
            return 0.5      # æœªçŸ¥æƒ…å†µï¼Œ50%æŠ˜æ‰£

    def _sigmoid(self, x: float) -> float:
        """æ•°å€¼ç¨³å®šçš„sigmoidå‡½æ•°"""
        # é˜²æ­¢æ•°å€¼æº¢å‡º
        x = np.clip(x, -500, 500)
        return 1.0 / (1.0 + np.exp(-x))

    def get_current_metrics(self, partition: torch.Tensor) -> Dict[str, float]:
        """è·å–å½“å‰åˆ†åŒºçš„æŒ‡æ ‡ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰"""
        return self._compute_core_metrics(partition)

    def update_weights(self, new_weights: Dict[str, float]):
        """åŠ¨æ€æ›´æ–°å¥–åŠ±æƒé‡ï¼ˆç”¨äºæ™ºèƒ½è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ ï¼‰"""
        try:
            # æ›´æ–°å³æ—¶å¥–åŠ±æƒé‡
            if 'balance_weight' in new_weights:
                self.weights['balance_weight'] = new_weights['balance_weight']
            if 'decoupling_weight' in new_weights:
                self.weights['decoupling_weight'] = new_weights['decoupling_weight']
            if 'power_weight' in new_weights:
                self.weights['power_weight'] = new_weights['power_weight']

            # æ›´æ–°ç»ˆå±€å¥–åŠ±æƒé‡ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
            if 'balance_weight' in new_weights:
                self.weights['final_balance_weight'] = new_weights['balance_weight']
            if 'decoupling_weight' in new_weights:
                self.weights['final_decoupling_weight'] = new_weights['decoupling_weight']
            if 'power_weight' in new_weights:
                self.weights['final_power_weight'] = new_weights['power_weight']

            print(f"ğŸ¯ å¥–åŠ±æƒé‡å·²æ›´æ–°: balance={self.weights['balance_weight']:.2f}, "
                  f"decoupling={self.weights['decoupling_weight']:.2f}, "
                  f"power={self.weights['power_weight']:.2f}")

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°å¥–åŠ±æƒé‡å¤±è´¥: {e}")

    def get_current_weights(self) -> Dict[str, float]:
        """è·å–å½“å‰å¥–åŠ±æƒé‡"""
        return {
            'balance_weight': self.weights.get('balance_weight', 1.0),
            'decoupling_weight': self.weights.get('decoupling_weight', 1.0),
            'power_weight': self.weights.get('power_weight', 1.0)
        }





