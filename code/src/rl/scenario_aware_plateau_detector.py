"""
åœºæ™¯æ„ŸçŸ¥å¥–åŠ±ç³»ç»Ÿ - åœºæ™¯æ„ŸçŸ¥å¹³å°æœŸæ£€æµ‹å™¨

å®ç°åŸºäºåœºæ™¯æ„ŸçŸ¥å†å²è¿½è¸ªå™¨çš„å¹³å°æœŸæ£€æµ‹ï¼Œç¡®ä¿å¹³å°æœŸæ£€æµ‹åœ¨åŒç±»éš¾åº¦åœºæ™¯å†…è¿›è¡Œæ¯”è¾ƒã€‚

ä½œè€…ï¼šAugment Agent
æ—¥æœŸï¼š2025-01-15
"""

import numpy as np
from typing import Dict, List, Optional, Tuple, NamedTuple
import warnings
from .scenario_context import ScenarioContext
from .scenario_aware_tracker import ScenarioAwareHistoryTracker

# æŠ‘åˆ¶numpyçš„è­¦å‘Š
warnings.filterwarnings('ignore', category=RuntimeWarning)


class PlateauResult(NamedTuple):
    """å¹³å°æœŸæ£€æµ‹ç»“æœ"""
    plateau_detected: bool
    confidence: float
    improvement_rate: float
    stability_score: float
    historical_percentile: float
    details: Dict[str, float]


class ScenarioAwarePlateauDetector:
    """
    åœºæ™¯æ„ŸçŸ¥å¹³å°æœŸæ£€æµ‹å™¨
    
    åŸºäºåœºæ™¯æ„ŸçŸ¥å†å²è¿½è¸ªå™¨å®ç°å¹³å°æœŸæ£€æµ‹ï¼Œç¡®ä¿åŒç±»åœºæ™¯å†…è¿›è¡Œæ¯”è¾ƒ
    """

    def __init__(self,
                 history_tracker: ScenarioAwareHistoryTracker,
                 config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–åœºæ™¯æ„ŸçŸ¥å¹³å°æœŸæ£€æµ‹å™¨

        Args:
            history_tracker: åœºæ™¯æ„ŸçŸ¥å†å²è¿½è¸ªå™¨
            config: æ£€æµ‹é…ç½®
        """
        self.history_tracker = history_tracker
        self.config = config or {}
        
        # æ£€æµ‹å‚æ•°
        self.window_size = self.config.get('window_size', 15)
        self.min_improvement_rate = self.config.get('min_improvement_rate', 0.005)
        self.stability_threshold = self.config.get('stability_threshold', 0.8)
        self.min_percentile = self.config.get('min_percentile', 0.7)
        self.confidence_threshold = self.config.get('confidence_threshold', 0.8)
        
        # æ•°å€¼ç¨³å®šæ€§å‚æ•°
        self.epsilon = 1e-9
        
        # å½“å‰åœºæ™¯ä¸Šä¸‹æ–‡
        self.current_scenario_context = None

    def detect_plateau(self, 
                      quality_score: float, 
                      scenario_context: ScenarioContext) -> PlateauResult:
        """
        æ£€æµ‹å¹³å°æœŸ

        Args:
            quality_score: å½“å‰è´¨é‡åˆ†æ•° [0, 1]
            scenario_context: åœºæ™¯ä¸Šä¸‹æ–‡

        Returns:
            PlateauResult: æ£€æµ‹ç»“æœ
        """
        # è¾“å…¥éªŒè¯
        if np.isnan(quality_score) or np.isinf(quality_score):
            quality_score = 0.0
        quality_score = np.clip(quality_score, 0.0, 1.0)
        
        # æ›´æ–°å†å²æ•°æ®
        self.history_tracker.update_history(quality_score, scenario_context)
        self.current_scenario_context = scenario_context
        
        # è·å–æœ€è¿‘åˆ†æ•°ç”¨äºå±€éƒ¨åˆ†æ
        recent_scores = self.history_tracker.get_recent_scores()
        
        # å¦‚æœæ•°æ®ä¸è¶³ï¼Œä¸è¿›è¡Œæ£€æµ‹
        if len(recent_scores) < min(5, self.window_size):
            return PlateauResult(
                plateau_detected=False,
                confidence=0.0,
                improvement_rate=1.0,  # å‡è®¾è¿˜åœ¨æ”¹å–„
                stability_score=0.0,
                historical_percentile=0.0,
                details={'reason': 'insufficient_data', 'data_count': len(recent_scores)}
            )

        # æ‰§è¡Œä¸‰å±‚æ£€æµ‹
        improvement_rate = self._compute_improvement_rate(recent_scores)
        stability_score = self._compute_stability_score(recent_scores)
        
        # ğŸ”¥ å…³é”®æ”¹è¿›ï¼šåœºæ™¯å†…ç™¾åˆ†ä½è®¡ç®—
        historical_percentile = self.history_tracker.compute_scenario_percentile(
            quality_score, scenario_context
        )

        # ç»¼åˆåˆ¤æ–­
        plateau_detected = (
            improvement_rate < self.min_improvement_rate and
            stability_score > self.stability_threshold and
            historical_percentile > self.min_percentile
        )

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._compute_confidence(
            improvement_rate, stability_score, historical_percentile
        )

        # è¯¦ç»†ä¿¡æ¯
        scenario_stats = self.history_tracker.get_scenario_statistics(scenario_context)
        details = {
            'window_size': len(recent_scores),
            'scenario_key': scenario_stats.get('scenario_key', 'unknown'),
            'scenario_count': scenario_stats.get('count', 0),
            'current_score': quality_score,
            'mean_recent': np.mean(recent_scores),
            'std_recent': np.std(recent_scores),
            'min_recent': np.min(recent_scores),
            'max_recent': np.max(recent_scores),
            'scenario_mean': scenario_stats.get('mean', 0.0),
            'scenario_std': scenario_stats.get('std', 0.0)
        }

        return PlateauResult(
            plateau_detected=plateau_detected,
            confidence=confidence,
            improvement_rate=improvement_rate,
            stability_score=stability_score,
            historical_percentile=historical_percentile,
            details=details
        )

    def _compute_improvement_rate(self, recent_scores: List[float]) -> float:
        """
        è®¡ç®—æ”¹å–„ç‡ï¼ˆåŸºäºçº¿æ€§å›å½’æ–œç‡ï¼‰

        Args:
            recent_scores: æœ€è¿‘çš„è´¨é‡åˆ†æ•°åˆ—è¡¨

        Returns:
            æ”¹å–„ç‡çš„ç»å¯¹å€¼ï¼Œè¶Šå°è¡¨ç¤ºæ”¹å–„è¶Šæ…¢
        """
        if len(recent_scores) < 3:
            return 1.0  # æ•°æ®ä¸è¶³ï¼Œå‡è®¾è¿˜åœ¨æ”¹å–„

        try:
            scores = np.array(recent_scores)
            x = np.arange(len(scores))

            # çº¿æ€§å›å½’è®¡ç®—æ–œç‡
            slope = np.polyfit(x, scores, 1)[0]

            # è¿”å›æ–œç‡çš„ç»å¯¹å€¼ä½œä¸ºæ”¹å–„ç‡
            improvement_rate = abs(slope)

            # æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(improvement_rate) or np.isinf(improvement_rate):
                improvement_rate = 1.0

            return improvement_rate

        except Exception:
            return 1.0

    def _compute_stability_score(self, recent_scores: List[float]) -> float:
        """
        è®¡ç®—ç¨³å®šæ€§åˆ†æ•°

        Args:
            recent_scores: æœ€è¿‘çš„è´¨é‡åˆ†æ•°åˆ—è¡¨

        Returns:
            ç¨³å®šæ€§åˆ†æ•° [0, 1]ï¼Œè¶Šå¤§è¡¨ç¤ºè¶Šç¨³å®š
        """
        if len(recent_scores) < 2:
            return 0.0

        try:
            variance = np.var(recent_scores)

            # ä½¿ç”¨åæ¯”å‡½æ•°ï¼šstability = 1 / (1 + variance)
            stability_score = 1.0 / (1.0 + variance + self.epsilon)

            # æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
            if np.isnan(stability_score) or np.isinf(stability_score):
                stability_score = 0.0

            return np.clip(stability_score, 0.0, 1.0)

        except Exception:
            return 0.0

    def _compute_confidence(self,
                           improvement_rate: float,
                           stability_score: float,
                           historical_percentile: float) -> float:
        """
        è®¡ç®—ç»¼åˆç½®ä¿¡åº¦

        Args:
            improvement_rate: æ”¹å–„ç‡
            stability_score: ç¨³å®šæ€§åˆ†æ•°  
            historical_percentile: å†å²ç™¾åˆ†ä½

        Returns:
            ç»¼åˆç½®ä¿¡åº¦ [0, 1]
        """
        try:
            # æ”¹å–„ç‡ç½®ä¿¡åº¦ï¼šæ”¹å–„ç‡è¶Šå°ï¼Œç½®ä¿¡åº¦è¶Šé«˜
            improvement_confidence = 1.0 - min(improvement_rate / self.min_improvement_rate, 1.0)

            # ç¨³å®šæ€§ç½®ä¿¡åº¦ï¼šç›´æ¥ä½¿ç”¨ç¨³å®šæ€§åˆ†æ•°
            stability_confidence = stability_score

            # å†å²è¡¨ç°ç½®ä¿¡åº¦ï¼šç™¾åˆ†ä½è¶Šé«˜ï¼Œç½®ä¿¡åº¦è¶Šé«˜
            historical_confidence = max(0.0, historical_percentile - self.min_percentile) / (1.0 - self.min_percentile)

            # åŠ æƒå¹³å‡è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
            weights = [0.4, 0.3, 0.3]  # æ”¹å–„ç‡ã€ç¨³å®šæ€§ã€å†å²è¡¨ç°çš„æƒé‡
            confidence = (
                weights[0] * improvement_confidence +
                weights[1] * stability_confidence +
                weights[2] * historical_confidence
            )

            return np.clip(confidence, 0.0, 1.0)

        except Exception:
            return 0.0

    def should_early_stop(self, 
                         quality_score: float, 
                         scenario_context: ScenarioContext) -> Tuple[bool, float]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æå‰åœæ­¢

        Args:
            quality_score: å½“å‰è´¨é‡åˆ†æ•°
            scenario_context: åœºæ™¯ä¸Šä¸‹æ–‡

        Returns:
            (æ˜¯å¦æå‰åœæ­¢, ç½®ä¿¡åº¦)
        """
        result = self.detect_plateau(quality_score, scenario_context)
        
        early_stop = (
            result.plateau_detected and 
            result.confidence > self.confidence_threshold
        )
        
        return early_stop, result.confidence

    def get_plateau_statistics(self) -> Dict[str, any]:
        """
        è·å–å¹³å°æœŸæ£€æµ‹ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        base_stats = self.history_tracker.get_global_statistics()
        
        if self.current_scenario_context:
            current_scenario_stats = self.history_tracker.get_scenario_statistics(
                self.current_scenario_context
            )
        else:
            current_scenario_stats = {}
        
        return {
            'global_stats': base_stats,
            'current_scenario_stats': current_scenario_stats,
            'detection_config': {
                'window_size': self.window_size,
                'min_improvement_rate': self.min_improvement_rate,
                'stability_threshold': self.stability_threshold,
                'min_percentile': self.min_percentile,
                'confidence_threshold': self.confidence_threshold
            }
        }

    def reset(self):
        """é‡ç½®æ£€æµ‹å™¨çŠ¶æ€"""
        self.current_scenario_context = None