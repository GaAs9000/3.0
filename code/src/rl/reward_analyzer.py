#!/usr/bin/env python3
"""
å¥–åŠ±åˆ†æå·¥å…·ï¼šæ·±åº¦åˆ†æå¥–åŠ±ç»„ä»¶çš„è´¡çŒ®å’Œæ¼”åŒ–
ä¸ºè°ƒè¯•å’Œä¼˜åŒ–å¥–åŠ±å‡½æ•°æä¾›ç§‘å­¦ä¾æ®
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, deque
import pandas as pd
from pathlib import Path
import json

class RewardAnalyzer:
    """
    å¥–åŠ±åˆ†æå·¥å…·
    
    åŠŸèƒ½ï¼š
    1. å¥–åŠ±ç»„ä»¶åˆ†è§£åˆ†æ
    2. å¥–åŠ±æ¼”åŒ–è¶‹åŠ¿åˆ†æ
    3. ç»„ä»¶ç›¸å…³æ€§åˆ†æ
    4. å¼‚å¸¸æ£€æµ‹å’Œè¯Šæ–­
    5. å¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self, output_dir: str = "reward_analysis"):
        """
        åˆå§‹åŒ–å¥–åŠ±åˆ†æå™¨
        
        Args:
            output_dir: åˆ†æç»“æœè¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        # æ•°æ®å­˜å‚¨
        self.reward_history: List[Dict[str, float]] = []
        self.episode_info: List[Dict[str, Any]] = []
        self.component_stats: Dict[str, Dict[str, float]] = defaultdict(dict)
        
        # åˆ†æé…ç½®
        self.moving_average_window = 50
        self.anomaly_threshold = 3.0  # æ ‡å‡†å·®å€æ•°
        
        # å¯è§†åŒ–é…ç½®
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
    def add_episode_data(self, 
                        episode: int,
                        total_reward: float,
                        reward_components: Dict[str, float],
                        episode_info: Optional[Dict[str, Any]] = None):
        """
        æ·»åŠ å•å›åˆçš„å¥–åŠ±æ•°æ®
        
        Args:
            episode: å›åˆç¼–å·
            total_reward: æ€»å¥–åŠ±
            reward_components: å¥–åŠ±ç»„ä»¶åˆ†è§£
            episode_info: é¢å¤–çš„å›åˆä¿¡æ¯
        """
        # æ·»åŠ æ€»å¥–åŠ±åˆ°ç»„ä»¶ä¸­
        components = reward_components.copy()
        components['total_reward'] = total_reward
        components['episode'] = episode
        
        self.reward_history.append(components)
        
        if episode_info:
            episode_info['episode'] = episode
            self.episode_info.append(episode_info)
        
        # æ›´æ–°ç»„ä»¶ç»Ÿè®¡
        self._update_component_stats(components)
    
    def _update_component_stats(self, components: Dict[str, float]):
        """æ›´æ–°ç»„ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        for comp_name, value in components.items():
            if comp_name == 'episode':
                continue
                
            if comp_name not in self.component_stats:
                self.component_stats[comp_name] = {
                    'values': [],
                    'mean': 0.0,
                    'std': 0.0,
                    'min': float('inf'),
                    'max': float('-inf'),
                    'count': 0
                }
            
            stats = self.component_stats[comp_name]
            stats['values'].append(value)
            stats['count'] += 1
            stats['min'] = min(stats['min'], value)
            stats['max'] = max(stats['max'], value)
            
            # æ›´æ–°å‡å€¼å’Œæ ‡å‡†å·®
            values = stats['values']
            stats['mean'] = np.mean(values)
            stats['std'] = np.std(values)
    
    def analyze_component_evolution(self) -> Dict[str, Any]:
        """åˆ†æå¥–åŠ±ç»„ä»¶çš„æ¼”åŒ–è¶‹åŠ¿"""
        if not self.reward_history:
            return {}
        
        analysis = {}
        
        # è½¬æ¢ä¸ºDataFrameä¾¿äºåˆ†æ
        df = pd.DataFrame(self.reward_history)
        
        for component in df.columns:
            if component == 'episode':
                continue
                
            values = df[component].values
            episodes = df['episode'].values
            
            # è¶‹åŠ¿åˆ†æ
            trend_analysis = self._analyze_trend(episodes, values)
            
            # ç¨³å®šæ€§åˆ†æ
            stability_analysis = self._analyze_stability(values)
            
            # ç›¸å…³æ€§åˆ†æ
            correlation_analysis = self._analyze_correlations(df, component)
            
            analysis[component] = {
                'trend': trend_analysis,
                'stability': stability_analysis,
                'correlation': correlation_analysis,
                'statistics': self.component_stats[component]
            }
        
        return analysis
    
    def _analyze_trend(self, episodes: np.ndarray, values: np.ndarray) -> Dict[str, Any]:
        """åˆ†æè¶‹åŠ¿"""
        # çº¿æ€§å›å½’åˆ†æè¶‹åŠ¿
        if len(values) < 2:
            return {'slope': 0, 'trend': 'insufficient_data'}
        
        # è®¡ç®—æ–œç‡
        slope = np.polyfit(episodes, values, 1)[0]
        
        # ç§»åŠ¨å¹³å‡
        if len(values) >= self.moving_average_window:
            moving_avg = pd.Series(values).rolling(window=self.moving_average_window).mean()
            recent_trend = moving_avg.iloc[-10:].mean() - moving_avg.iloc[-20:-10].mean()
        else:
            recent_trend = 0
        
        # è¶‹åŠ¿åˆ†ç±»
        if abs(slope) < 1e-6:
            trend_type = 'stable'
        elif slope > 0:
            trend_type = 'increasing'
        else:
            trend_type = 'decreasing'
        
        return {
            'slope': slope,
            'trend_type': trend_type,
            'recent_trend': recent_trend,
            'trend_strength': abs(slope)
        }
    
    def _analyze_stability(self, values: np.ndarray) -> Dict[str, Any]:
        """åˆ†æç¨³å®šæ€§"""
        if len(values) < 10:
            return {'stability': 'insufficient_data'}
        
        # å˜å¼‚ç³»æ•°
        mean_val = np.mean(values)
        std_val = np.std(values)
        cv = std_val / abs(mean_val) if mean_val != 0 else float('inf')
        
        # å¼‚å¸¸å€¼æ£€æµ‹
        z_scores = np.abs((values - mean_val) / std_val) if std_val > 0 else np.zeros_like(values)
        anomalies = np.sum(z_scores > self.anomaly_threshold)
        anomaly_rate = anomalies / len(values)
        
        # ç¨³å®šæ€§è¯„çº§
        if cv < 0.1:
            stability_level = 'very_stable'
        elif cv < 0.3:
            stability_level = 'stable'
        elif cv < 0.5:
            stability_level = 'moderate'
        else:
            stability_level = 'unstable'
        
        return {
            'coefficient_of_variation': cv,
            'anomaly_count': anomalies,
            'anomaly_rate': anomaly_rate,
            'stability_level': stability_level
        }
    
    def _analyze_correlations(self, df: pd.DataFrame, target_component: str) -> Dict[str, float]:
        """åˆ†æä¸å…¶ä»–ç»„ä»¶çš„ç›¸å…³æ€§"""
        correlations = {}
        
        target_values = df[target_component]
        
        for component in df.columns:
            if component in ['episode', target_component]:
                continue
                
            try:
                corr = target_values.corr(df[component])
                if not np.isnan(corr):
                    correlations[component] = corr
            except:
                continue
        
        return correlations
    
    def detect_anomalies(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹å¥–åŠ±å¼‚å¸¸"""
        anomalies = []
        
        if not self.reward_history:
            return anomalies
        
        df = pd.DataFrame(self.reward_history)
        
        for component in df.columns:
            if component == 'episode':
                continue
                
            values = df[component].values
            mean_val = np.mean(values)
            std_val = np.std(values)
            
            if std_val == 0:
                continue
            
            z_scores = np.abs((values - mean_val) / std_val)
            anomaly_indices = np.where(z_scores > self.anomaly_threshold)[0]
            
            for idx in anomaly_indices:
                anomalies.append({
                    'episode': df.iloc[idx]['episode'],
                    'component': component,
                    'value': values[idx],
                    'z_score': z_scores[idx],
                    'expected_range': (mean_val - 2*std_val, mean_val + 2*std_val)
                })
        
        return anomalies
    
    def generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        if not self.reward_history:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¾›å¯è§†åŒ–")
            return
        
        df = pd.DataFrame(self.reward_history)
        
        # 1. å¥–åŠ±ç»„ä»¶æ¼”åŒ–å›¾
        self._plot_component_evolution(df)
        
        # 2. ç»„ä»¶åˆ†å¸ƒå›¾
        self._plot_component_distributions(df)
        
        # 3. ç›¸å…³æ€§çƒ­åŠ›å›¾
        self._plot_correlation_heatmap(df)
        
        # 4. å¼‚å¸¸æ£€æµ‹å›¾
        self._plot_anomaly_detection(df)
        
        print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {self.output_dir}")
    
    def _plot_component_evolution(self, df: pd.DataFrame):
        """ç»˜åˆ¶ç»„ä»¶æ¼”åŒ–å›¾"""
        components = [col for col in df.columns if col != 'episode']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, component in enumerate(components[:4]):  # åªæ˜¾ç¤ºå‰4ä¸ªç»„ä»¶
            if i >= len(axes):
                break
                
            ax = axes[i]
            episodes = df['episode']
            values = df[component]
            
            # åŸå§‹æ•°æ®
            ax.plot(episodes, values, alpha=0.3, label='åŸå§‹æ•°æ®')
            
            # ç§»åŠ¨å¹³å‡
            if len(values) >= self.moving_average_window:
                moving_avg = pd.Series(values).rolling(window=self.moving_average_window).mean()
                ax.plot(episodes, moving_avg, linewidth=2, label=f'{self.moving_average_window}å›åˆç§»åŠ¨å¹³å‡')
            
            ax.set_title(f'{component} æ¼”åŒ–è¶‹åŠ¿')
            ax.set_xlabel('å›åˆ')
            ax.set_ylabel('å¥–åŠ±å€¼')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(components), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'component_evolution.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_component_distributions(self, df: pd.DataFrame):
        """ç»˜åˆ¶ç»„ä»¶åˆ†å¸ƒå›¾"""
        components = [col for col in df.columns if col != 'episode']
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        axes = axes.flatten()
        
        for i, component in enumerate(components[:4]):
            if i >= len(axes):
                break
                
            ax = axes[i]
            values = df[component].dropna()
            
            # ç›´æ–¹å›¾
            ax.hist(values, bins=30, alpha=0.7, density=True)
            
            # æ ¸å¯†åº¦ä¼°è®¡
            try:
                values.plot.density(ax=ax, linewidth=2)
            except:
                pass
            
            ax.set_title(f'{component} åˆ†å¸ƒ')
            ax.set_xlabel('å¥–åŠ±å€¼')
            ax.set_ylabel('å¯†åº¦')
            ax.grid(True, alpha=0.3)
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(components), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'component_distributions.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_correlation_heatmap(self, df: pd.DataFrame):
        """ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        # åªåŒ…å«æ•°å€¼åˆ—
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        correlation_matrix = df[numeric_cols].corr()
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(correlation_matrix, 
                   annot=True, 
                   cmap='coolwarm', 
                   center=0,
                   square=True,
                   fmt='.2f')
        plt.title('å¥–åŠ±ç»„ä»¶ç›¸å…³æ€§çƒ­åŠ›å›¾')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'correlation_heatmap.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_anomaly_detection(self, df: pd.DataFrame):
        """ç»˜åˆ¶å¼‚å¸¸æ£€æµ‹å›¾"""
        anomalies = self.detect_anomalies()
        
        if not anomalies:
            return
        
        # æŒ‰ç»„ä»¶åˆ†ç»„å¼‚å¸¸
        component_anomalies = defaultdict(list)
        for anomaly in anomalies:
            component_anomalies[anomaly['component']].append(anomaly)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, (component, comp_anomalies) in enumerate(list(component_anomalies.items())[:4]):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # ç»˜åˆ¶æ­£å¸¸æ•°æ®
            episodes = df['episode']
            values = df[component]
            ax.plot(episodes, values, alpha=0.5, label='æ­£å¸¸æ•°æ®')
            
            # æ ‡è®°å¼‚å¸¸ç‚¹
            anomaly_episodes = [a['episode'] for a in comp_anomalies]
            anomaly_values = [a['value'] for a in comp_anomalies]
            ax.scatter(anomaly_episodes, anomaly_values, 
                      color='red', s=50, label=f'å¼‚å¸¸ç‚¹ ({len(comp_anomalies)}ä¸ª)')
            
            ax.set_title(f'{component} å¼‚å¸¸æ£€æµ‹')
            ax.set_xlabel('å›åˆ')
            ax.set_ylabel('å¥–åŠ±å€¼')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(component_anomalies), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'anomaly_detection.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def generate_analysis_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not self.reward_history:
            return "æ²¡æœ‰æ•°æ®å¯ä¾›åˆ†æ"
        
        analysis = self.analyze_component_evolution()
        anomalies = self.detect_anomalies()
        
        report_file = self.output_dir / 'reward_analysis_report.md'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# å¥–åŠ±ç³»ç»Ÿåˆ†ææŠ¥å‘Š\n\n")
            f.write(f"åˆ†ææ•°æ®: {len(self.reward_history)} ä¸ªå›åˆ\n\n")
            
            # ç»„ä»¶æ¦‚è§ˆ
            f.write("## å¥–åŠ±ç»„ä»¶æ¦‚è§ˆ\n\n")
            f.write("| ç»„ä»¶åç§° | å‡å€¼ | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | è¶‹åŠ¿ | ç¨³å®šæ€§ |\n")
            f.write("|---------|------|--------|--------|--------|------|--------|\n")
            
            for component, comp_analysis in analysis.items():
                stats = comp_analysis['statistics']
                trend = comp_analysis['trend']['trend_type']
                stability = comp_analysis['stability']['stability_level']
                
                f.write(f"| {component} | {stats['mean']:.4f} | {stats['std']:.4f} | "
                       f"{stats['min']:.4f} | {stats['max']:.4f} | {trend} | {stability} |\n")
            
            # å¼‚å¸¸æ£€æµ‹ç»“æœ
            f.write(f"\n## å¼‚å¸¸æ£€æµ‹ç»“æœ\n\n")
            f.write(f"æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸ç‚¹\n\n")
            
            if anomalies:
                f.write("| å›åˆ | ç»„ä»¶ | å¼‚å¸¸å€¼ | Zåˆ†æ•° |\n")
                f.write("|------|------|--------|-------|\n")
                
                for anomaly in anomalies[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    f.write(f"| {anomaly['episode']} | {anomaly['component']} | "
                           f"{anomaly['value']:.4f} | {anomaly['z_score']:.2f} |\n")
            
            # å»ºè®®
            f.write("\n## ä¼˜åŒ–å»ºè®®\n\n")
            
            # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
            unstable_components = [comp for comp, analysis in analysis.items() 
                                 if analysis['stability']['stability_level'] == 'unstable']
            
            if unstable_components:
                f.write(f"### ç¨³å®šæ€§æ”¹è¿›\n")
                f.write(f"ä»¥ä¸‹ç»„ä»¶è¡¨ç°ä¸ç¨³å®šï¼Œå»ºè®®è°ƒæ•´æƒé‡æˆ–å®ç°:\n")
                for comp in unstable_components:
                    f.write(f"- {comp}\n")
                f.write("\n")
            
            # è¶‹åŠ¿å»ºè®®
            decreasing_components = [comp for comp, analysis in analysis.items() 
                                   if analysis['trend']['trend_type'] == 'decreasing']
            
            if decreasing_components:
                f.write(f"### è¶‹åŠ¿ä¼˜åŒ–\n")
                f.write(f"ä»¥ä¸‹ç»„ä»¶å‘ˆä¸‹é™è¶‹åŠ¿ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´:\n")
                for comp in decreasing_components:
                    f.write(f"- {comp}\n")
        
        print(f"ğŸ“‹ åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return str(report_file)

if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    analyzer = RewardAnalyzer()
    
    # æ¨¡æ‹Ÿæ·»åŠ ä¸€äº›æ•°æ®
    for episode in range(100):
        components = {
            'local_connectivity': np.random.normal(0.5, 0.1),
            'incremental_balance': np.random.normal(0.3, 0.05),
            'boundary_compression': np.random.normal(0.7, 0.15),
            'exploration_bonus': np.random.normal(0.2, 0.08)
        }
        total_reward = sum(components.values()) + np.random.normal(0, 0.1)
        
        analyzer.add_episode_data(episode, total_reward, components)
    
    # ç”Ÿæˆåˆ†æ
    analyzer.generate_visualizations()
    analyzer.generate_analysis_report()
    
    print("âœ… å¥–åŠ±åˆ†æå®Œæˆ")
