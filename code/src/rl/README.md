# ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ æ¨¡å—

æœ¬æ¨¡å—å®ç°äº†åŸºäºé¡¹ç›®æ–‡æ¡£ä¸­MDPå»ºæ¨¡çš„å®Œæ•´ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿã€‚

## æ¦‚è¿°

ç³»ç»Ÿé‡‡ç”¨"è‡ªé¡¶å‘ä¸‹ä¼˜åŒ–"èŒƒå¼ï¼š
1. **METIS** æä¾›åˆå§‹åˆ†åŒº
2. **RLæ™ºèƒ½ä½“** æ‰§è¡Œè¿­ä»£å¾®è°ƒä»¥ä¼˜åŒ–åˆ†åŒº

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### ä¸»è¦æ¨¡å—

- **`environment.py`**: å®ç°çŠ¶æ€ç©ºé—´ã€åŠ¨ä½œç©ºé—´å’ŒçŠ¶æ€è½¬ç§»çš„MDPç¯å¢ƒ
- **`agent.py`**: å…·æœ‰Actor-Criticç½‘ç»œçš„PPOæ™ºèƒ½ä½“ï¼Œæ”¯æŒä¸¤é˜¶æ®µåŠ¨ä½œé€‰æ‹©
- **`state.py`**: çŠ¶æ€ç®¡ç†ï¼ŒåŒ…å«èŠ‚ç‚¹åµŒå…¥å’Œè¾¹ç•Œè·Ÿè¸ª
- **`action_space.py`**: ä¸¤é˜¶æ®µåŠ¨ä½œç©ºé—´ï¼Œæ”¯æŒæ©ç çº¦æŸ
- **`reward.py`**: å¤åˆå¥–åŠ±å‡½æ•°ï¼ˆå¹³è¡¡+è§£è€¦+å†…éƒ¨å¹³è¡¡ï¼‰
- **`utils.py`**: METISåˆå§‹åŒ–å’Œåˆ†åŒºè¯„ä¼°å·¥å…·
- **`scenario_generator.py`**: åœºæ™¯ç”Ÿæˆå™¨ï¼Œæ”¯æŒN-1æ•…éšœå’Œè´Ÿè·æ³¢åŠ¨
- **`gym_wrapper.py`**: OpenAI Gymç¯å¢ƒåŒ…è£…å™¨ï¼Œæ”¯æŒå¹¶è¡Œè®­ç»ƒ

### æ‰©å±•ç»„ä»¶

- **`__init__.py`**: æ¨¡å—åˆå§‹åŒ–æ–‡ä»¶ï¼Œå®šä¹‰å…¬å…±æ¥å£
- **ç»Ÿä¸€è®­ç»ƒç³»ç»Ÿ**: é€šè¿‡ `train_unified.py` é›†æˆæ‰€æœ‰è®­ç»ƒæ¨¡å¼

## ğŸ“Š çŠ¶æ€è¡¨ç¤º

MDPçŠ¶æ€åŒ…å«ï¼š
- **èŠ‚ç‚¹ç‰¹å¾åµŒå…¥ (H)**: ä»GATç¼–ç å™¨é¢„è®¡ç®—çš„é™æ€åµŒå…¥
- **èŠ‚ç‚¹åˆ†é…æ ‡ç­¾ (z_t)**: åŠ¨æ€åˆ†åŒºåˆ†é…
- **è¾¹ç•ŒèŠ‚ç‚¹**: ä¸ä¸åŒåˆ†åŒºèŠ‚ç‚¹ç›¸é‚»çš„èŠ‚ç‚¹
- **åŒºåŸŸåµŒå…¥**: æ¯ä¸ªåˆ†åŒºçš„èšåˆåµŒå…¥

## ğŸ¯ åŠ¨ä½œç©ºé—´

ä¸¤é˜¶æ®µåŠ¨ä½œé€‰æ‹©ï¼š
1. **èŠ‚ç‚¹é€‰æ‹©**: é€‰æ‹©è¦ç§»åŠ¨çš„è¾¹ç•ŒèŠ‚ç‚¹
2. **åˆ†åŒºé€‰æ‹©**: ä»ç›¸é‚»åˆ†åŒºä¸­é€‰æ‹©ç›®æ ‡åˆ†åŒº

åŠ¨ä½œæ©ç å¼ºåˆ¶æ‰§è¡Œï¼š
- åªæœ‰è¾¹ç•ŒèŠ‚ç‚¹å¯ä»¥ç§»åŠ¨
- åªå…è®¸ç§»åŠ¨åˆ°ç›¸é‚»åˆ†åŒº
- è¿é€šæ€§çº¦æŸï¼ˆå¯é€‰ï¼‰

## ğŸ† å¥–åŠ±å‡½æ•°

åŒ…å«ä¸‰ä¸ªç»„ä»¶çš„å¤åˆå¥–åŠ±ï¼š
- **R_balance**: åˆ†åŒºè´Ÿè½½å¹³è¡¡ (-Var(Lâ‚, ..., Lâ‚–))
- **R_decoupling**: ç”µæ°”è§£è€¦ (-Î£|Y_uv| å¯¹äºè€¦åˆè¾¹)
- **R_internal_balance**: å†…éƒ¨åŠŸç‡å¹³è¡¡ (-Î£(P_gen - P_load)Â²)

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬è®­ç»ƒ

```python
from src.rl import PowerGridPartitioningEnv, PPOAgent

# åˆ›å»ºç¯å¢ƒ
env = PowerGridPartitioningEnv(
    hetero_data=hetero_data,
    node_embeddings=node_embeddings,
    num_partitions=3
)

# åˆ›å»ºæ™ºèƒ½ä½“
agent = PPOAgent(
    node_embedding_dim=128,
    region_embedding_dim=256,
    num_partitions=3
)

# è®­ç»ƒï¼ˆé€šè¿‡ç»Ÿä¸€è®­ç»ƒç³»ç»Ÿï¼‰
python train_unified.py --mode standard --case ieee14 --partitions 3
```

### ä½¿ç”¨ç»Ÿä¸€è®­ç»ƒè„šæœ¬

```bash
# å¿«é€Ÿè®­ç»ƒï¼ˆé»˜è®¤è®¾ç½®ï¼‰
python train_unified.py --mode quick --case ieee14 --episodes 100 --partitions 3

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è®­ç»ƒ
python train_unified.py --config config_unified.yaml

# IEEE 118èŠ‚ç‚¹å¤§è§„æ¨¡è®­ç»ƒ
python train_unified.py --mode ieee118

# å¹¶è¡Œè®­ç»ƒ
python train_unified.py --mode parallel --episodes 2000

# è¯¾ç¨‹å­¦ä¹ è®­ç»ƒ
python train_unified.py --mode curriculum
```

### é…ç½®ç®¡ç†

ä½¿ç”¨ `config_unified.yaml` é…ç½®ï¼š
- æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- ç¯å¢ƒå‚æ•°
- GATç¼–ç å™¨è®¾ç½®
- PPOè¶…å‚æ•°
- è®­ç»ƒè®¾ç½®
- å¹¶è¡Œè®­ç»ƒå‚æ•°
- åœºæ™¯ç”Ÿæˆé…ç½®

## âœ¨ å…³é”®ç‰¹æ€§

### ç‰©ç†å¼•å¯¼å­¦ä¹ 
- åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­èå…¥ç”µæ°”é˜»æŠ—
- åŸºäºç”µåŠ›ç³»ç»Ÿç›®æ ‡çš„å¥–åŠ±å‡½æ•°
- é€šè¿‡åŠ¨ä½œæ©ç å¼ºåˆ¶ç‰©ç†çº¦æŸ

### å¯æ‰©å±•æ¶æ„
- å¼‚æ„å›¾è¡¨ç¤º
- é«˜æ•ˆçš„è¾¹ç•ŒèŠ‚ç‚¹è·Ÿè¸ª
- å¢é‡çŠ¶æ€æ›´æ–°
- æ”¯æŒå¤šç§ç”µåŠ›ç³»ç»Ÿè§„æ¨¡

### é²æ£’è®­ç»ƒ
- å¸¦åŠ¨ä½œæ©ç çš„PPO
- å…¨é¢çš„æ—¥å¿—è®°å½•å’Œæ£€æŸ¥ç‚¹
- åœºæ™¯ç”Ÿæˆæ”¯æŒ
- è¯¾ç¨‹å­¦ä¹ æ”¯æŒ
- è¯„ä¼°æŒ‡æ ‡

### ç³»ç»Ÿé›†æˆ
- ä¸ç°æœ‰æ•°æ®å¤„ç†æµæ°´çº¿å…¼å®¹
- ä½¿ç”¨é¢„è®­ç»ƒçš„GATåµŒå…¥
- æ”¯æŒå¤šç§ç”µåŠ›ç½‘ç»œæ ¼å¼
- ç»Ÿä¸€çš„è®­ç»ƒå…¥å£

## ğŸ§ª éªŒè¯

ç³»ç»Ÿé›†æˆéªŒè¯ï¼š
```bash
# éªŒè¯å®Œæ•´è®­ç»ƒæµæ°´çº¿
python main.py --mode quick

# éªŒè¯å¹¶è¡Œè®­ç»ƒåŠŸèƒ½
python main.py --mode parallel

# éªŒè¯å¢å¼ºå¥–åŠ±ç³»ç»Ÿ
python -c "from code.src.rl.ab_testing import create_standard_ab_test; framework = create_standard_ab_test(); framework.run_all_experiments()"
```

è¿™äº›å‘½ä»¤éªŒè¯äº†æ•´ä¸ªç³»ç»Ÿçš„ç«¯åˆ°ç«¯åŠŸèƒ½ã€‚

## ğŸ›ï¸ åœºæ™¯ç”Ÿæˆ

### N-1æ•…éšœæ¨¡æ‹Ÿ
```python
from src.rl.scenario_generator import ScenarioGenerator

generator = ScenarioGenerator(base_case_data)

# ç”ŸæˆéšæœºN-1æ•…éšœ
perturbed_case = generator.generate_random_scene()

# åº”ç”¨ç‰¹å®šæ•…éšœ
case_n1 = generator.apply_specific_contingency(base_case_data, branch_idx=10)
```

### è´Ÿè·æ³¢åŠ¨
```python
# åº”ç”¨è´Ÿè·ç¼©æ”¾
case_scaled = generator.apply_load_scaling(base_case_data, scale_factor=1.2)

# æ‰¹é‡ç”Ÿæˆåœºæ™¯
scenarios = generator.generate_batch_scenarios(num_scenarios=100)
```

## ğŸŒ å¹¶è¡Œè®­ç»ƒ

### OpenAI GymåŒ…è£…å™¨
```python
from src.rl.gym_wrapper import make_parallel_env

# åˆ›å»ºå¹¶è¡Œç¯å¢ƒ
parallel_env = make_parallel_env(
    base_case_data=case_data,
    config=config,
    num_envs=12,
    use_scenario_generator=True
)
```

### ä½¿ç”¨Stable-Baselines3
```bash
# å®‰è£…ä¾èµ–
pip install stable-baselines3[extra]

# è¿è¡Œå¹¶è¡Œè®­ç»ƒ
python train_unified.py --mode parallel --episodes 5000
```

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **GPUä½¿ç”¨**: åœ¨é…ç½®ä¸­è®¾ç½® `device: cuda` å¯ç”¨GPUåŠ é€Ÿ
2. **æ‰¹é‡æ›´æ–°**: å¢åŠ  `update_interval` ä»¥è·å¾—æ›´ç¨³å®šçš„è®­ç»ƒ
3. **å†…å­˜ä¼˜åŒ–**: å¯¹å¤§å‹ç”µç½‘ä½¿ç”¨è¾ƒå°çš„åµŒå…¥ç»´åº¦
4. **æ”¶æ•›ç›‘æ§**: ç›‘æ§å¥–åŠ±æ›²çº¿å¹¶è°ƒæ•´å­¦ä¹ ç‡

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ— æœ‰æ•ˆåŠ¨ä½œ**: æ£€æŸ¥è¾¹ç•ŒèŠ‚ç‚¹è®¡ç®—å’ŒåŠ¨ä½œæ©ç 
2. **è®­ç»ƒä¸ç¨³å®š**: é™ä½å­¦ä¹ ç‡æˆ–å¢åŠ è£å‰ª
3. **å†…å­˜é—®é¢˜**: å‡å°‘æ‰¹å¤§å°æˆ–åµŒå…¥ç»´åº¦
4. **è®­ç»ƒç¼“æ…¢**: å¯ç”¨GPUæˆ–å‡å°‘ç½‘ç»œå¤æ‚åº¦

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•ï¼š
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### ç³»ç»Ÿæ£€æŸ¥

```bash
# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
python main.py --mode quick --episodes 10

# æŸ¥çœ‹å¯ç”¨é…ç½®
python -c "import yaml; print(yaml.safe_load(open('config.yaml')))"

# è¿è¡Œå¿«é€ŸéªŒè¯
python main.py --mode quick
```

## ğŸ”Œ æ‰©å±•ç‚¹

æ¨¡å—åŒ–è®¾è®¡å…è®¸è½»æ¾æ‰©å±•ï¼š

- **è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°**: ä¿®æ”¹ `reward.py`
- **é«˜çº§åŠ¨ä½œç©ºé—´**: æ‰©å±• `action_space.py`
- **ä¸åŒç®—æ³•**: åœ¨ `agent.py` ä¸­æ›¿æ¢PPO
- **è¯¾ç¨‹å­¦ä¹ **: é€šè¿‡ç»Ÿä¸€è®­ç»ƒç³»ç»Ÿå®ç°
- **æ–°åœºæ™¯ç±»å‹**: æ‰©å±• `scenario_generator.py`

## ğŸ“ˆ è®­ç»ƒæ¨¡å¼

| æ¨¡å¼ | æè¿° | ç”¨é€” | ç‰¹è‰²åŠŸèƒ½ |
|------|------|------|----------|
| `quick` | å¿«é€Ÿæµ‹è¯• | åŠŸèƒ½éªŒè¯ | 100å›åˆï¼Œå¿«é€Ÿæ”¶æ•› |
| `standard` | æ ‡å‡†è®­ç»ƒ | å¸¸è§„ç ”ç©¶ | 1000å›åˆï¼Œå¹³è¡¡æ€§èƒ½ |
| `full` | å®Œæ•´è®­ç»ƒ | æ·±åº¦ç ”ç©¶ | 2000å›åˆï¼Œé«˜è´¨é‡ç»“æœ |
| `ieee118` | å¤§è§„æ¨¡è®­ç»ƒ | å¤æ‚ç³»ç»Ÿ | è‡ªåŠ¨å¯ç”¨å¹¶è¡Œ+åœºæ™¯ç”Ÿæˆ |
| `parallel` | å¹¶è¡Œè®­ç»ƒ | é«˜æ•ˆè®­ç»ƒ | å¤šè¿›ç¨‹ï¼Œ3-5å€åŠ é€Ÿ |
| `curriculum` | è¯¾ç¨‹å­¦ä¹  | æ¸è¿›è®­ç»ƒ | åˆ†åŒºæ•°é€’å¢ï¼Œç¨³å®šæ”¶æ•› |

## ğŸ“š é…ç½®ç¤ºä¾‹

### å¿«é€Ÿæµ‹è¯•é…ç½®
```yaml
training:
  mode: quick
  num_episodes: 100
  max_steps_per_episode: 50

environment:
  num_partitions: 3
  
agent:
  lr_actor: 3e-4
  lr_critic: 1e-3
```

### å¤§è§„æ¨¡è®­ç»ƒé…ç½®
```yaml
data:
  case_name: ieee118

environment:
  num_partitions: 8
  max_steps: 500

parallel_training:
  enabled: true
  num_cpus: 12

scenario_generation:
  enabled: true
  perturb_prob: 0.8
```



## ğŸ“‹ ä¾èµ–è¦æ±‚

### å¿…éœ€ä¾èµ–
```bash
pip install torch torch-geometric numpy scipy scikit-learn pandas pyyaml matplotlib
```

### å¯é€‰ä¾èµ–
```bash
# å¹¶è¡Œè®­ç»ƒæ”¯æŒ
pip install stable-baselines3[extra]

# å¯è§†åŒ–å¢å¼º
pip install plotly tensorboard

# æ€§èƒ½ä¼˜åŒ–
pip install metis  # æˆ–ä½¿ç”¨conda install -c conda-forge metis
```

## ğŸ‰ å®Œæ•´å·¥ä½œæµç¨‹

```bash
# 1. å¿«é€Ÿä½“éªŒ
python main.py --mode quick

# 2. æ ‡å‡†è®­ç»ƒ
python main.py --mode standard --case ieee30 --partitions 5

# 3. å¤§è§„æ¨¡è®­ç»ƒ
python main.py --mode ieee118

# 4. å¹¶è¡Œè®­ç»ƒ
python main.py --mode parallel

# 5. è¯¾ç¨‹å­¦ä¹ 
python main.py --mode curriculum
```


