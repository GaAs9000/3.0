"""
ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ çš„å®ç”¨å‡½æ•°

æœ¬æ¨¡å—æä¾›å®ç”¨å‡½æ•°ï¼ŒåŒ…æ‹¬ï¼š
- ç”¨äºåˆå§‹åˆ†åŒºçš„METISåˆå§‹åŒ–
- åˆ†åŒºè´¨é‡è¯„ä¼°
- çŠ¶æ€ç®¡ç†åŠ©æ‰‹
- å¯è§†åŒ–å·¥å…·
"""

import torch
import numpy as np
import networkx as nx
import random
from typing import Dict, List, Tuple, Optional, Any
from torch_geometric.data import HeteroData
import warnings

try:
    import pymetis
    METIS_AVAILABLE = True
except (ImportError, RuntimeError):
    METIS_AVAILABLE = False
    warnings.warn("PyMetis åº“åŠ è½½å¤±è´¥ã€‚å°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ï¼ˆè°±èšç±»æˆ–éšæœºåˆ†åŒºï¼‰è¿›è¡Œåˆå§‹åŒ–ã€‚")

try:
    from sklearn.cluster import SpectralClustering
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False


class IntelligentAdmittanceExtractor:
    """
    æ™ºèƒ½å¯¼çº³æå–å™¨ï¼Œæä¾›å¤šç§å¯¼çº³æå–ç­–ç•¥

    ä»RewardFunctionä¸­æå–çš„æ™ºèƒ½å¯¼çº³æå–é€»è¾‘ï¼Œ
    ç¡®ä¿PartitionEvaluatorä½¿ç”¨ä¸å¥–åŠ±å‡½æ•°ç›¸åŒçš„é«˜è´¨é‡å¯¼çº³æ•°æ®
    """

    def __init__(self, device: torch.device):
        self.device = device

    def extract_admittance(self, edge_attr: torch.Tensor, edge_index: torch.Tensor = None) -> Tuple[torch.Tensor, str]:
        """
        æ™ºèƒ½æå–å¯¼çº³æ•°æ®ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•å¤šç§æ–¹æ³•

        Args:
            edge_attr: è¾¹å±æ€§å¼ é‡
            edge_index: è¾¹ç´¢å¼•å¼ é‡ï¼ˆç”¨äºæ‹“æ‰‘ä¼°ç®—ï¼‰

        Returns:
            admittance: å¯¼çº³å¼ é‡
            source: æ•°æ®æ¥æºæ ‡è¯†
        """
        # æ–¹æ³•1: ä»è¾¹å±æ€§ç›´æ¥æå–
        admittance = self._identify_admittance_from_attributes(edge_attr)
        if admittance is not None:
            return admittance, 'extracted'

        # æ–¹æ³•2: ä»é˜»æŠ—è®¡ç®—å¯¼çº³
        admittance = self._calculate_admittance_from_impedance(edge_attr)
        if admittance is not None:
            return admittance, 'calculated'

        # æ–¹æ³•3: åŸºäºæ‹“æ‰‘ä¼°ç®—ï¼ˆå¦‚æœæä¾›äº†edge_indexï¼‰
        if edge_index is not None:
            admittance = self._estimate_admittance_from_topology(edge_index)
            if admittance is not None:
                return admittance, 'estimated'

        # æ–¹æ³•4: ä¿å®ˆé»˜è®¤å€¼ï¼ˆå¸¦è­¦å‘Šï¼‰
        return self._get_conservative_admittance_defaults(edge_attr.shape[0]), 'default'

    def _identify_admittance_from_attributes(self, edge_attr: torch.Tensor) -> Optional[torch.Tensor]:
        """
        ä»è¾¹å±æ€§ä¸­æ™ºèƒ½è¯†åˆ«å¯¼çº³æ•°æ®

        æ ¹æ®data_processing.pyä¸­çš„ç‰¹å¾é¡ºåºï¼š
        [r, x, b, z_magnitude, y, rateA, angle_diff, is_transformer, status]
        å¯¼çº³yåœ¨ç¬¬4åˆ—ï¼ˆç´¢å¼•4ï¼‰
        """
        if edge_attr.shape[1] <= 4:
            return None

        # æå–å¯¼çº³åˆ—ï¼ˆç¬¬4åˆ—ï¼‰
        admittance_candidate = edge_attr[:, 4]

        # æ£€æŸ¥å¯¼çº³å€¼çš„åˆç†æ€§
        if self._validate_admittance_values(admittance_candidate):
            return torch.abs(admittance_candidate)

        # å¦‚æœç¬¬4åˆ—ä¸åˆç†ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„åˆ—
        for col_idx in [3, 5]:  # z_magnitude, rateA
            if edge_attr.shape[1] > col_idx:
                candidate = edge_attr[:, col_idx]
                if self._validate_admittance_values(candidate):
                    return torch.abs(candidate)

        return None

    def _calculate_admittance_from_impedance(self, edge_attr: torch.Tensor) -> Optional[torch.Tensor]:
        """
        ä»é˜»æŠ—å‚æ•°è®¡ç®—å¯¼çº³

        ç‰¹å¾é¡ºåºï¼š[r, x, b, z_magnitude, y, ...]
        """
        if edge_attr.shape[1] < 2:
            return None

        # æå–ç”µé˜»å’Œç”µæŠ—
        r = edge_attr[:, 0]  # ç”µé˜»
        x = edge_attr[:, 1]  # ç”µæŠ—

        # è®¡ç®—é˜»æŠ—æ¨¡é•¿
        z_squared = r**2 + x**2

        # é¿å…é™¤é›¶ï¼Œè®¾ç½®æœ€å°é˜»æŠ—å€¼
        min_impedance = 1e-6
        z_magnitude = torch.sqrt(z_squared.clamp(min=min_impedance**2))

        # è®¡ç®—å¯¼çº³ Y = 1/Z
        admittance = 1.0 / z_magnitude

        # éªŒè¯ç»“æœ
        if self._validate_admittance_values(admittance):
            return admittance

        return None

    def _estimate_admittance_from_topology(self, edge_index: torch.Tensor) -> Optional[torch.Tensor]:
        """
        åŸºäºç½‘ç»œæ‹“æ‰‘ä¼°ç®—å¯¼çº³
        """
        num_edges = edge_index.shape[1]
        if num_edges == 0:
            return torch.empty(0, device=self.device)

        # è®¡ç®—èŠ‚ç‚¹åº¦æ•°
        max_node = edge_index.max().item() + 1
        node_degrees = torch.zeros(max_node, device=self.device)

        # ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„åº¦æ•°
        for i in range(num_edges):
            node1, node2 = edge_index[:, i]
            node_degrees[node1] += 1
            node_degrees[node2] += 1

        # åŸºäºè¿æ¥çš„èŠ‚ç‚¹åº¦æ•°ä¼°ç®—å¯¼çº³
        admittance_estimates = torch.zeros(num_edges, device=self.device)

        for i in range(num_edges):
            node1, node2 = edge_index[:, i]

            # åŸºäºèŠ‚ç‚¹åº¦æ•°çš„å¯å‘å¼ä¼°ç®—
            avg_degree = (node_degrees[node1] + node_degrees[node2]) / 2.0

            # å…¸å‹å¯¼çº³èŒƒå›´ï¼š0.5-5.0ï¼ŒåŸºäºåº¦æ•°è°ƒæ•´
            base_admittance = 2.0
            degree_factor = torch.clamp(avg_degree / 3.0, 0.5, 2.0)

            admittance_estimates[i] = base_admittance * degree_factor

        return admittance_estimates

    def _validate_admittance_values(self, admittance: torch.Tensor) -> bool:
        """éªŒè¯å¯¼çº³å€¼çš„åˆç†æ€§"""
        if admittance.numel() == 0:
            return False

        # æ£€æŸ¥NaNå’ŒInf
        if torch.any(torch.isnan(admittance)) or torch.any(torch.isinf(admittance)):
            return False

        # æ£€æŸ¥æ˜¯å¦å…¨ä¸ºé›¶
        if torch.all(admittance == 0):
            return False

        # æ£€æŸ¥åˆç†èŒƒå›´ï¼ˆå…¸å‹è¾“ç”µçº¿è·¯å¯¼çº³ï¼š0.1-10 Sï¼‰
        valid_range = (0.01, 20.0)
        abs_admittance = torch.abs(admittance)

        if torch.any(abs_admittance < valid_range[0]) or torch.any(abs_admittance > valid_range[1]):
            # å¦‚æœåªæœ‰å°‘æ•°å€¼è¶…å‡ºèŒƒå›´ï¼Œä»ç„¶å¯ä»¥æ¥å—
            out_of_range_ratio = torch.sum(
                (abs_admittance < valid_range[0]) | (abs_admittance > valid_range[1])
            ).float() / admittance.numel()

            return out_of_range_ratio < 0.3  # å…è®¸30%çš„å€¼è¶…å‡ºèŒƒå›´

        return True

    def _get_conservative_admittance_defaults(self, num_edges: int) -> torch.Tensor:
        """
        è·å–ä¿å®ˆçš„é»˜è®¤å¯¼çº³å€¼ï¼Œå¹¶è®°å½•è¯¦ç»†è­¦å‘Š
        """
        # è®°å½•è¯¦ç»†è­¦å‘Š
        warning_msg = (
            f"æ— æ³•æå–æˆ–è®¡ç®—å¯¼çº³æ•°æ®ï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼ã€‚"
            f"è¾¹æ•°: {num_edges}ã€‚"
            f"è¿™å¯èƒ½å½±å“ç”µæ°”è§£è€¦è®¡ç®—çš„å‡†ç¡®æ€§ã€‚"
            f"å»ºè®®æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼æˆ–æä¾›å¯¼çº³ä¿¡æ¯ã€‚"
        )

        print(f"âš ï¸ {warning_msg}")

        if num_edges == 0:
            return torch.empty(0, device=self.device)

        # ä½¿ç”¨åŸºäºç½‘ç»œè§„æ¨¡çš„åˆç†é»˜è®¤å€¼
        # å…¸å‹è¾“ç”µçº¿è·¯å¯¼çº³èŒƒå›´ï¼š1-3 S
        mean_admittance = 2.0
        std_admittance = 0.3

        # ç”Ÿæˆæ­£æ€åˆ†å¸ƒçš„å¯¼çº³å€¼
        admittance = torch.normal(
            mean=mean_admittance,
            std=std_admittance,
            size=(num_edges,),
            device=self.device
        )

        # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        admittance = torch.clamp(torch.abs(admittance), 0.8, 4.0)

        return admittance


class MetisInitializer:
    """
    åŸºäºMETISçš„ç”µåŠ›ç½‘ç»œåˆ†åŒºåˆå§‹åŒ–
    
    ä½¿ç”¨METISå›¾åˆ†åŒºç®—æ³•æä¾›åˆå§‹åˆ†åŒºï¼Œ
    èŠ‚ç‚¹æƒé‡åŸºäºåŠŸç‡è´Ÿè½½ã€‚
    """
    
    def __init__(self, hetero_data: HeteroData, device: torch.device, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–METISåˆ†åŒºå™¨

        Args:
            hetero_data: å¼‚æ„å›¾æ•°æ®
            device: è®¡ç®—è®¾å¤‡
            config: é…ç½®å­—å…¸ï¼Œç”¨äºæ§åˆ¶è¾“å‡ºè¯¦ç»†ç¨‹åº¦
        """
        self.device = device
        self.hetero_data = hetero_data.to(device)
        self.config = config

        # è·å–è°ƒè¯•é…ç½®
        debug_config = config.get('debug', {}) if config else {}
        self.training_output = debug_config.get('training_output', {})

        # è®¾ç½®ä¸METISå…¼å®¹çš„å›¾è¡¨ç¤º
        self._setup_graph_representation()
        
    def _setup_graph_representation(self):
        """è®¾ç½®ä¸METISå…¼å®¹çš„å›¾è¡¨ç¤º"""
        # è·å–èŠ‚ç‚¹æ€»æ•°
        self.total_nodes = sum(x.shape[0] for x in self.hetero_data.x_dict.values())
        
        # è®¾ç½®èŠ‚ç‚¹æ˜ å°„
        self._setup_node_mappings()
        
        # æå–èŠ‚ç‚¹æƒé‡ï¼ˆåŠŸç‡è´Ÿè½½ï¼‰
        self._extract_node_weights()
        
        # ä¸ºMETISæ„å»ºé‚»æ¥åˆ—è¡¨
        self._build_adjacency_list()
        
    def _setup_node_mappings(self):
        """è®¾ç½®å±€éƒ¨å’Œå…¨å±€èŠ‚ç‚¹ç´¢å¼•ä¹‹é—´çš„æ˜ å°„"""
        self.node_types = list(self.hetero_data.x_dict.keys())
        self.local_to_global_map = {}
        
        global_idx = 0
        for node_type in self.node_types:
            num_nodes = self.hetero_data.x_dict[node_type].shape[0]
            global_indices = torch.arange(global_idx, global_idx + num_nodes, device=self.device)
            self.local_to_global_map[node_type] = global_indices
            global_idx += num_nodes
            
    def _local_to_global(self, local_indices: torch.Tensor, node_type: str) -> torch.Tensor:
        """å°†å±€éƒ¨ç´¢å¼•è½¬æ¢ä¸ºå…¨å±€ç´¢å¼•"""
        return self.local_to_global_map[node_type][local_indices]
        
    def _extract_node_weights(self):
        """åŸºäºåŠŸç‡è´Ÿè½½æå–èŠ‚ç‚¹æƒé‡"""
        # è¿æ¥æ‰€æœ‰èŠ‚ç‚¹ç‰¹å¾
        all_features = []
        for node_type in self.node_types:
            features = self.hetero_data.x_dict[node_type]
            all_features.append(features)
            
        all_node_features = torch.cat(all_features, dim=0)
        
        # æå–è´Ÿè½½æ•°æ®ï¼ˆå‡è®¾Pdåœ¨ç´¢å¼•0å¤„ï¼‰
        if all_node_features.shape[1] > 0:
            loads = all_node_features[:, 0]  # Pdåˆ—
            # è½¬æ¢ä¸ºMETISçš„æ­£æ•´æ•°ï¼ˆç¼©æ”¾å¹¶æ·»åŠ åç§»ï¼‰
            loads_scaled = (loads * 1000 + 1000).clamp(min=1).int()
            try:
                self.node_weights = loads_scaled.cpu().numpy()
            except RuntimeError:
                # numpyè½¬æ¢å¤±è´¥æ—¶çš„å›é€€
                self.node_weights = [int(x) for x in loads_scaled.cpu().tolist()]
        else:
            # å¦‚æœæ²¡æœ‰è´Ÿè½½æ•°æ®åˆ™ä½¿ç”¨å‡åŒ€æƒé‡
            self.node_weights = [1] * self.total_nodes
            
    def _build_adjacency_list(self):
        """
        ä»å¼‚æ„å›¾æ„å»ºé‚»æ¥åˆ—è¡¨ (ä¿®å¤ç‰ˆæœ¬)
        """
        self.adjacency_list = [[] for _ in range(self.total_nodes)]

        # éå†æ‰€æœ‰è¾¹ç±»å‹ï¼Œæ„å»ºé‚»æ¥å…³ç³»
        for edge_type in self.hetero_data.edge_types:
            edge_index = self.hetero_data[edge_type].edge_index

            # è§£æè¾¹ç±»å‹å…ƒç»„ (src_node_type, relation, dst_node_type)
            src_node_type, relation, dst_node_type = edge_type

            # ä½¿ç”¨å·²æœ‰çš„æ˜ å°„æ–¹æ³•è½¬æ¢ä¸ºå…¨å±€ç´¢å¼•
            src_global = self._local_to_global(edge_index[0], src_node_type)
            dst_global = self._local_to_global(edge_index[1], dst_node_type)

            # æ·»åŠ è¾¹åˆ°é‚»æ¥åˆ—è¡¨
            for src, dst in zip(src_global, dst_global):
                src_idx = src.item()
                dst_idx = dst.item()

                # æ£€æŸ¥å…¨å±€ç´¢å¼•æœ‰æ•ˆæ€§
                if 0 <= src_idx < self.total_nodes and 0 <= dst_idx < self.total_nodes:
                    # æ·»åŠ åŒå‘è¿æ¥ï¼ˆæ— å‘å›¾ï¼‰
                    if dst_idx not in self.adjacency_list[src_idx]:
                        self.adjacency_list[src_idx].append(dst_idx)
                    if src_idx not in self.adjacency_list[dst_idx]:
                        self.adjacency_list[dst_idx].append(src_idx)

        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        show_metis_details = self.training_output.get('show_metis_details', True)
        only_show_errors = self.training_output.get('only_show_errors', False)

        if show_metis_details and not only_show_errors:
            edge_count = sum(len(neighbors) for neighbors in self.adjacency_list) // 2
            non_isolated = sum(1 for neighbors in self.adjacency_list if len(neighbors) > 0)
            from code.src.utils_common import safe_rich_debug
            safe_rich_debug(f"æ„å»ºé‚»æ¥åˆ—è¡¨: {edge_count} æ¡è¾¹, {non_isolated} ä¸ªéå­¤ç«‹èŠ‚ç‚¹", "metis")
        
    def initialize_partition(self, num_partitions: int) -> torch.Tensor:
        """
        ä½¿ç”¨å¤šé˜¶æ®µæ–¹æ³•åˆå§‹åŒ–åˆ†åŒº

        1. å°è¯• PyMetis (å¦‚æœå¯ç”¨)
        2. å¦‚æœå¤±è´¥ï¼Œå›é€€åˆ°è°±èšç±»
        3. å¦‚æœä¸¤è€…éƒ½å¤±è´¥ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸

        å‚æ•°:
            num_partitions: ç›®æ ‡åˆ†åŒºæ•°

        è¿”å›:
            åˆå§‹åˆ†åŒºæ ‡ç­¾ [num_nodes]
        """
        try:
            # 1. å°è¯• METIS
            show_metis_details = self.training_output.get('show_metis_details', True)
            only_show_errors = self.training_output.get('only_show_errors', False)

            if show_metis_details and not only_show_errors:
                print("ğŸš€ ä½¿ç”¨ METIS è¿›è¡Œé«˜è´¨é‡çš„åˆå§‹åˆ†åŒº...")
            partition_labels = self._metis_partition(num_partitions)
            if show_metis_details and not only_show_errors:
                from code.src.utils_common import safe_rich_debug
                safe_rich_debug("METIS åˆ†åŒºæˆåŠŸ", "metis")
        except (ImportError, Exception) as e:
            from code.src.utils_common import safe_rich_warning
            safe_rich_warning(f"METIS åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°è°±èšç±»...")
            try:
                # 2. å°è¯•è°±èšç±»
                partition_labels = self._spectral_partition(num_partitions)
                from code.src.utils_common import safe_rich_debug
                safe_rich_debug("è°±èšç±»åˆ†åŒºæˆåŠŸ", "metis")
            except Exception as e_spectral:
                from code.src.utils_common import safe_rich_error
                safe_rich_error(f"è°±èšç±»ä¹Ÿå¤±è´¥: {e_spectral}")
                raise RuntimeError("æ— æ³•ä½¿ç”¨ METIS æˆ–è°±èšç±»è¿›è¡Œåˆå§‹åˆ†åŒºã€‚è¯·æ£€æŸ¥æ‚¨çš„ç¯å¢ƒå’Œæ•°æ®ã€‚") from e_spectral

        # æ£€æŸ¥å¹¶ä¿®å¤è¿é€šæ€§
        repaired_labels = self._check_and_repair_connectivity(partition_labels, num_partitions)

        return repaired_labels
            
    def _metis_partition(self, num_partitions: int) -> torch.Tensor:
        """ä½¿ç”¨PyMetisç®—æ³•åˆ†åŒº"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
        if not any(self.adjacency_list):
            # æ²¡æœ‰è¾¹ - ä½¿ç”¨éšæœºåˆ†åŒº
            return self._random_partition(num_partitions)
            
        try:
            # PyMetis éœ€è¦é‚»æ¥åˆ—è¡¨æ ¼å¼ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ numpy æ•°ç»„
            adjacency_list = [np.array(neighbors, dtype=np.int32) for neighbors in self.adjacency_list]
            
            # ä½¿ç”¨ PyMetis è¿›è¡Œåˆ†åŒº
            n_cuts, labels = pymetis.part_graph(num_partitions, adjacency=adjacency_list)
            
            # PyMetis è¿”å› 0-based æ ‡ç­¾ï¼Œè½¬æ¢ä¸º 1-based
            return torch.tensor(labels + 1, dtype=torch.long, device=self.device)
            
        except Exception as e:
            warnings.warn(f"PyMetiså¤±è´¥ï¼š{e}ã€‚ä½¿ç”¨è°±èšç±»å›é€€ã€‚")
            return self._spectral_partition(num_partitions)
            
    def _spectral_partition(self, num_partitions: int) -> torch.Tensor:
        """ä½¿ç”¨è°±èšç±»åˆ†åŒº"""
        # æ„å»ºé‚»æ¥çŸ©é˜µ
        adj_matrix = np.zeros((self.total_nodes, self.total_nodes))
        
        for i, neighbors in enumerate(self.adjacency_list):
            for j in neighbors:
                adj_matrix[i, j] = 1.0
                
        # å¤„ç†è¾¹ç•Œæƒ…å†µ
        if np.sum(adj_matrix) == 0:
            return self._random_partition(num_partitions)
            
        try:
            clustering = SpectralClustering(
                n_clusters=num_partitions,
                affinity='precomputed',
                random_state=42
            )
            
            labels = clustering.fit_predict(adj_matrix)
            
            # è½¬æ¢ä¸ºåŸºäº1çš„ç´¢å¼•å’Œtorchå¼ é‡
            return torch.tensor(labels + 1, dtype=torch.long, device=self.device)
            
        except Exception as e:
            warnings.warn(f"è°±èšç±»å¤±è´¥ï¼š{e}ã€‚ä½¿ç”¨éšæœºåˆ†åŒºã€‚")
            return self._random_partition(num_partitions)
            
    def _random_partition(self, num_partitions: int) -> torch.Tensor:
        """ä½œä¸ºæœ€ç»ˆå›é€€çš„éšæœºåˆ†åŒº"""
        partition = torch.randint(
            1, num_partitions + 1,
            (self.total_nodes,),
            device=self.device
        )
        return partition

    def _check_and_repair_connectivity(self, partition_labels: torch.Tensor, num_partitions: int) -> torch.Tensor:
        """
        æ£€æŸ¥å¹¶ä¿®å¤åˆ†åŒºè¿é€šæ€§

        Args:
            partition_labels: åˆå§‹åˆ†åŒºæ ‡ç­¾
            num_partitions: åˆ†åŒºæ•°é‡

        Returns:
            ä¿®å¤åçš„åˆ†åŒºæ ‡ç­¾
        """
        # print("ğŸ”§ æ£€æŸ¥å¹¶ä¿®å¤åˆ†åŒºè¿é€šæ€§...")
        labels_np = partition_labels.cpu().numpy()

        # æ„å»ºNetworkXå›¾
        G = nx.Graph()
        G.add_nodes_from(range(self.total_nodes))

        # æ·»åŠ è¾¹
        for i in range(self.total_nodes):
            for neighbor in self.adjacency_list[i]:
                G.add_edge(i, neighbor)

        # æ£€æŸ¥æ¯ä¸ªåˆ†åŒºçš„è¿é€šæ€§
        repaired_labels = labels_np.copy()
        needs_repair = True
        repair_iterations = 0
        max_repair_iterations = 3

        while needs_repair and repair_iterations < max_repair_iterations:
            needs_repair = False
            repair_iterations += 1
            
            for partition_id in range(1, num_partitions + 1):
                partition_nodes = np.where(repaired_labels == partition_id)[0]

                if len(partition_nodes) <= 1:
                    continue

                # æå–å­å›¾
                subgraph = G.subgraph(partition_nodes)

                # æ£€æŸ¥è¿é€šæ€§
                if not nx.is_connected(subgraph):
                    # print(f"âš ï¸ åˆ†åŒº {partition_id} ä¸è¿é€šï¼Œæ­£åœ¨ä¿®å¤... (ç¬¬{repair_iterations}æ¬¡å°è¯•)")
                    needs_repair = True

                    # è·å–è¿é€šåˆ†é‡ï¼ŒæŒ‰å¤§å°æ’åº
                    components = sorted(list(nx.connected_components(subgraph)), key=len, reverse=True)
                    largest_component = components[0]

                    # å°†è¾ƒå°åˆ†é‡çš„èŠ‚ç‚¹é‡æ–°åˆ†é…
                    for component in components[1:]:
                        for node in component:
                            # æ‰¾åˆ°è¯¥èŠ‚ç‚¹çš„é‚»å±…åˆ†åŒºç»Ÿè®¡
                            neighbor_partitions_count = {}
                            for neighbor in self.adjacency_list[node]:
                                if neighbor < len(repaired_labels):
                                    neighbor_partition = repaired_labels[neighbor]
                                    if neighbor_partition != 0:  # å¿½ç•¥æœªåˆ†åŒºçš„é‚»å±…
                                        neighbor_partitions_count[neighbor_partition] = neighbor_partitions_count.get(neighbor_partition, 0) + 1

                            if neighbor_partitions_count:
                                # é€‰æ‹©è¿æ¥æœ€å¤šçš„é‚»å±…åˆ†åŒº
                                best_partition = max(neighbor_partitions_count, key=neighbor_partitions_count.get)
                                repaired_labels[node] = best_partition
                            else:
                                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆé‚»å±…ï¼Œä¿æŒåœ¨ä¸»åˆ†é‡ä¸­
                                pass

        if repair_iterations >= max_repair_iterations:
            warnings.warn(f"è¿é€šæ€§ä¿®å¤è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°({max_repair_iterations})ï¼Œå¯èƒ½ä»æœ‰ä¸è¿é€šçš„åˆ†åŒº")
        # else:
            # print("âœ… åˆ†åŒºè¿é€šæ€§ä¿®å¤å®Œæˆ")
            
        return torch.from_numpy(repaired_labels).to(self.device)

    def _create_action_space_on_boundaries(self, partition_labels: torch.Tensor) -> torch.Tensor:
        """
        ã€æ–°å¢ã€‘è¯†åˆ«åˆ†åŒºè¾¹ç•Œï¼Œå¹¶å°†è¾¹ç•ŒèŠ‚ç‚¹ç½®ä¸º"æœªåˆ†åŒº"(0)ï¼Œä¸ºRL Agentåˆ›é€ åŠ¨ä½œç©ºé—´ã€‚
        """
        # print("ğŸ” è¯†åˆ«è¾¹ç•ŒèŠ‚ç‚¹å¹¶åˆ›é€ åˆå§‹åŠ¨ä½œç©ºé—´...")
        labels_np = partition_labels.cpu().numpy()
        boundary_nodes = set()

        # éå†æ‰€æœ‰è¾¹æ¥æ‰¾åˆ°è¾¹ç•ŒèŠ‚ç‚¹
        for i in range(self.total_nodes):
            for neighbor in self.adjacency_list[i]:
                if labels_np[i] != labels_np[neighbor]:
                    boundary_nodes.add(i)
                    # åªè¦å‘ç°ä¸€ä¸ªé‚»å±…åœ¨ä¸åŒåŒºï¼Œå°±æ˜¯è¾¹ç•ŒèŠ‚ç‚¹ï¼Œå¯ä»¥è·³å‡ºå†…å±‚å¾ªç¯
                    break

        if not boundary_nodes:
            # å¦‚æœæ²¡æœ‰è¾¹ç•Œï¼ˆä¾‹å¦‚ï¼Œå›¾æœ¬èº«å°±æ˜¯éè¿é€šçš„ï¼‰ï¼Œéšæœºé€‰æ‹©ä¸€äº›èŠ‚ç‚¹
            warnings.warn("æœªå‘ç°è¾¹ç•ŒèŠ‚ç‚¹ï¼Œéšæœºé€‰æ‹©5%çš„èŠ‚ç‚¹ä½œä¸ºå¯ç§»åŠ¨èŠ‚ç‚¹ã€‚")
            num_to_unassign = max(1, int(self.total_nodes * 0.05))
            nodes_to_unassign = random.sample(range(self.total_nodes), num_to_unassign)
        else:
            nodes_to_unassign = list(boundary_nodes)

        # å°†è¿™äº›è¾¹ç•ŒèŠ‚ç‚¹çš„åˆ†åŒºæ ‡ç­¾è®¾ç½®ä¸º0
        final_labels_np = labels_np.copy()
        final_labels_np[nodes_to_unassign] = 0

        # print(f"âœ… æˆåŠŸå°† {len(nodes_to_unassign)} ä¸ªè¾¹ç•ŒèŠ‚ç‚¹ç½®ä¸º'æœªåˆ†åŒº'çŠ¶æ€ã€‚")

        return torch.from_numpy(final_labels_np).to(self.device)


class PartitionEvaluator:
    """
    ç»¼åˆåˆ†åŒºè´¨é‡è¯„ä¼°
    
    æä¾›è¯„ä¼°åˆ†åŒºè´¨é‡çš„å„ç§æŒ‡æ ‡ï¼ŒåŒ…æ‹¬
    ç”µæ°”ã€æ‹“æ‰‘å’Œè´Ÿè½½å¹³è¡¡æŒ‡æ ‡ã€‚
    """
    
    def __init__(self, hetero_data: HeteroData, device: torch.device):
        """
        åˆå§‹åŒ–åˆ†åŒºè¯„ä¼°å™¨

        Args:
            hetero_data: å¼‚æ„å›¾æ•°æ®
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.hetero_data = hetero_data.to(device)

        # åˆå§‹åŒ–æ™ºèƒ½å¯¼çº³æå–å™¨
        self.admittance_extractor = IntelligentAdmittanceExtractor(device)

        # è®¾ç½®è¯„ä¼°æ•°æ®
        self._setup_evaluation_data()
        
    def _setup_evaluation_data(self):
        """è®¾ç½®è¯„ä¼°æ‰€éœ€çš„æ•°æ®"""
        # è®¾ç½®èŠ‚ç‚¹æ˜ å°„
        self._setup_node_mappings()
        
        # æå–åŠŸç‡æ•°æ®
        self._extract_power_data()
        
        # æå–ç”µæ°”æ•°æ®
        self._extract_electrical_data()
        
    def _setup_node_mappings(self):
        """è®¾ç½®èŠ‚ç‚¹ç±»å‹æ˜ å°„"""
        self.node_types = list(self.hetero_data.x_dict.keys())
        self.local_to_global_map = {}
        
        global_idx = 0
        for node_type in self.node_types:
            num_nodes = self.hetero_data.x_dict[node_type].shape[0]
            global_indices = torch.arange(global_idx, global_idx + num_nodes, device=self.device)
            self.local_to_global_map[node_type] = global_indices
            global_idx += num_nodes
            
        self.total_nodes = global_idx
        
    def _local_to_global(self, local_indices: torch.Tensor, node_type: str) -> torch.Tensor:
        """å°†å±€éƒ¨ç´¢å¼•è½¬æ¢ä¸ºå…¨å±€ç´¢å¼•"""
        return self.local_to_global_map[node_type][local_indices]
        
    def _extract_power_data(self):
        """ä»èŠ‚ç‚¹ç‰¹å¾ä¸­æå–åŠŸç‡æ•°æ®"""
        all_features = []
        for node_type in self.node_types:
            features = self.hetero_data.x_dict[node_type]
            all_features.append(features)
            
        self.all_node_features = torch.cat(all_features, dim=0)
        
        # æå–åŠŸç‡æ•°æ®
        self.load_active = self.all_node_features[:, 0]  # Pd
        if self.all_node_features.shape[1] > 9:
            self.gen_active = self.all_node_features[:, 9]  # Pg
        else:
            self.gen_active = torch.zeros_like(self.load_active)
            
    def _extract_electrical_data(self):
        """ä»è¾¹ä¸­æå–ç”µæ°”æ•°æ®ï¼Œä½¿ç”¨æ™ºèƒ½å¯¼çº³æå–å™¨"""
        self.all_edges = []
        self.all_admittances = []
        self.admittance_sources = []  # è®°å½•å¯¼çº³æ•°æ®æ¥æº

        for edge_type, edge_index in self.hetero_data.edge_index_dict.items():
            edge_attr = self.hetero_data.edge_attr_dict[edge_type]
            src_type, _, dst_type = edge_type

            # è½¬æ¢ä¸ºå…¨å±€ç´¢å¼•
            src_global = self._local_to_global(edge_index[0], src_type)
            dst_global = self._local_to_global(edge_index[1], dst_type)

            global_edges = torch.stack([src_global, dst_global], dim=0)
            self.all_edges.append(global_edges)

            # ä½¿ç”¨æ™ºèƒ½å¯¼çº³æå–å™¨
            admittances, source = self.admittance_extractor.extract_admittance(
                edge_attr, global_edges
            )

            self.all_admittances.append(admittances)
            self.admittance_sources.append(source)

            # è®°å½•å¯¼çº³æ•°æ®æ¥æºï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if source != 'extracted':
                print(f"âš ï¸ è¾¹ç±»å‹ {edge_type} çš„å¯¼çº³æ•°æ®æ¥æº: {source}")

        if self.all_edges:
            self.edge_index = torch.cat(self.all_edges, dim=1)
            self.edge_admittances = torch.cat(self.all_admittances, dim=0)
        else:
            self.edge_index = torch.empty(2, 0, device=self.device)
            self.edge_admittances = torch.empty(0, device=self.device)
            
    def evaluate_partition(self, partition: torch.Tensor) -> Dict[str, float]:
        """
        ç»¼åˆåˆ†åŒºè¯„ä¼°
        
        Args:
            partition: åˆ†åŒºåˆ†é… [total_nodes]
            
        Returns:
            åŒ…å«è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
        """
        metrics = {}
        
        # åŸºæœ¬åˆ†åŒºä¿¡æ¯
        num_partitions = partition.max().item()
        partition_sizes = torch.bincount(partition, minlength=num_partitions + 1)[1:]
        
        # è´Ÿè½½å¹³è¡¡æŒ‡æ ‡
        partition_loads = torch.zeros(num_partitions, device=self.device)
        for i in range(1, num_partitions + 1):
            mask = (partition == i)
            if mask.any():
                partition_loads[i-1] = self.load_active[mask].sum()
                
        load_mean = torch.mean(partition_loads)
        load_std = torch.std(partition_loads)
        load_cv = (load_std / load_mean).item() if load_mean > 0 else 0.0
        
        # è€¦åˆæŒ‡æ ‡
        if self.edge_index.shape[1] > 0:
            src_partitions = partition[self.edge_index[0]]
            dst_partitions = partition[self.edge_index[1]]
            coupling_mask = (src_partitions != dst_partitions)
            
            coupling_edges = coupling_mask.sum().item()
            total_coupling = self.edge_admittances[coupling_mask].sum().item() if coupling_mask.any() else 0.0
        else:
            coupling_edges = 0
            total_coupling = 0.0
            
        # åŠŸç‡å¹³è¡¡æŒ‡æ ‡
        power_imbalances = []
        for i in range(1, num_partitions + 1):
            mask = (partition == i)
            if mask.any():
                gen = self.gen_active[mask].sum()
                load = self.load_active[mask].sum()
                imbalance = abs(gen - load).item()
                power_imbalances.append(imbalance)
                
        # è¿é€šæ€§æ£€æŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰
        connectivity = self._check_connectivity(partition)
        
        try:
            partition_sizes_list = partition_sizes.cpu().numpy().tolist()
        except RuntimeError:
            partition_sizes_list = partition_sizes.cpu().tolist()

        metrics.update({
            'num_partitions': num_partitions,
            'partition_sizes': partition_sizes_list,
            'load_cv': load_cv,
            'load_variance': torch.var(partition_loads).item(),
            'coupling_edges': coupling_edges,
            'total_coupling': total_coupling,
            'power_imbalance_mean': np.mean(power_imbalances) if power_imbalances else 0.0,
            'power_imbalance_max': np.max(power_imbalances) if power_imbalances else 0.0,
            'connectivity': connectivity
        })
        
        return metrics
        
    def _check_connectivity(self, partition: torch.Tensor) -> float:
        """
        æ£€æŸ¥åˆ†åŒºè¿é€šæ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            partition: åˆ†åŒºåˆ†é…
            
        Returns:
            è¿é€šæ€§å¾—åˆ†ï¼ˆå¦‚æœæ‰€æœ‰åˆ†åŒºè¿é€šä¸º1.0ï¼Œå¦åˆ™æ›´ä½ï¼‰
        """
        # ç›®å‰è¿”å›1.0ï¼ˆå‡è®¾è¿é€šï¼‰
        # å®Œæ•´å®ç°å°†æ£€æŸ¥æ¯ä¸ªåˆ†åŒºå†…çš„å›¾è¿é€šæ€§
        return 1.0
