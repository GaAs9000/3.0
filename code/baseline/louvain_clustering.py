import numpy as np
import networkx as nx
from typing import TYPE_CHECKING
from .baseline import BasePartitioner, set_baseline_seed

if TYPE_CHECKING:
    from ..src.rl.environment import PowerGridPartitioningEnv

try:
    import community as community_louvain
    LOUVAIN_AVAILABLE = True
except ImportError:
    LOUVAIN_AVAILABLE = False


class LouvainPartitioner(BasePartitioner):
    """
    Louvainç¤¾åŒºå‘ç°åˆ†åŒºæ–¹æ³•
    
    åŸºäºæ¨¡å—åº¦ä¼˜åŒ–çš„ç¤¾åŒºå‘ç°ç®—æ³•ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–æ¨¡å—åº¦å‡½æ•°æ¥å‘ç°ç½‘ç»œä¸­çš„ç¤¾åŒºç»“æ„ã€‚
    é€‚ç”¨äºå¤§è§„æ¨¡ç½‘ç»œçš„å¿«é€Ÿç¤¾åŒºå‘ç°ã€‚
    """
    
    def __init__(self, seed: int = 42, resolution: float = 1.0):
        """
        åˆå§‹åŒ–Louvainåˆ†åŒºå™¨
        
        Args:
            seed: éšæœºç§å­ï¼Œç”¨äºä¿è¯ç»“æœå¯é‡å¤æ€§
            resolution: åˆ†è¾¨ç‡å‚æ•°ï¼Œæ§åˆ¶ç¤¾åŒºçš„å¤§å°ã€‚å€¼è¶Šå¤§ï¼Œç¤¾åŒºè¶Šå°
        """
        super().__init__(seed)
        self.resolution = resolution
        
        if not LOUVAIN_AVAILABLE:
            raise ImportError("python-louvainåº“æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install python-louvain")
    
    def partition(self, env: 'PowerGridPartitioningEnv') -> np.ndarray:
        """æ‰§è¡ŒLouvainç¤¾åŒºå‘ç°åˆ†åŒº"""
        # è®¾ç½®éšæœºç§å­
        self._set_seed()
        
        try:
            # æ„å»ºNetworkXå›¾
            G = self._build_networkx_graph(env)
            
            # å¦‚æœç½‘ç»œå¤ªå°ï¼Œä½¿ç”¨ç®€å•çš„åˆ†åŒºæ–¹æ³•
            if G.number_of_nodes() <= env.num_partitions:
                return self._simple_partition(G, env.num_partitions)
            
            # è¿è¡ŒLouvainç®—æ³•
            # ä¸ºäº†ä¿è¯å®éªŒå¯é‡å¤æ€§ï¼Œç»Ÿä¸€ä½¿ç”¨random_state=seed
            partition = community_louvain.best_partition(
                G, 
                resolution=self.resolution, 
                random_state=self.seed
            )
            
            # è½¬æ¢åˆ†åŒºç»“æœ
            labels = self._convert_partition_to_labels(partition, env)
            
            return labels
            
        except Exception as e:
            print(f"âŒ Louvainåˆ†åŒºå¤±è´¥: {str(e)}")
            # é™çº§åˆ°ç®€å•çš„åˆ†åŒºæ–¹æ³•
            return self._fallback_partition(env)
    
    def _build_networkx_graph(self, env: 'PowerGridPartitioningEnv') -> nx.Graph:
        """æ„å»ºNetworkXå›¾ï¼Œä½¿ç”¨å¯¼çº³ä½œä¸ºè¾¹æƒé‡"""
        G = nx.Graph()
        
        # è·å–è¾¹ä¿¡æ¯
        edge_array = env.edge_info['edge_index'].cpu().numpy()
        total_nodes = env.total_nodes
        
        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        G.add_nodes_from(range(total_nodes))
        
        # æ·»åŠ è¾¹å’Œæƒé‡
        for i in range(edge_array.shape[1]):
            u, v = edge_array[0, i], edge_array[1, i]
            
            # è·å–è¾¹æƒé‡ï¼ˆå¯¼çº³ç»å¯¹å€¼ï¼‰
            if hasattr(env.evaluator, 'edge_admittances') and i < len(env.evaluator.edge_admittances):
                weight = float(env.evaluator.edge_admittances[i].item())
            else:
                # ä½¿ç”¨ä¼°ç®—çš„æƒé‡
                weight = self._estimate_edge_weight(u, v, total_nodes)
            
            # å¤„ç†å¼‚å¸¸æƒé‡
            if np.isnan(weight) or np.isinf(weight) or weight <= 0:
                weight = 1.0
            
            G.add_edge(u, v, weight=weight)
        
        return G
    
    def _estimate_edge_weight(self, u: int, v: int, total_nodes: int) -> float:
        """ä¼°ç®—è¾¹æƒé‡ï¼ˆä¸è°±èšç±»ä¸­ç›¸åŒçš„ç­–ç•¥ï¼‰"""
        # åŸºäºç½‘ç»œè§„æ¨¡çš„åŸºç¡€æƒé‡
        if total_nodes <= 30:
            base_weight = 3.0
        elif total_nodes <= 100:
            base_weight = 2.0
        else:
            base_weight = 1.5
        
        # åŸºäºèŠ‚ç‚¹ç´¢å¼•çš„è°ƒæ•´
        index_diff = abs(u - v)
        if index_diff == 1:
            weight_factor = 1.2
        elif index_diff <= 5:
            weight_factor = 1.1
        else:
            weight_factor = 1.0
        
        return base_weight * weight_factor
    
    def _convert_partition_to_labels(self, partition: dict, env: 'PowerGridPartitioningEnv') -> np.ndarray:
        """
        å°†Louvainåˆ†åŒºç»“æœè½¬æ¢ä¸ºæ ‡ç­¾æ•°ç»„
        
        Args:
            partition: Louvainç®—æ³•è¿”å›çš„åˆ†åŒºå­—å…¸ {node_id: community_id}
            env: ç¯å¢ƒå¯¹è±¡
            
        Returns:
            æ ‡ç­¾æ•°ç»„ï¼Œä»1å¼€å§‹ç¼–å·
        """
        # è·å–åŸå§‹ç¤¾åŒºæ ‡ç­¾
        original_labels = np.array([partition[i] for i in range(env.total_nodes)])
        
        # è·å–å”¯ä¸€çš„ç¤¾åŒºID
        unique_communities = np.unique(original_labels)
        num_communities = len(unique_communities)
        
        # å¦‚æœç¤¾åŒºæ•°é‡ç­‰äºç›®æ ‡åˆ†åŒºæ•°ï¼Œç›´æ¥è¿”å›
        if num_communities == env.num_partitions:
            # é‡æ–°æ˜ å°„åˆ°1å¼€å§‹çš„è¿ç»­æ ‡ç­¾
            label_mapping = {old_id: new_id + 1 for new_id, old_id in enumerate(unique_communities)}
            return np.array([label_mapping[label] for label in original_labels])
        
        # å¦‚æœç¤¾åŒºæ•°é‡å°äºç›®æ ‡åˆ†åŒºæ•°ï¼Œä½¿ç”¨ç»†åˆ†ç­–ç•¥
        elif num_communities < env.num_partitions:
            return self._subdivide_communities(original_labels, unique_communities, env)
        
        # å¦‚æœç¤¾åŒºæ•°é‡å¤§äºç›®æ ‡åˆ†åŒºæ•°ï¼Œä½¿ç”¨åˆå¹¶ç­–ç•¥
        else:
            return self._merge_communities(original_labels, unique_communities, env)
    
    def _subdivide_communities(self, labels: np.ndarray, communities: np.ndarray, env: 'PowerGridPartitioningEnv') -> np.ndarray:
        """ç»†åˆ†ç¤¾åŒºä»¥è¾¾åˆ°ç›®æ ‡åˆ†åŒºæ•°"""
        print(f"ğŸ”„ Louvainå‘ç°{len(communities)}ä¸ªç¤¾åŒºï¼Œç›®æ ‡{env.num_partitions}ä¸ªåˆ†åŒºï¼Œæ‰§è¡Œç»†åˆ†...")
        
        # æ‰¾åˆ°æœ€å¤§çš„ç¤¾åŒºè¿›è¡Œç»†åˆ†
        current_labels = labels.copy()
        current_num_partitions = len(communities)
        
        # é‡æ–°æ˜ å°„åˆ°1å¼€å§‹çš„è¿ç»­æ ‡ç­¾
        label_mapping = {old_id: new_id + 1 for new_id, old_id in enumerate(communities)}
        current_labels = np.array([label_mapping[label] for label in current_labels])
        
        # éœ€è¦é¢å¤–çš„åˆ†åŒºæ•°
        additional_partitions = env.num_partitions - current_num_partitions
        
        for _ in range(additional_partitions):
            # æ‰¾åˆ°æœ€å¤§çš„ç¤¾åŒº
            unique_labels, counts = np.unique(current_labels, return_counts=True)
            largest_community_idx = np.argmax(counts)
            largest_community = unique_labels[largest_community_idx]
            
            # å¦‚æœæœ€å¤§ç¤¾åŒºåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œåœæ­¢ç»†åˆ†
            if counts[largest_community_idx] <= 1:
                break
            
            # åˆ†å‰²æœ€å¤§ç¤¾åŒº
            largest_community_nodes = np.where(current_labels == largest_community)[0]
            split_point = len(largest_community_nodes) // 2
            
            # åˆ›å»ºæ–°çš„æ ‡ç­¾
            new_label = current_labels.max() + 1
            current_labels[largest_community_nodes[split_point:]] = new_label
        
        return current_labels
    
    def _merge_communities(self, labels: np.ndarray, communities: np.ndarray, env: 'PowerGridPartitioningEnv') -> np.ndarray:
        """åˆå¹¶ç¤¾åŒºä»¥è¾¾åˆ°ç›®æ ‡åˆ†åŒºæ•°"""
        print(f"ğŸ”„ Louvainå‘ç°{len(communities)}ä¸ªç¤¾åŒºï¼Œç›®æ ‡{env.num_partitions}ä¸ªåˆ†åŒºï¼Œæ‰§è¡Œåˆå¹¶...")
        
        # è®¡ç®—æ¯ä¸ªç¤¾åŒºçš„å¤§å°
        community_sizes = []
        for community in communities:
            size = np.sum(labels == community)
            community_sizes.append((community, size))
        
        # æŒ‰å¤§å°æ’åºï¼Œä¿ç•™æœ€å¤§çš„å‡ ä¸ªç¤¾åŒº
        community_sizes.sort(key=lambda x: x[1], reverse=True)
        
        # ä¿ç•™å‰num_partitionsä¸ªæœ€å¤§ç¤¾åŒº
        kept_communities = [comm[0] for comm in community_sizes[:env.num_partitions]]
        
        # å°†å‰©ä½™çš„å°ç¤¾åŒºåˆå¹¶åˆ°æœ€è¿‘çš„å¤§ç¤¾åŒº
        merged_labels = labels.copy()
        
        for community in communities:
            if community not in kept_communities:
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„ä¿ç•™ç¤¾åŒºï¼ˆè¿™é‡Œç®€åŒ–ä¸ºæœ€å°çš„ä¿ç•™ç¤¾åŒºï¼‰
                target_community = kept_communities[-1]  # æœ€å°çš„ä¿ç•™ç¤¾åŒº
                merged_labels[labels == community] = target_community
        
        # é‡æ–°æ˜ å°„åˆ°1å¼€å§‹çš„è¿ç»­æ ‡ç­¾
        unique_labels = np.unique(merged_labels)
        label_mapping = {old_id: new_id + 1 for new_id, old_id in enumerate(unique_labels)}
        final_labels = np.array([label_mapping[label] for label in merged_labels])
        
        return final_labels
    
    def _simple_partition(self, G: nx.Graph, num_partitions: int) -> np.ndarray:
        """ç®€å•çš„åˆ†åŒºæ–¹æ³•ï¼Œç”¨äºå°ç½‘ç»œ"""
        nodes = list(G.nodes())
        labels = np.zeros(len(nodes), dtype=int)
        
        # ç®€å•çš„è½®è¯¢åˆ†é…
        for i, node in enumerate(nodes):
            labels[node] = (i % num_partitions) + 1
        
        return labels
    
    def _fallback_partition(self, env: 'PowerGridPartitioningEnv') -> np.ndarray:
        """é™çº§åˆ†åŒºæ–¹æ³•"""
        print("âš ï¸ ä½¿ç”¨é™çº§åˆ†åŒºæ–¹æ³•...")
        
        # ç®€å•çš„è½®è¯¢åˆ†é…
        labels = np.zeros(env.total_nodes, dtype=int)
        for i in range(env.total_nodes):
            labels[i] = (i % env.num_partitions) + 1
        
        return labels
    
    def get_modularity(self, env: 'PowerGridPartitioningEnv', labels: np.ndarray) -> float:
        """è®¡ç®—åˆ†åŒºçš„æ¨¡å—åº¦"""
        try:
            G = self._build_networkx_graph(env)
            
            # å°†æ ‡ç­¾è½¬æ¢ä¸ºç¤¾åŒºå­—å…¸
            partition = {i: labels[i] for i in range(len(labels))}
            
            # è®¡ç®—æ¨¡å—åº¦
            modularity = community_louvain.modularity(partition, G)
            
            return modularity
            
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ¨¡å—åº¦å¤±è´¥: {e}")
            return 0.0