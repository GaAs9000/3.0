import numpy as np
import pandas as pd
import torch
from torch_geometric.data import HeteroData
from typing import Dict, Tuple, List, Optional
from sklearn.preprocessing import StandardScaler, RobustScaler
import hashlib
import pickle
import os
from pathlib import Path

class PowerGridDataProcessor:
    """
    ç”µç½‘æ•°æ®å¤„ç†
    
    1. å…¨é¢å‡çº§ä»¥æ”¯æŒ PyTorch Geometric çš„ HeteroData æ ¼å¼
    2. ä¸ºèŠ‚ç‚¹ï¼ˆæ¯çº¿ï¼‰å’Œè¾¹ï¼ˆæ”¯è·¯ï¼‰å®šä¹‰äº†ç‰©ç†ç±»å‹
    3. é‡æ„äº†æ•°æ®åˆ›å»ºæµç¨‹ï¼Œä»¥åæ˜ ç”µç½‘çš„å¼‚æ„æ€§
    4. æ”¯æŒå“ˆå¸Œç¼“å­˜æœºåˆ¶
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. MATPOWERæ ¼å¼æ•°æ®æ¸…æ´—å’Œç‰¹å¾æå–
    2. æ„å»ºPyTorch Geometricå¼‚æ„å›¾æ•°æ®
    3. åŒºåˆ†ä¸åŒç±»å‹çš„ç”µåŠ›è®¾å¤‡å’Œè¿æ¥
    """
    
    def __init__(self, normalize: bool = True, cache_dir: str = 'cache'):
        self.normalize = normalize
        self.node_scaler = None
        self.edge_scaler = None
        self.cache_dir = cache_dir
        Path(cache_dir).mkdir(exist_ok=True, parents=True)
        
        # å®šä¹‰ç±»å‹æ˜ å°„å…³ç³»ï¼Œç”¨äºå°†MATPOWERä¸­çš„æ•°å­—ä»£ç è½¬æ¢ä¸ºæœ‰æ„ä¹‰çš„å­—ç¬¦ä¸²
        self.BUS_TYPE_MAP = {1: 'pq', 2: 'pv', 3: 'slack'}
        self.BRANCH_TYPE_MAP = {0: 'line', 1: 'transformer'}

    def graph_from_mpc(self, mpc: Dict) -> HeteroData:
        """
        å°†MATPOWERæ ¼å¼æ•°æ®è½¬æ¢ä¸ºPyTorch Geometricçš„å¼‚æ„å›¾æ•°æ® (HeteroData)
        
        å‚æ•°:
            mpc: MATPOWERæ ¼å¼çš„ç”µç½‘æ•°æ®å­—å…¸
            
        è¿”å›:
            data: PyTorch Geometric HeteroDataå¯¹è±¡
        """
        # 1. è®¡ç®—æ•°æ®å“ˆå¸Œç”¨äºç¼“å­˜ (æ–‡ä»¶åä¸­åŠ å…¥åç¼€ä»¥åŒºåˆ†æ–°æ—§ç‰ˆæœ¬)
        raw_bytes = pickle.dumps((mpc["bus"].tolist(), mpc["branch"].tolist()))
        case_hash = hashlib.md5(raw_bytes).hexdigest()[:8]
        cache_file = f"{self.cache_dir}/{case_hash}_hetero.pt"
        
        # 2. å°è¯•ä»ç¼“å­˜åŠ è½½
        if os.path.exists(cache_file):
            print(f"ğŸ“‚ ä»ç¼“å­˜åŠ è½½å¼‚æ„å›¾: {cache_file}")
            return torch.load(cache_file, map_location="cpu", weights_only=False)
        
        # 3. é¦–æ¬¡æ„å»ºå¼‚æ„å›¾æ•°æ®
        print(f"ğŸ”¨ é¦–æ¬¡æ„å»ºå¼‚æ„å›¾æ•°æ®...")
        baseMVA, df_nodes, df_edges, df_edge_features = self.process_matpower_data(mpc)
        data = self.create_pyg_hetero_data(df_nodes, df_edges, df_edge_features)
        
        # 4. ä¿å­˜åˆ°ç¼“å­˜
        torch.save(data, cache_file, pickle_protocol=pickle.DEFAULT_PROTOCOL)
        print(f"ğŸ’¾ å·²ç¼“å­˜å¼‚æ„å›¾åˆ°: {cache_file}")
        
        return data   
    
    def process_matpower_data(self, mpc: Dict) -> Tuple[float, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """
        å¤„ç†MATPOWERæ ¼å¼æ•°æ®ï¼Œä¸ºæ„å»ºå¼‚æ„å›¾å‡†å¤‡åŒ…å«ç±»å‹ä¿¡æ¯çš„DataFrame
        
        å‚æ•°:
            mpc: MATPOWERæ ¼å¼çš„ç”µç½‘æ•°æ®å­—å…¸
            
        è¿”å›:
            baseMVA: åŸºå‡†åŠŸç‡(MVA)
            df_nodes: åŒ…å«ç±»å‹ä¿¡æ¯çš„èŠ‚ç‚¹ç‰¹å¾DataFrame
            df_edges: è¾¹ç´¢å¼•DataFrame
            df_edge_features: åŒ…å«ç±»å‹ä¿¡æ¯çš„è¾¹ç‰¹å¾DataFrame
        """
        # 1. æå–åŸºå‡†åŠŸç‡å’ŒåŸºç¡€æ•°æ®
        baseMVA = float(mpc['baseMVA'])
        bus = np.asarray(mpc['bus']).copy()
        branch = np.asarray(mpc['branch']).copy()
        
        # 2. ä¿®å¤æ”¯è·¯è½½æµé™åˆ¶çš„ç¼ºå¤±å€¼
        for col in [5, 6, 7]:  # rateA, rateB, rateC
            mask = branch[:, col] == 0
            branch[mask, col] = baseMVA
        
        # 3. æå–åŸºç¡€ç‰¹å¾
        node_features = self._extract_node_features(bus, branch, baseMVA)
        edge_features, edge_index = self._extract_edge_features(branch, baseMVA)
        
        # 4. æ·»åŠ å‘ç”µæœºç‰¹å¾
        if 'gen' in mpc:
            gen_features = self._extract_generator_features(mpc['gen'], bus, baseMVA)
            node_features = np.hstack([node_features, gen_features])
        
        # 5. æ ‡å‡†åŒ–ç‰¹å¾ (åœ¨åˆ†å‰²æ•°æ®ç±»å‹å‰è¿›è¡Œï¼Œç¡®ä¿å°ºåº¦ä¸€è‡´)
        if self.normalize:
            node_features = self._normalize_features(node_features, 'node')
            edge_features = self._normalize_features(edge_features, 'edge')
            
        # 6. åˆ›å»ºåŒ…å«ç±»å‹ä¿¡æ¯çš„DataFrame
        # å®šä¹‰èŠ‚ç‚¹ç‰¹å¾åˆ—å (ç§»é™¤äº†æ—§çš„one-hotç±»å‹åˆ—)
        node_columns = ['Pd', 'Qd', 'Gs', 'Bs', 'Vm', 'Va', 'Vmax', 'Vmin', 'degree']
        if 'gen' in mpc:
            node_columns.extend(['Pg', 'Qg', 'Pg_max', 'Pg_min', 'is_gen'])
            
        # ä½¿ç”¨0-basedçš„æ¯çº¿ç´¢å¼•ä½œä¸ºDataFrameçš„ç´¢å¼•
        df_nodes = pd.DataFrame(node_features, columns=node_columns, index=bus[:,0].astype(int)-1)
        
        # æ·»åŠ èŠ‚ç‚¹ç±»å‹åˆ—
        bus_types_raw = bus[:, 1].astype(int)
        df_nodes['type'] = [self.BUS_TYPE_MAP.get(bt, 'pq') for bt in bus_types_raw] # é»˜è®¤ä¸ºpqç±»å‹

        # å®šä¹‰è¾¹ç‰¹å¾åˆ—å
        df_edge_features = pd.DataFrame(
            edge_features,
            columns=['r', 'x', 'b', '|z|', 'y', 'rateA', 'angle_diff', 'is_transformer', 'status']
        )
        # æ·»åŠ è¾¹ç±»å‹åˆ—
        is_transformer_int = df_edge_features['is_transformer'].astype(int)
        df_edge_features['type'] = [self.BRANCH_TYPE_MAP.get(bt, 'line') for bt in is_transformer_int]
        
        # åˆ›å»ºè¾¹ç´¢å¼•DataFrame
        df_edges = pd.DataFrame(edge_index, columns=['from_bus', 'to_bus'])
        
        return baseMVA, df_nodes, df_edges, df_edge_features

    def _extract_node_features(self, bus: np.ndarray, branch: np.ndarray, baseMVA: float) -> np.ndarray:
        """
        æå–èŠ‚ç‚¹ç‰¹å¾ (V2.0: ä¸å†è¿›è¡Œone-hotç¼–ç ï¼Œåªæå–æ•°å€¼ç‰¹å¾)
        
        å‚æ•°:
            bus: æ¯çº¿æ•°æ®çŸ©é˜µ
            branch: æ”¯è·¯æ•°æ®çŸ©é˜µ  
            baseMVA: åŸºå‡†åŠŸç‡
            
        è¿”å›:
            features: èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ [n_bus, n_features]
            
        ç‰¹å¾åŒ…æ‹¬:
            - æœ‰åŠŸ/æ— åŠŸè´Ÿè· (å½“å‰å€¼ï¼Œç”¨äºRLçŠ¶æ€è¡¨å¾)
            - å¹¶è”ç”µå¯¼/ç”µçº³
            - ç”µå‹è¿è¡ŒçŠ¶æ€å’Œçº¦æŸ
            - èŠ‚ç‚¹åº¦æ•°
            æ³¨ï¼šèŠ‚ç‚¹ç±»å‹å°†åœ¨åç»­é˜¶æ®µé€šè¿‡DataFrameçš„'type'åˆ—å•ç‹¬å¤„ç†
        """
        n_bus = bus.shape[0]
        
        # 1. è¿è¡ŒçŠ¶æ€ç‰¹å¾
        Pd_pu = bus[:, 2] / baseMVA
        Qd_pu = bus[:, 3] / baseMVA
        Gs = bus[:, 4]
        Bs = bus[:, 5]
        Vm = bus[:, 7]
        Va = np.deg2rad(bus[:, 8])
        
        # 2. ç”µå‹çº¦æŸ
        Vmax = bus[:, 11] if bus.shape[1] > 11 else np.ones(n_bus) * 1.1
        Vmin = bus[:, 12] if bus.shape[1] > 12 else np.ones(n_bus) * 0.9
        
        # 3. æ‹“æ‰‘ç‰¹å¾ï¼šè®¡ç®—èŠ‚ç‚¹åº¦æ•°
        from_idx = branch[:, 0].astype(int) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
        to_idx = branch[:, 1].astype(int) - 1
        degree = np.bincount(np.hstack([from_idx, to_idx]), minlength=n_bus)
        
        # 4. ç»„åˆæ‰€æœ‰æ•°å€¼ç‰¹å¾ (ä¸å†åŒ…å«one-hotç¼–ç çš„ç±»å‹ä¿¡æ¯)
        features = np.column_stack([
            Pd_pu, Qd_pu, Gs, Bs, Vm, Va, Vmax, Vmin, degree
        ])
        
        return features
    
    def _extract_edge_features(self, branch: np.ndarray, baseMVA: float) -> Tuple[np.ndarray, np.ndarray]:
        """
        æå–è¾¹ç‰¹å¾ (é€»è¾‘åŸºæœ¬ä¸å˜)
        
        å‚æ•°:
            branch: æ”¯è·¯æ•°æ®çŸ©é˜µ
            baseMVA: åŸºå‡†åŠŸç‡
            
        è¿”å›:
            features: è¾¹ç‰¹å¾çŸ©é˜µ [n_branch, n_features]
            edge_index: è¾¹ç´¢å¼•çŸ©é˜µ [n_branch, 2]
            
        ç‰¹å¾åŒ…æ‹¬:
            - ç”µé˜»ã€ç”µæŠ—ã€ç”µçº³
            - é˜»æŠ—æ¨¡é•¿ã€å¯¼çº³
            - è½½æµé™åˆ¶
            - ç›¸è§’å·®é™åˆ¶  
            - æ˜¯å¦ä¸ºå˜å‹å™¨
            - æ”¯è·¯è¿è¡ŒçŠ¶æ€
        """
        # 1. ç”µæ°”å‚æ•°
        r_raw = branch[:, 2]
        x_raw = branch[:, 3]
        b = branch[:, 4]

        # 2. å¤„ç†NaNå€¼
        valid_mask = ~np.isnan(r_raw) & ~np.isnan(x_raw)
        r_filled = np.nan_to_num(r_raw, nan=0.0)
        x_filled = np.nan_to_num(x_raw, nan=0.0)
        
        # 3. è®¡ç®—é˜»æŠ—æ¨¡é•¿å’Œå¯¼çº³
        z_mag_calc = np.sqrt(r_filled**2 + x_filled**2)
        z_magnitude = np.where(valid_mask, z_mag_calc, np.inf)
        y = np.where(np.isinf(z_magnitude), 0.0, 1.0 / (z_magnitude + 1e-10))
        
        # 4. è½½æµé™åˆ¶å’Œç›¸è§’çº¦æŸ
        rateA = branch[:, 5] / baseMVA
        angle_min = branch[:, 11] if branch.shape[1] > 11 else -np.pi * np.ones(len(branch))
        angle_max = branch[:, 12] if branch.shape[1] > 12 else np.pi * np.ones(len(branch))
        angle_diff = angle_max - angle_min
        
        # 5. å˜å‹å™¨æ ‡è¯†å’Œè¿è¡ŒçŠ¶æ€
        tap_ratio = branch[:, 8]
        is_transformer = ((tap_ratio != 0) & (tap_ratio != 1)).astype(float)
        status = branch[:, 10].astype(float) if branch.shape[1] > 10 else np.ones(len(branch))
        
        # 6. è¾¹ç´¢å¼• (è½¬æ¢ä¸º0-based)
        edge_index = np.column_stack([
            branch[:, 0].astype(int) - 1,
            branch[:, 1].astype(int) - 1
        ])
        
        # 7. ç»„åˆæ‰€æœ‰ç‰¹å¾
        features = np.column_stack([
            r_filled, x_filled, b, z_magnitude, y, rateA, angle_diff, is_transformer, status
        ])
        
        # 8. æœ€ç»ˆNaNæ£€æŸ¥å’Œå¤„ç†
        if np.any(np.isnan(features)):
            print("âš ï¸ è­¦å‘Šï¼šæ¸…ç†ç‰¹å¾çŸ©é˜µä¸­çš„NaNå€¼...")
            features = np.nan_to_num(features, nan=0.0, posinf=1e6, neginf=-1e6)
        
        return features, edge_index

    def _extract_generator_features(self, gen: np.ndarray, bus: np.ndarray, baseMVA: float) -> np.ndarray:
        """
        æå–å‘ç”µæœºç‰¹å¾å¹¶æ˜ å°„åˆ°èŠ‚ç‚¹ (é€»è¾‘åŸºæœ¬ä¸å˜)
        
        å‚æ•°:
            gen: å‘ç”µæœºæ•°æ®çŸ©é˜µ
            bus: æ¯çº¿æ•°æ®çŸ©é˜µ
            baseMVA: åŸºå‡†åŠŸç‡
            
        è¿”å›:
            features: å‘ç”µæœºç‰¹å¾çŸ©é˜µ [n_bus, n_gen_features]
            
        ç‰¹å¾åŒ…æ‹¬:
            - å½“å‰æœ‰åŠŸ/æ— åŠŸå‡ºåŠ› (ç”¨äºçŠ¶æ€è¡¨å¾)
            - æœ‰åŠŸå‘ç”µå®¹é‡ä¸Šä¸‹é™ (ç”¨äºçº¦æŸ)
            - å‘ç”µæœºæ ‡è¯†
        """
        n_bus = bus.shape[0]
        
        # 1. åˆå§‹åŒ–å‘ç”µæœºç‰¹å¾
        Pg = np.zeros(n_bus)
        Qg = np.zeros(n_bus)
        Pg_max = np.zeros(n_bus)
        Pg_min = np.zeros(n_bus)
        is_gen = np.zeros(n_bus)
        
        # 2. èšåˆæ¯ä¸ªèŠ‚ç‚¹çš„å‘ç”µæœºç‰¹å¾
        if len(gen) > 0:
            idx = gen[:, 0].astype(int) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
            # å½“å‰å‡ºåŠ› (ç”¨äºçŠ¶æ€è¡¨å¾)
            np.add.at(Pg, idx, gen[:, 1] / baseMVA)      # å½“å‰æœ‰åŠŸå‡ºåŠ›
            np.add.at(Qg, idx, gen[:, 2] / baseMVA)      # å½“å‰æ— åŠŸå‡ºåŠ›
            # å®¹é‡çº¦æŸ (ç”¨äºå¯è¡ŒåŸŸçº¦æŸ)
            np.add.at(Pg_max, idx, gen[:, 8] / baseMVA)  # æœ‰åŠŸå®¹é‡ä¸Šé™
            np.add.at(Pg_min, idx, gen[:, 9] / baseMVA)  # æœ‰åŠŸå®¹é‡ä¸‹é™
            is_gen[idx] = 1.0
        
        return np.column_stack([Pg, Qg, Pg_max, Pg_min, is_gen])
    
    def _normalize_features(self, features: np.ndarray, feature_type: str) -> np.ndarray:
        """
        æ ‡å‡†åŒ–ç‰¹å¾ (é€»è¾‘åŸºæœ¬ä¸å˜)
        
        å‚æ•°:
            features: ç‰¹å¾çŸ©é˜µ
            feature_type: ç‰¹å¾ç±»å‹ ('node' æˆ– 'edge')
            
        è¿”å›:
            normalized_features: æ ‡å‡†åŒ–åçš„ç‰¹å¾çŸ©é˜µ
        """
        # å¤„ç†infå€¼
        if np.any(np.isinf(features)):
            features = np.nan_to_num(features, nan=0.0, posinf=1e6, neginf=-1e6)

        scaler_attr = f"{feature_type}_scaler"
        if getattr(self, scaler_attr) is None:
            scaler = RobustScaler()
            setattr(self, scaler_attr, scaler)
            return scaler.fit_transform(features)
        else:
            return getattr(self, scaler_attr).transform(features)
    
    def create_pyg_hetero_data(self, df_nodes: pd.DataFrame, df_edges: pd.DataFrame, 
                               df_edge_features: pd.DataFrame) -> HeteroData:
        """
        æ ¹æ®åŒ…å«ç±»å‹ä¿¡æ¯çš„DataFrameåˆ›å»ºPyTorch Geometricçš„HeteroDataå¯¹è±¡
        è¿™æ˜¯æœ¬æ¬¡å‡çº§çš„æ ¸å¿ƒåŠŸèƒ½
        
        å‚æ•°:
            df_nodes: åŒ…å«ç±»å‹ä¿¡æ¯çš„èŠ‚ç‚¹ç‰¹å¾DataFrame
            df_edges: è¾¹ç´¢å¼•DataFrame
            df_edge_features: åŒ…å«ç±»å‹ä¿¡æ¯çš„è¾¹ç‰¹å¾DataFrame
            
        è¿”å›:
            data: PyTorch Geometric HeteroDataå¯¹è±¡
            
        å…³é”®æ­¥éª¤:
            1. ä¸ºæ¯ç§èŠ‚ç‚¹ç±»å‹åˆ›å»ºç‹¬ç«‹çš„ç‰¹å¾å¼ é‡å’Œç´¢å¼•æ˜ å°„
            2. ä¸ºæ¯ç§è¾¹ç±»å‹åˆ›å»ºè¿æ¥å…³ç³»
            3. å¤„ç†å…¨å±€ç´¢å¼•åˆ°å±€éƒ¨ç´¢å¼•çš„è½¬æ¢
            4. åˆ›å»ºæ— å‘å›¾ç»“æ„
        """
        data = HeteroData()
        
        # --- 1. å¤„ç†èŠ‚ç‚¹ï¼šä¸ºæ¯ç§èŠ‚ç‚¹ç±»å‹åˆ›å»ºç‹¬ç«‹çš„æ•°æ®ç»“æ„ ---
        # è¿™æ˜¯æœ€å…³é”®çš„æ­¥éª¤ï¼šç»´æŠ¤å…¨å±€IDåˆ°å„ç±»å‹å±€éƒ¨IDçš„æ˜ å°„å…³ç³»
        global_to_local_maps = {}
        
        print(f"ğŸ” å‘ç°èŠ‚ç‚¹ç±»å‹: {df_nodes['type'].unique()}")
        
        for node_type, group in df_nodes.groupby('type'):
            # èŠ‚ç‚¹ç±»å‹é”®ï¼Œä¾‹å¦‚ 'bus_pq', 'bus_pv', 'bus_slack'
            node_type_key = f'bus_{node_type}'
            
            # è·å–è¯¥ç±»å‹èŠ‚ç‚¹çš„å…¨å±€IDåˆ—è¡¨ (0-basedç´¢å¼•)
            type_global_indices = group.index.tolist()
            
            # åˆ›å»ºå…¨å±€IDåˆ°è¯¥ç±»å‹å±€éƒ¨IDçš„æ˜ å°„
            global_to_local_maps[node_type_key] = {
                global_id: local_id for local_id, global_id in enumerate(type_global_indices)
            }
            
            # æå–ç‰¹å¾ (å»é™¤ç±»å‹åˆ—)
            feature_cols = [col for col in group.columns if col != 'type']
            data[node_type_key].x = torch.tensor(group[feature_cols].values, dtype=torch.float32)
            
            # å­˜å‚¨å…¨å±€IDï¼Œæ–¹ä¾¿æœªæ¥è¿½æº¯å’Œè°ƒè¯•
            data[node_type_key].global_ids = torch.tensor(type_global_indices, dtype=torch.long)
            
            print(f"  ğŸ“ {node_type_key}: {len(type_global_indices)} ä¸ªèŠ‚ç‚¹")

        # --- 2. å¤„ç†è¾¹ï¼šåˆ›å»ºå¼‚æ„å›¾çš„è¿æ¥å…³ç³» ---
        # åˆå¹¶è¾¹ä¿¡æ¯ï¼Œæ–¹ä¾¿å¤„ç†
        full_edge_df = pd.concat([df_edges, df_edge_features], axis=1)
        
        print(f"ğŸ”— å‘ç°è¾¹ç±»å‹: {df_edge_features['type'].unique()}")
        
        # ç”¨äºç»Ÿè®¡å…³ç³»ç±»å‹
        relation_stats = {}
        
        for _, row in full_edge_df.iterrows():
            src_global, dst_global = int(row['from_bus']), int(row['to_bus'])
            
            # å®‰å…¨åœ°è·å–èŠ‚ç‚¹ç±»å‹ï¼Œå¦‚æœèŠ‚ç‚¹IDä¸å­˜åœ¨åˆ™è·³è¿‡ (å¤„ç†ä¸ä¸€è‡´çš„æ•°æ®)
            try:
                src_type_name = df_nodes.loc[src_global, 'type']
                dst_type_name = df_nodes.loc[dst_global, 'type']
            except KeyError:
                print(f"âš ï¸ è­¦å‘Šï¼šè·³è¿‡ä¸å­˜åœ¨çš„èŠ‚ç‚¹è¿æ¥ {src_global}-{dst_global}")
                continue

            src_type_key = f'bus_{src_type_name}'
            dst_type_key = f'bus_{dst_type_name}'
            edge_type = row['type']  # 'line' or 'transformer'

            # æ„å»ºå…³ç³»å…ƒç»„ï¼Œä¾‹å¦‚ ('bus_pq', 'connects_line', 'bus_pv')
            # ä¸ºäº†è§„èŒƒåŒ–ï¼Œæˆ‘ä»¬å°†èŠ‚ç‚¹ç±»å‹æŒ‰å­—æ¯é¡ºåºæ’åºï¼Œä»¥åˆ›å»ºå”¯ä¸€çš„å…³ç³»é”®
            sorted_node_keys = sorted([src_type_key, dst_type_key])
            relation_tuple = (sorted_node_keys[0], f'connects_{edge_type}', sorted_node_keys[1])
            
            # ç»Ÿè®¡å…³ç³»ç±»å‹
            if relation_tuple not in relation_stats:
                relation_stats[relation_tuple] = 0
            relation_stats[relation_tuple] += 1
            
            # ä»å…¨å±€IDè½¬æ¢ä¸ºç›¸åº”ç±»å‹çš„å±€éƒ¨ID
            try:
                src_local = global_to_local_maps[src_type_key][src_global]
                dst_local = global_to_local_maps[dst_type_key][dst_global]
            except KeyError:
                print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ°èŠ‚ç‚¹çš„å±€éƒ¨ç´¢å¼•æ˜ å°„")
                continue
            
            # æå–è¾¹ç‰¹å¾ (å»é™¤ç±»å‹åˆ—)
            edge_feature_cols = [col for col in df_edge_features.columns if col != 'type']
            edge_attr_values = row[edge_feature_cols].values.astype(np.float32)
            edge_attr = torch.tensor(edge_attr_values, dtype=torch.float32).unsqueeze(0)

            # åœ¨dataå¯¹è±¡ä¸­åˆå§‹åŒ–è¯¥å…³ç³»ç±»å‹çš„å­˜å‚¨
            if relation_tuple not in data:
                data[relation_tuple].edge_index = torch.empty((2, 0), dtype=torch.long)
                data[relation_tuple].edge_attr = torch.empty((0, len(edge_feature_cols)), dtype=torch.float32)
            
            # æ·»åŠ è¾¹ (æ³¨æ„ï¼šæ ¹æ®æ’åºåçš„å…ƒç»„ï¼Œå†³å®šsrcå’Œdstå“ªä¸ªåœ¨å‰)
            if src_type_key == sorted_node_keys[0]:
                edge_pair = torch.tensor([[src_local], [dst_local]], dtype=torch.long)
            else:
                edge_pair = torch.tensor([[dst_local], [src_local]], dtype=torch.long)

            data[relation_tuple].edge_index = torch.cat([data[relation_tuple].edge_index, edge_pair], dim=1)
            data[relation_tuple].edge_attr = torch.cat([data[relation_tuple].edge_attr, edge_attr], dim=0)

        # æ‰“å°å…³ç³»ç»Ÿè®¡ä¿¡æ¯
        print("ğŸŒ å¼‚æ„å›¾å…³ç³»ç»Ÿè®¡:")
        for relation, count in relation_stats.items():
            print(f"  ğŸ”— {relation}: {count} æ¡è¾¹")

        # --- 3. åˆ›å»ºæ— å‘å›¾ ---
        # PyGçš„ToUndirectedå¯ä»¥æ–¹ä¾¿åœ°ä¸ºå¼‚æ„å›¾åˆ›å»ºåå‘è¾¹
        try:
            from torch_geometric.transforms import ToUndirected
            data = ToUndirected()(data)
            print("âœ… æˆåŠŸåˆ›å»ºæ— å‘å¼‚æ„å›¾")
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•ä½¿ç”¨ToUndirectedè½¬æ¢ï¼Œä½¿ç”¨å½“å‰çš„æœ‰å‘å›¾: {e}")

        return data

    # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæ¥çš„create_pyg_dataæ–¹æ³•
    def create_pyg_data(self, df_nodes: pd.DataFrame, df_edges: pd.DataFrame, 
                       df_edge_features: pd.DataFrame):
        """
        å‘åå…¼å®¹çš„æ–¹æ³•ï¼Œç°åœ¨é‡å®šå‘åˆ°å¼‚æ„å›¾åˆ›å»º
        """
        print("âš ï¸ è­¦å‘Šï¼šcreate_pyg_dataå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨create_pyg_hetero_data")
        return self.create_pyg_hetero_data(df_nodes, df_edges, df_edge_features)

