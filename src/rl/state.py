"""
ç”µåŠ›ç½‘ç»œåˆ†åŒºMDPçš„çŠ¶æ€ç®¡ç†

æœ¬æ¨¡å—ç®¡ç†MDPå…¬å¼ä¸­æŒ‡å®šçš„çŠ¶æ€è¡¨ç¤ºï¼š
- èŠ‚ç‚¹ç‰¹å¾åµŒå…¥ï¼ˆHæˆ–H'ï¼‰ï¼šé™æ€çš„ï¼Œç”±GATç¼–ç å™¨é¢„è®¡ç®—ï¼Œå¯èƒ½åŒ…å«æ³¨æ„åŠ›å¢å¼ºä¿¡æ¯
- èŠ‚ç‚¹åˆ†é…æ ‡ç­¾ï¼ˆz_tï¼‰ï¼šåŠ¨æ€çš„ï¼Œéšæ¯ä¸ªåŠ¨ä½œå˜åŒ–
- è¾¹ç•ŒèŠ‚ç‚¹ï¼šä»å½“å‰åˆ†åŒºæ´¾ç”Ÿ
- åŒºåŸŸèšåˆåµŒå…¥ï¼šç”¨äºç­–ç•¥è¾“å…¥
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Set
from torch_geometric.data import HeteroData


class StateManager:
    """
    ç®¡ç†ç”µåŠ›ç½‘ç»œåˆ†åŒºçš„MDPçŠ¶æ€è¡¨ç¤º
    
    çŠ¶æ€ç»„ä»¶ï¼š
    1. èŠ‚ç‚¹ç‰¹å¾åµŒå…¥ï¼ˆH'ï¼‰- æ¥è‡ªGATç¼–ç å™¨çš„é™æ€çŸ©é˜µï¼Œå¯èƒ½åŒ…å«æ³¨æ„åŠ›å¢å¼ºä¿¡æ¯
       - å¦‚æœæä¾›äº†æ³¨æ„åŠ›æƒé‡ï¼šH' = concat(H, H_attn)
       - å¦‚æœæ²¡æœ‰æ³¨æ„åŠ›æƒé‡ï¼šH' = Hï¼ˆåŸå§‹åµŒå…¥ï¼‰
    2. èŠ‚ç‚¹åˆ†é…æ ‡ç­¾ï¼ˆz_tï¼‰- åŠ¨æ€åˆ†åŒºåˆ†é…
    3. è¾¹ç•ŒèŠ‚ç‚¹ï¼ˆBdry_tï¼‰- ä¸ä¸åŒåˆ†åŒºä¸­é‚»å±…ç›¸è¿çš„èŠ‚ç‚¹
    4. åŒºåŸŸèšåˆåµŒå…¥ - æ¯ä¸ªåŒºåŸŸçš„å‡å€¼/æœ€å¤§æ± åŒ–åµŒå…¥
    """
    
    def __init__(self, 
                 hetero_data: HeteroData,
                 node_embeddings: Dict[str, torch.Tensor],
                 device: torch.device):
        """
        åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        
        Args:
            hetero_data: å¼‚æ„å›¾æ•°æ®
            node_embeddings: æ¥è‡ªGATç¼–ç å™¨çš„é¢„è®¡ç®—èŠ‚ç‚¹åµŒå…¥
                           - å¯èƒ½æ˜¯åŸå§‹åµŒå…¥Hï¼Œä¹Ÿå¯èƒ½æ˜¯å¢å¼ºåµŒå…¥H' = concat(H, H_attn)
                           - å…·ä½“å–å†³äºEnvironmentæ˜¯å¦æä¾›äº†æ³¨æ„åŠ›æƒé‡
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.hetero_data = hetero_data.to(device)
        
        # è®¾ç½®èŠ‚ç‚¹æ˜ å°„å’ŒåµŒå…¥
        self._setup_node_mappings()
        self._setup_node_embeddings(node_embeddings)
        self._setup_adjacency_info()
        
        # çŠ¶æ€å˜é‡
        self.current_partition = None
        self.boundary_nodes = None
        self.region_embeddings = None
        
    def _setup_node_mappings(self):
        """è®¾ç½®å±€éƒ¨å’Œå…¨å±€èŠ‚ç‚¹ç´¢å¼•ä¹‹é—´çš„æ˜ å°„"""
        self.node_types = list(self.hetero_data.x_dict.keys())
        self.total_nodes = sum(x.shape[0] for x in self.hetero_data.x_dict.values())
        
        # åˆ›å»ºä»å±€éƒ¨ç´¢å¼•åˆ°å…¨å±€ç´¢å¼•çš„æ˜ å°„
        self.local_to_global_map = {}
        self.global_to_local_map = {}
        
        global_idx = 0
        for node_type in self.node_types:
            num_nodes = self.hetero_data.x_dict[node_type].shape[0]
            
            # è¯¥ç±»å‹çš„å±€éƒ¨åˆ°å…¨å±€æ˜ å°„
            local_indices = torch.arange(num_nodes, device=self.device)
            global_indices = torch.arange(global_idx, global_idx + num_nodes, device=self.device)
            
            self.local_to_global_map[node_type] = global_indices
            
            # å…¨å±€åˆ°å±€éƒ¨æ˜ å°„
            for local_idx, global_idx_val in zip(local_indices, global_indices):
                self.global_to_local_map[global_idx_val.item()] = (node_type, local_idx.item())
                
            global_idx += num_nodes
            
    def _setup_node_embeddings(self, node_embeddings: Dict[str, torch.Tensor]):
        """
        è®¾ç½®è¿æ¥çš„èŠ‚ç‚¹åµŒå…¥çŸ©é˜µH'
        
        è¿™é‡Œçš„node_embeddingså¯èƒ½æ˜¯ï¼š
        1. åŸå§‹GATåµŒå…¥Hï¼ˆå¦‚æœEnvironmentæ²¡æœ‰æä¾›æ³¨æ„åŠ›æƒé‡ï¼‰
        2. å¢å¼ºåµŒå…¥H' = concat(H, H_attn)ï¼ˆå¦‚æœEnvironmentæä¾›äº†æ³¨æ„åŠ›æƒé‡ï¼‰
        
        æ— è®ºå“ªç§æƒ…å†µï¼Œæˆ‘ä»¬éƒ½å°†å…¶ä½œä¸ºå®Œæ•´çš„èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µä½¿ç”¨
        """
        # å°†æ‰€æœ‰èŠ‚ç‚¹åµŒå…¥è¿æ¥æˆå•ä¸ªçŸ©é˜µ
        embedding_list = []
        for node_type in self.node_types:
            embeddings = node_embeddings[node_type].to(self.device)
            embedding_list.append(embeddings)
            
        self.node_embeddings = torch.cat(embedding_list, dim=0)  # å½¢çŠ¶ï¼š[total_nodes, embedding_dim]
        self.embedding_dim = self.node_embeddings.shape[1]
        
        # è®°å½•åµŒå…¥ç»´åº¦ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        print(f"ğŸ”§ StateManager: è®¾ç½®èŠ‚ç‚¹åµŒå…¥çŸ©é˜µï¼Œå½¢çŠ¶ {self.node_embeddings.shape}")
        print(f"   - æ€»èŠ‚ç‚¹æ•°: {self.total_nodes}")
        print(f"   - åµŒå…¥ç»´åº¦: {self.embedding_dim}")
        print(f"   - æ³¨æ„ï¼šæ­¤åµŒå…¥å¯èƒ½åŒ…å«GATåŸå§‹åµŒå…¥ + æ³¨æ„åŠ›å¢å¼ºä¿¡æ¯")
        
    def _setup_adjacency_info(self):
        """è®¾ç½®ç”¨äºè¾¹ç•ŒèŠ‚ç‚¹è®¡ç®—çš„é‚»æ¥ä¿¡æ¯"""
        # åˆ›å»ºå…¨å±€é‚»æ¥åˆ—è¡¨
        self.adjacency_list = [[] for _ in range(self.total_nodes)]
        
        for edge_type, edge_index in self.hetero_data.edge_index_dict.items():
            src_type, _, dst_type = edge_type
            
            # è½¬æ¢ä¸ºå…¨å±€ç´¢å¼•
            src_global = self.local_to_global(edge_index[0], src_type)
            dst_global = self.local_to_global(edge_index[1], dst_type)
            
            # æ·»åŠ åˆ°é‚»æ¥åˆ—è¡¨
            for src, dst in zip(src_global, dst_global):
                self.adjacency_list[src.item()].append(dst.item())
                
    def local_to_global(self, local_indices: torch.Tensor, node_type: str) -> torch.Tensor:
        """å°†ç»™å®šèŠ‚ç‚¹ç±»å‹çš„å±€éƒ¨ç´¢å¼•è½¬æ¢ä¸ºå…¨å±€ç´¢å¼•"""
        return self.local_to_global_map[node_type][local_indices]
        
    def global_to_local(self, global_idx: int) -> Tuple[str, int]:
        """å°†å…¨å±€ç´¢å¼•è½¬æ¢ä¸º(node_type, local_index)"""
        return self.global_to_local_map[global_idx]
        
    def reset(self, initial_partition: torch.Tensor):
        """
        ä½¿ç”¨åˆå§‹åˆ†åŒºé‡ç½®çŠ¶æ€
        
        Args:
            initial_partition: åˆå§‹åˆ†åŒºåˆ†é… [total_nodes]
        """
        self.current_partition = initial_partition.to(self.device)
        self._update_derived_state()
        
    def update_partition(self, node_idx: int, new_partition: int):
        """
        æ›´æ–°å•ä¸ªèŠ‚ç‚¹çš„åˆ†åŒºåˆ†é…
        
        Args:
            node_idx: å…¨å±€èŠ‚ç‚¹ç´¢å¼•
            new_partition: æ–°çš„åˆ†åŒºåˆ†é…
        """
        old_partition = self.current_partition[node_idx].item()
        self.current_partition[node_idx] = new_partition
        
        # é«˜æ•ˆæ›´æ–°è¾¹ç•ŒèŠ‚ç‚¹
        self._update_boundary_nodes_incremental(node_idx, old_partition, new_partition)
        
        # æ›´æ–°å—å½±å“åˆ†åŒºçš„åŒºåŸŸåµŒå…¥
        self._update_region_embeddings_incremental(old_partition, new_partition)
        
    def _update_derived_state(self):
        """æ›´æ–°æ‰€æœ‰æ´¾ç”ŸçŠ¶æ€ç»„ä»¶"""
        self._compute_boundary_nodes()
        self._compute_region_embeddings()
        
    def _compute_boundary_nodes(self):
        """ä»å½“å‰åˆ†åŒºè®¡ç®—è¾¹ç•ŒèŠ‚ç‚¹"""
        boundary_set = set()
        
        for node_idx in range(self.total_nodes):
            node_partition = self.current_partition[node_idx].item()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‚»å±…åœ¨ä¸åŒåˆ†åŒºä¸­
            for neighbor_idx in self.adjacency_list[node_idx]:
                neighbor_partition = self.current_partition[neighbor_idx].item()
                if neighbor_partition != node_partition:
                    boundary_set.add(node_idx)
                    break
                    
        self.boundary_nodes = torch.tensor(list(boundary_set), device=self.device)
        
    def _update_boundary_nodes_incremental(self, changed_node: int, old_partition: int, new_partition: int):
        """å•ä¸ªèŠ‚ç‚¹å˜åŒ–åå¢é‡æ›´æ–°è¾¹ç•ŒèŠ‚ç‚¹"""
        # è½¬æ¢ä¸ºé›†åˆä»¥è¿›è¡Œé«˜æ•ˆæ“ä½œ
        if self.boundary_nodes is not None:
            try:
                boundary_set = set(self.boundary_nodes.cpu().numpy())
            except RuntimeError:
                boundary_set = set(self.boundary_nodes.cpu().tolist())
        else:
            boundary_set = set()
        
        # æ£€æŸ¥å˜åŒ–çš„èŠ‚ç‚¹
        is_boundary = False
        for neighbor_idx in self.adjacency_list[changed_node]:
            neighbor_partition = self.current_partition[neighbor_idx].item()
            if neighbor_partition != new_partition:
                is_boundary = True
                break
                
        if is_boundary:
            boundary_set.add(changed_node)
        else:
            boundary_set.discard(changed_node)
            
        # æ£€æŸ¥å˜åŒ–èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…
        for neighbor_idx in self.adjacency_list[changed_node]:
            neighbor_partition = self.current_partition[neighbor_idx].item()
            
            # æ£€æŸ¥é‚»å±…æ˜¯å¦ç°åœ¨æ˜¯è¾¹ç•ŒèŠ‚ç‚¹
            neighbor_is_boundary = False
            for neighbor_neighbor_idx in self.adjacency_list[neighbor_idx]:
                neighbor_neighbor_partition = self.current_partition[neighbor_neighbor_idx].item()
                if neighbor_neighbor_partition != neighbor_partition:
                    neighbor_is_boundary = True
                    break
                    
            if neighbor_is_boundary:
                boundary_set.add(neighbor_idx)
            else:
                boundary_set.discard(neighbor_idx)
                
        self.boundary_nodes = torch.tensor(list(boundary_set), device=self.device)
        
    def _compute_region_embeddings(self):
        """è®¡ç®—æ‰€æœ‰åˆ†åŒºçš„åŒºåŸŸèšåˆåµŒå…¥"""
        num_partitions = self.current_partition.max().item()
        self.region_embeddings = {}
        
        for partition_id in range(1, num_partitions + 1):
            # æ‰¾åˆ°è¯¥åˆ†åŒºä¸­çš„èŠ‚ç‚¹
            partition_mask = (self.current_partition == partition_id)
            partition_nodes = torch.where(partition_mask)[0]
            
            if len(partition_nodes) > 0:
                # è·å–è¯¥åˆ†åŒºä¸­èŠ‚ç‚¹çš„åµŒå…¥
                partition_embeddings = self.node_embeddings[partition_nodes]
                
                # è®¡ç®—å‡å€¼å’Œæœ€å¤§æ± åŒ–
                mean_embedding = torch.mean(partition_embeddings, dim=0)
                max_embedding = torch.max(partition_embeddings, dim=0)[0]
                
                # è¿æ¥å‡å€¼å’Œæœ€å¤§å€¼
                region_embedding = torch.cat([mean_embedding, max_embedding], dim=0)
                self.region_embeddings[partition_id] = region_embedding
            else:
                # ç©ºåˆ†åŒº - ä½¿ç”¨é›¶åµŒå…¥
                zero_embedding = torch.zeros(2 * self.embedding_dim, device=self.device)
                self.region_embeddings[partition_id] = zero_embedding
                
    def _update_region_embeddings_incremental(self, old_partition: int, new_partition: int):
        """å¢é‡æ›´æ–°å—å½±å“åˆ†åŒºçš„åŒºåŸŸåµŒå…¥"""
        # ä¸ºç®€å•èµ·è§ï¼Œé‡æ–°è®¡ç®—å—å½±å“åˆ†åŒºçš„åµŒå…¥
        # å¯¹äºéå¸¸å¤§çš„å›¾ï¼Œè¿™å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–
        for partition_id in [old_partition, new_partition]:
            partition_mask = (self.current_partition == partition_id)
            partition_nodes = torch.where(partition_mask)[0]
            
            if len(partition_nodes) > 0:
                partition_embeddings = self.node_embeddings[partition_nodes]
                mean_embedding = torch.mean(partition_embeddings, dim=0)
                max_embedding = torch.max(partition_embeddings, dim=0)[0]
                region_embedding = torch.cat([mean_embedding, max_embedding], dim=0)
                self.region_embeddings[partition_id] = region_embedding
            else:
                zero_embedding = torch.zeros(2 * self.embedding_dim, device=self.device)
                self.region_embeddings[partition_id] = zero_embedding
                
    def get_observation(self) -> Dict[str, torch.Tensor]:
        """
        è·å–RLæ™ºèƒ½ä½“çš„å½“å‰çŠ¶æ€è§‚å¯Ÿ
        
        Returns:
            åŒ…å«çŠ¶æ€ç»„ä»¶çš„å­—å…¸
        """
        # å°†åŒºåŸŸåµŒå…¥ä½œä¸ºå¼ é‡
        num_partitions = len(self.region_embeddings)
        region_embedding_tensor = torch.stack([
            self.region_embeddings[i+1] for i in range(num_partitions)
        ], dim=0)
        
        # è¾¹ç•ŒèŠ‚ç‚¹ç‰¹å¾
        if len(self.boundary_nodes) > 0:
            boundary_features = self.node_embeddings[self.boundary_nodes]
        else:
            boundary_features = torch.empty(0, self.embedding_dim, device=self.device)
            
        observation = {
            'node_embeddings': self.node_embeddings,  # [total_nodes, embedding_dim]
            'region_embeddings': region_embedding_tensor,  # [num_partitions, 2*embedding_dim]
            'boundary_features': boundary_features,  # [num_boundary, embedding_dim]
            'current_partition': self.current_partition,  # [total_nodes]
            'boundary_nodes': self.boundary_nodes,  # [num_boundary]
        }
        
        return observation
        
    def get_boundary_nodes(self) -> torch.Tensor:
        """è·å–å½“å‰è¾¹ç•ŒèŠ‚ç‚¹"""
        return self.boundary_nodes if self.boundary_nodes is not None else torch.empty(0, dtype=torch.long, device=self.device)
        
    def get_global_node_mapping(self) -> Dict[str, torch.Tensor]:
        """è·å–ä»èŠ‚ç‚¹ç±»å‹åˆ°å…¨å±€ç´¢å¼•çš„æ˜ å°„"""
        return self.local_to_global_map
        
    def get_partition_info(self) -> Dict[str, torch.Tensor]:
        """è·å–è¯¦ç»†çš„åˆ†åŒºä¿¡æ¯"""
        num_partitions = self.current_partition.max().item()
        partition_sizes = torch.bincount(self.current_partition, minlength=num_partitions + 1)[1:]
        
        return {
            'partition_assignments': self.current_partition,
            'partition_sizes': partition_sizes,
            'num_partitions': num_partitions,
            'boundary_nodes': self.get_boundary_nodes()
        }
