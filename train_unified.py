#!/usr/bin/env python3
"""
ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ ç»Ÿä¸€è®­ç»ƒç³»ç»Ÿ

æ•´åˆäº†æ‰€æœ‰è®­ç»ƒæ¨¡å¼ï¼š
- æ ‡å‡†è®­ç»ƒ (IEEE 14, 30, 57èŠ‚ç‚¹)
- å¤§è§„æ¨¡è®­ç»ƒ (IEEE 118èŠ‚ç‚¹)
- å¹¶è¡Œè®­ç»ƒæ”¯æŒ
- åœºæ™¯ç”Ÿæˆè®­ç»ƒ
- è¯¾ç¨‹å­¦ä¹ è®­ç»ƒ
- åŸºçº¿æ–¹æ³•å¯¹æ¯”
"""

import torch
import numpy as np
import argparse
import yaml
import os
import sys
import time
import json
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from collections import deque
import matplotlib.pyplot as plt

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent / 'src'))

# ç¦ç”¨è­¦å‘Š
warnings.filterwarnings('ignore')

# åŠ¨æ€å¯¼å…¥æ£€æŸ¥
def check_dependencies():
    """æ£€æŸ¥å¯é€‰ä¾èµ–"""
    deps = {
        'stable_baselines3': False,
        'tensorboard': False,
        'plotly': False
    }
    
    try:
        import stable_baselines3
        deps['stable_baselines3'] = True
    except ImportError:
        pass
    
    try:
        from torch.utils.tensorboard import SummaryWriter
        deps['tensorboard'] = True
    except ImportError:
        pass
        
    try:
        import plotly.graph_objects as go
        deps['plotly'] = True
    except ImportError:
        pass
    
    return deps


class UnifiedTrainingSystem:
    """ç»Ÿä¸€è®­ç»ƒç³»ç»Ÿ - æ•´åˆæ‰€æœ‰è®­ç»ƒæ¨¡å¼"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–ç»Ÿä¸€è®­ç»ƒç³»ç»Ÿ"""
        self.deps = check_dependencies()
        self.config = self._load_config(config_path)
        self.device = self._setup_device()
        self.setup_directories()
        
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        else:
            return self._create_default_config()
    
    def _create_default_config(self) -> Dict[str, Any]:
        """åˆ›å»ºé»˜è®¤é…ç½®"""
        return {
            'system': {
                'name': 'unified_power_grid_partitioning',
                'version': '2.0',
                'device': 'auto',
                'seed': 42,
                'num_threads': 1
            },
            'data': {
                'case_name': 'ieee14',
                'normalize': True,
                'cache_dir': 'cache'
            },
            'training': {
                'mode': 'standard',  # standard, parallel, curriculum, large_scale
                'num_episodes': 1000,
                'max_steps_per_episode': 200,
                'update_interval': 10,
                'save_interval': 100,
                'eval_interval': 50
            },
            'environment': {
                'num_partitions': 3,
                'max_steps': 200,
                'reward_weights': {
                    'load_balance': 0.4,
                    'electrical_decoupling': 0.4,
                    'power_balance': 0.2
                }
            },
            'gat': {
                'hidden_channels': 64,
                'gnn_layers': 3,
                'heads': 4,
                'output_dim': 128,
                'dropout': 0.1
            },
            'agent': {
                'type': 'ppo',  # ppo, sb3_ppo
                'lr_actor': 3e-4,
                'lr_critic': 1e-3,
                'gamma': 0.99,
                'eps_clip': 0.2,
                'k_epochs': 4,
                'entropy_coef': 0.01,
                'value_coef': 0.5,
                'hidden_dim': 256
            },
            'parallel_training': {
                'enabled': False,
                'num_cpus': 12,
                'total_timesteps': 5_000_000,
                'scenario_generation': True
            },
            'scenario_generation': {
                'enabled': False,
                'perturb_prob': 0.8,
                'perturb_types': ['n-1', 'load_gen_fluctuation', 'both', 'none'],
                'scale_range': [0.8, 1.2]
            },
            'curriculum': {
                'enabled': False,
                'start_partitions': 2,
                'end_partitions': 5,
                'episodes_per_stage': 200
            },
            'evaluation': {
                'num_episodes': 20,
                'include_baselines': True,
                'baseline_methods': ['spectral', 'kmeans', 'random']
            },
            'visualization': {
                'enabled': True,
                'save_figures': True,
                'figures_dir': 'figures',
                'interactive': True
            },
            'logging': {
                'use_tensorboard': True,
                'log_dir': 'logs',
                'checkpoint_dir': 'checkpoints',
                'console_log_interval': 10,
                'metrics_save_interval': 50
            }
        }
    
    def _setup_device(self) -> torch.device:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        device_config = self.config['system'].get('device', 'auto')
        if device_config == 'auto':
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            device = torch.device(device_config)
        
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
        return device
    
    def setup_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        dirs = [
            self.config['data']['cache_dir'],
            self.config['logging']['log_dir'], 
            self.config['logging']['checkpoint_dir'],
            self.config['visualization']['figures_dir'],
            'models', 'output', 'experiments'
        ]
        
        for dir_path in dirs:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def get_training_configs(self) -> Dict[str, Dict[str, Any]]:
        """è·å–ä¸åŒè®­ç»ƒæ¨¡å¼çš„é…ç½®"""
        base_config = self.config.copy()
        
        configs = {
            'quick': {
                **base_config,
                'training': {
                    **base_config['training'],
                    'num_episodes': 100,
                    'max_steps_per_episode': 50,
                    'update_interval': 5
                }
            },
            'standard': base_config,
            'full': {
                **base_config,
                'training': {
                    **base_config['training'],
                    'num_episodes': 2000,
                    'max_steps_per_episode': 500,
                    'update_interval': 20
                }
            },
            'ieee118': {
                **base_config,
                'data': {
                    **base_config['data'],
                    'case_name': 'ieee118'
                },
                'environment': {
                    **base_config['environment'],
                    'num_partitions': 8,
                    'max_steps': 500
                },
                'gat': {
                    **base_config['gat'],
                    'hidden_channels': 128,
                    'gnn_layers': 4,
                    'heads': 8,
                    'output_dim': 256
                },
                'training': {
                    **base_config['training'],
                    'num_episodes': 5000,
                    'max_steps_per_episode': 500
                },
                'parallel_training': {
                    **base_config['parallel_training'],
                    'enabled': True
                },
                'scenario_generation': {
                    **base_config['scenario_generation'],
                    'enabled': True
                }
            },
            'parallel': {
                **base_config,
                'parallel_training': {
                    **base_config['parallel_training'],
                    'enabled': True
                },
                'scenario_generation': {
                    **base_config['scenario_generation'],
                    'enabled': True
                }
            },
            'curriculum': {
                **base_config,
                'curriculum': {
                    **base_config['curriculum'],
                    'enabled': True
                }
            }
        }
        
        return configs
    
    def run_training(self, mode: str = 'standard', **kwargs) -> Dict[str, Any]:
        """è¿è¡Œè®­ç»ƒ"""
        print(f"\nğŸš€ å¼€å§‹{mode.upper()}æ¨¡å¼è®­ç»ƒ")
        print("=" * 60)
        
        # è·å–æ¨¡å¼é…ç½®
        configs = self.get_training_configs()
        if mode not in configs:
            print(f"âš ï¸ æœªçŸ¥è®­ç»ƒæ¨¡å¼: {mode}ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼")
            mode = 'standard'
        
        config = configs[mode]
        
        # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
        for key, value in kwargs.items():
            if '.' in key:
                # æ”¯æŒåµŒå¥—é…ç½®ï¼Œå¦‚ training.num_episodes
                keys = key.split('.')
                current = config
                for k in keys[:-1]:
                    if k not in current:
                        current[k] = {}
                    current = current[k]
                current[keys[-1]] = value
            else:
                config[key] = value
        
        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(config['system']['seed'])
        np.random.seed(config['system']['seed'])
        
        try:
            if mode == 'parallel' or config['parallel_training']['enabled']:
                return self._run_parallel_training(config)
            elif mode == 'curriculum' or config['curriculum']['enabled']:
                return self._run_curriculum_training(config)
            else:
                return self._run_standard_training(config)
                
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def _run_standard_training(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œæ ‡å‡†è®­ç»ƒ"""
        print("ğŸ“Š æ ‡å‡†è®­ç»ƒæ¨¡å¼")
        
        # å¯¼å…¥å¿…è¦æ¨¡å—
        from data_processing import PowerGridDataProcessor
        from gat import create_hetero_graph_encoder
        from rl.environment import PowerGridPartitioningEnv
        from rl.agent import PPOAgent
        from src.train_rl import UnifiedTrainer, TrainingLogger, CheckpointManager
        
        # 1. æ•°æ®å¤„ç†
        print("\n1ï¸âƒ£ æ•°æ®å¤„ç†...")
        processor = PowerGridDataProcessor(
            normalize=config['data']['normalize'],
            cache_dir=config['data']['cache_dir']
        )
        
        # åŠ è½½æ•°æ®
        if config['data']['case_name'] == 'ieee118':
            from src.train_parallel_118bus import load_case118_data
            mpc = load_case118_data()
        else:
            from src.train_rl import load_power_grid_data
            mpc = load_power_grid_data(config['data']['case_name'])
        
        hetero_data = processor.graph_from_mpc(mpc).to(self.device)
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {hetero_data}")
        
        # 2. GATç¼–ç å™¨
        print("\n2ï¸âƒ£ GATç¼–ç å™¨...")
        gat_config = config['gat']
        encoder = create_hetero_graph_encoder(
            hetero_data,
            hidden_channels=gat_config['hidden_channels'],
            gnn_layers=gat_config['gnn_layers'],
            heads=gat_config['heads'],
            output_dim=gat_config['output_dim']
        ).to(self.device)
        
        with torch.no_grad():
            node_embeddings, attention_weights = encoder.encode_nodes_with_attention(hetero_data)
        
        print(f"âœ… ç¼–ç å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # 3. ç¯å¢ƒ
        print("\n3ï¸âƒ£ å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ...")
        env_config = config['environment']
        env = PowerGridPartitioningEnv(
            hetero_data=hetero_data,
            node_embeddings=node_embeddings,
            num_partitions=env_config['num_partitions'],
            reward_weights=env_config['reward_weights'],
            max_steps=env_config['max_steps'],
            device=self.device,
            attention_weights=attention_weights
        )
        
        print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ: {env.total_nodes}èŠ‚ç‚¹, {env.num_partitions}åˆ†åŒº")
        
        # 4. æ™ºèƒ½ä½“
        print("\n4ï¸âƒ£ PPOæ™ºèƒ½ä½“...")
        agent_config = config['agent']
        node_embedding_dim = env.state_manager.embedding_dim
        region_embedding_dim = node_embedding_dim * 2
        
        agent = PPOAgent(
            node_embedding_dim=node_embedding_dim,
            region_embedding_dim=region_embedding_dim,
            num_partitions=env.num_partitions,
            lr_actor=agent_config['lr_actor'],
            lr_critic=agent_config['lr_critic'],
            gamma=agent_config['gamma'],
            eps_clip=agent_config['eps_clip'],
            k_epochs=agent_config['k_epochs'],
            entropy_coef=agent_config['entropy_coef'],
            value_coef=agent_config['value_coef'],
            device=self.device
        )
        
        print(f"âœ… æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ")
        
        # 5. è®­ç»ƒ
        print("\n5ï¸âƒ£ å¼€å§‹è®­ç»ƒ...")
        trainer = UnifiedTrainer(agent=agent, env=env, config=config)
        
        training_config = config['training']
        history = trainer.train(
            num_episodes=training_config['num_episodes'],
            max_steps_per_episode=training_config['max_steps_per_episode'],
            update_interval=training_config['update_interval']
        )
        
        # 6. è¯„ä¼°
        print("\n6ï¸âƒ£ è¯„ä¼°...")
        eval_stats = trainer.evaluate()
        
        # 7. åŸºçº¿å¯¹æ¯”
        baseline_results = None
        if config['evaluation']['include_baselines']:
            print("\n7ï¸âƒ£ åŸºçº¿æ–¹æ³•å¯¹æ¯”...")
            try:
                from baseline import run_baseline_comparison
                baseline_results = run_baseline_comparison(env, agent, seed=42)
                print("âœ… åŸºçº¿å¯¹æ¯”å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ åŸºçº¿å¯¹æ¯”å¤±è´¥: {e}")
        
        # 8. å¯è§†åŒ–
        if config['visualization']['enabled']:
            print("\n8ï¸âƒ£ ç”Ÿæˆå¯è§†åŒ–...")
            try:
                trainer.run_final_visualization()
                if baseline_results is not None and config['visualization']['interactive']:
                    from visualization import run_interactive_visualization
                    run_interactive_visualization(env, baseline_results)
            except Exception as e:
                print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")
        
        trainer.close()
        
        return {
            'success': True,
            'mode': 'standard',
            'config': config,
            'history': history,
            'eval_stats': eval_stats,
            'baseline_results': baseline_results,
            'best_reward': trainer.logger.best_reward
        }
    
    def _run_parallel_training(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå¹¶è¡Œè®­ç»ƒ"""
        print("ğŸŒ å¹¶è¡Œè®­ç»ƒæ¨¡å¼")
        
        if not self.deps['stable_baselines3']:
            print("âŒ å¹¶è¡Œè®­ç»ƒéœ€è¦stable-baselines3ï¼Œè¯·å®‰è£…ï¼špip install stable-baselines3")
            return {'success': False, 'error': 'Missing stable-baselines3'}
        
        # ä½¿ç”¨118èŠ‚ç‚¹ç³»ç»Ÿçš„å¹¶è¡Œè®­ç»ƒé€»è¾‘
        from src.train_parallel_118bus import main as run_parallel_118
        
        # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
        import sys
        original_argv = sys.argv.copy()
        
        parallel_config = config['parallel_training']
        sys.argv = [
            'train_parallel_118bus.py',
            '--num-cpus', str(parallel_config['num_cpus']),
            '--total-timesteps', str(parallel_config['total_timesteps'])
        ]
        
        if not parallel_config['scenario_generation']:
            sys.argv.append('--no-scenario')
        
        try:
            result = run_parallel_118()
            return {
                'success': True,
                'mode': 'parallel',
                'config': config
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}
        finally:
            sys.argv = original_argv
    
    def _run_curriculum_training(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œè¯¾ç¨‹å­¦ä¹ è®­ç»ƒ"""
        print("ğŸ“š è¯¾ç¨‹å­¦ä¹ è®­ç»ƒæ¨¡å¼")
        
        curriculum_config = config['curriculum']
        start_partitions = curriculum_config['start_partitions']
        end_partitions = curriculum_config['end_partitions']
        episodes_per_stage = curriculum_config['episodes_per_stage']
        
        results = []
        
        for num_partitions in range(start_partitions, end_partitions + 1):
            print(f"\nğŸ“– è¯¾ç¨‹é˜¶æ®µ: {num_partitions}ä¸ªåˆ†åŒº")
            
            # æ›´æ–°é…ç½®
            stage_config = config.copy()
            stage_config['environment']['num_partitions'] = num_partitions
            stage_config['training']['num_episodes'] = episodes_per_stage
            
            # è¿è¡Œè¯¥é˜¶æ®µçš„è®­ç»ƒ
            stage_result = self._run_standard_training(stage_config)
            results.append(stage_result)
            
            if not stage_result['success']:
                break
        
        return {
            'success': all(r['success'] for r in results),
            'mode': 'curriculum',
            'config': config,
            'stage_results': results
        }
    
    def run_demo(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´ç³»ç»Ÿæ¼”ç¤º"""
        print("\nğŸª è¿è¡Œå®Œæ•´ç³»ç»Ÿæ¼”ç¤º")
        print("=" * 60)
        
        # å¯¼å…¥ä¸»æ¼”ç¤ºå‡½æ•°
        from main import main as run_main_demo
        
        try:
            run_main_demo('quick')
            return {'success': True, 'mode': 'demo'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def create_training_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        report_lines = [
            f"# ç”µåŠ›ç½‘ç»œåˆ†åŒºè®­ç»ƒæŠ¥å‘Š",
            f"",
            f"## ç³»ç»Ÿä¿¡æ¯",
            f"- è®­ç»ƒæ¨¡å¼: {results.get('mode', 'unknown')}",
            f"- è®¾å¤‡: {self.device}",
            f"- æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"",
            f"## é…ç½®ä¿¡æ¯"
        ]
        
        if 'config' in results:
            config = results['config']
            report_lines.extend([
                f"- æ¡ˆä¾‹: {config['data']['case_name']}",
                f"- åˆ†åŒºæ•°: {config['environment']['num_partitions']}",
                f"- è®­ç»ƒå›åˆ: {config['training']['num_episodes']}",
                f"- æœ€å¤§æ­¥æ•°: {config['training']['max_steps_per_episode']}"
            ])
        
        if 'eval_stats' in results:
            eval_stats = results['eval_stats']
            report_lines.extend([
                f"",
                f"## è¯„ä¼°ç»“æœ",
                f"- å¹³å‡å¥–åŠ±: {eval_stats.get('mean_reward', 0):.4f}",
                f"- æˆåŠŸç‡: {eval_stats.get('success_rate', 0):.4f}",
                f"- å¹³å‡è´Ÿè½½CV: {eval_stats.get('mean_load_cv', 0):.4f}"
            ])
        
        if 'baseline_results' in results and results['baseline_results'] is not None:
            report_lines.extend([
                f"",
                f"## åŸºçº¿æ–¹æ³•å¯¹æ¯”",
                f"åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœå·²ä¿å­˜"
            ])
        
        return "\n".join(report_lines)
    
    def save_results(self, results: Dict[str, Any], output_dir: str = 'experiments'):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        mode = results.get('mode', 'unknown')
        
        # ä¿å­˜ç»“æœJSON
        results_file = output_path / f"{mode}_results_{timestamp}.json"
        
        # æ¸…ç†ä¸èƒ½åºåˆ—åŒ–çš„å¯¹è±¡
        clean_results = {}
        for key, value in results.items():
            if key in ['history', 'eval_stats', 'config']:
                clean_results[key] = value
            elif key == 'baseline_results' and value is not None:
                clean_results[key] = value.to_dict() if hasattr(value, 'to_dict') else str(value)
            elif isinstance(value, (str, int, float, bool, type(None))):
                clean_results[key] = value
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(clean_results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜è®­ç»ƒæŠ¥å‘Š
        report = self.create_training_report(results)
        report_file = output_path / f"{mode}_report_{timestamp}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        print(f"   - ç»“æœæ–‡ä»¶: {results_file.name}")
        print(f"   - æŠ¥å‘Šæ–‡ä»¶: {report_file.name}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”µåŠ›ç½‘ç»œåˆ†åŒºç»Ÿä¸€è®­ç»ƒç³»ç»Ÿ')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, default='standard',
                       choices=['quick', 'standard', 'full', 'ieee118', 'parallel', 'curriculum', 'demo'],
                       help='è®­ç»ƒæ¨¡å¼')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--case', type=str, help='ç”µç½‘æ¡ˆä¾‹åç§°')
    parser.add_argument('--episodes', type=int, help='è®­ç»ƒå›åˆæ•°')
    parser.add_argument('--partitions', type=int, help='åˆ†åŒºæ•°é‡')
    parser.add_argument('--device', type=str, help='è®¡ç®—è®¾å¤‡')
    
    # åŠŸèƒ½å¼€å…³
    parser.add_argument('--no-baselines', action='store_true', help='è·³è¿‡åŸºçº¿æ–¹æ³•å¯¹æ¯”')
    parser.add_argument('--no-viz', action='store_true', help='è·³è¿‡å¯è§†åŒ–')
    parser.add_argument('--save-results', action='store_true', help='ä¿å­˜è®­ç»ƒç»“æœ')
    
    # ç‰¹æ®Šæ¨¡å¼
    parser.add_argument('--list-configs', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®')
    parser.add_argument('--check-deps', action='store_true', help='æ£€æŸ¥ä¾èµ–')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–
    if args.check_deps:
        deps = check_dependencies()
        print("ğŸ“‹ ä¾èµ–æ£€æŸ¥ç»“æœ:")
        for dep, available in deps.items():
            status = "âœ…" if available else "âŒ"
            print(f"  {status} {dep}")
        return
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = UnifiedTrainingSystem(args.config)
    
    # åˆ—å‡ºé…ç½®
    if args.list_configs:
        configs = system.get_training_configs()
        print("ğŸ“‹ å¯ç”¨è®­ç»ƒé…ç½®:")
        for name in configs.keys():
            print(f"  - {name}")
        return
    
    # æ„å»ºå‚æ•°è¦†ç›–
    overrides = {}
    if args.case:
        overrides['data.case_name'] = args.case
    if args.episodes:
        overrides['training.num_episodes'] = args.episodes
    if args.partitions:
        overrides['environment.num_partitions'] = args.partitions
    if args.device:
        overrides['system.device'] = args.device
    if args.no_baselines:
        overrides['evaluation.include_baselines'] = False
    if args.no_viz:
        overrides['visualization.enabled'] = False
    
    # è¿è¡Œè®­ç»ƒ
    print("\nğŸ¯ ç”µåŠ›ç½‘ç»œåˆ†åŒºç»Ÿä¸€è®­ç»ƒç³»ç»Ÿå¯åŠ¨")
    print("=" * 60)
    
    start_time = time.time()
    
    if args.mode == 'demo':
        results = system.run_demo()
    else:
        results = system.run_training(args.mode, **overrides)
    
    elapsed_time = time.time() - start_time
    
    # ç»“æœæ±‡æ€»
    print("\nğŸ“Š è®­ç»ƒå®Œæˆæ€»ç»“")
    print("=" * 60)
    print(f"æ¨¡å¼: {args.mode}")
    print(f"è€—æ—¶: {elapsed_time/3600:.2f} å°æ—¶")
    print(f"çŠ¶æ€: {'âœ… æˆåŠŸ' if results.get('success', False) else 'âŒ å¤±è´¥'}")
    
    if results.get('success', False):
        if 'best_reward' in results:
            print(f"æœ€ä½³å¥–åŠ±: {results['best_reward']:.4f}")
        if 'eval_stats' in results:
            print(f"æœ€ç»ˆæˆåŠŸç‡: {results['eval_stats'].get('success_rate', 0):.4f}")
    else:
        print(f"é”™è¯¯: {results.get('error', 'Unknown error')}")
    
    # ä¿å­˜ç»“æœ
    if args.save_results and results.get('success', False):
        system.save_results(results)
    
    print("\nğŸ‰ ç»Ÿä¸€è®­ç»ƒç³»ç»Ÿè¿è¡Œå®Œæˆï¼")


if __name__ == "__main__":
    main() 