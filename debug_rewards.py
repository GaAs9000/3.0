#!/usr/bin/env python3
"""
è°ƒè¯•å¥–åŠ±ç³»ç»Ÿ - æ£€æŸ¥ä¸ºä»€ä¹ˆæ€»æ˜¯-2.0
"""

import sys
import torch
import numpy as np
sys.path.append('code/src')

from rl.reward import RewardFunction
from torch_geometric.data import HeteroData

def test_reward_calculation():
    """æµ‹è¯•å¥–åŠ±è®¡ç®—çš„è¯¦ç»†è¿‡ç¨‹"""
    print("ğŸ” è°ƒè¯•å¥–åŠ±è®¡ç®—è¿‡ç¨‹...")
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    hetero_data = HeteroData()
    hetero_data['bus'].x = torch.randn(14, 12)
    hetero_data['bus', 'connects', 'bus'].edge_index = torch.tensor([
        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],
        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
    ])
    hetero_data['bus', 'connects', 'bus'].edge_attr = torch.randn(13, 9)
    
    # æµ‹è¯•é…ç½®
    config = {
        'adaptive_quality': {
            'plateau_detection': {
                'window_size': 15,
                'min_improvement_rate': 0.005,
                'stability_threshold': 0.8,
                'min_percentile': 0.7,
                'confidence_threshold': 0.8
            },
            'efficiency_reward': {
                'lambda': 0.5,
                'early_stop_confidence': 0.85
            },
            'quality_weights': {
                'cv_weight': 0.4,
                'coupling_weight': 0.3,
                'power_weight': 0.3
            }
        }
    }
    
    # åˆ›å»ºå¥–åŠ±å‡½æ•°
    reward_function = RewardFunction(hetero_data, config=config)
    
    # æµ‹è¯•ä¸åŒçš„åˆ†åŒºçŠ¶æ€
    test_partitions = [
        torch.tensor([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3]),  # å‡åŒ€åˆ†åŒº
        torch.tensor([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3]),  # ä¸å‡åŒ€åˆ†åŒº
        torch.tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2]),  # äº¤æ›¿åˆ†åŒº
    ]
    
    for i, partition in enumerate(test_partitions):
        print(f"\n--- æµ‹è¯•åˆ†åŒº {i+1} ---")
        print(f"åˆ†åŒºåˆ†å¸ƒ: {partition.tolist()}")
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        quality_score = reward_function._compute_quality_score(partition)
        print(f"è´¨é‡åˆ†æ•°: {quality_score:.4f}")
        
        # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
        metrics = reward_function._compute_core_metrics(partition)
        print(f"CV: {metrics['cv']:.4f}")
        print(f"è€¦åˆæ¯”: {metrics['coupling_ratio']:.4f}")
        print(f"åŠŸç‡ä¸å¹³è¡¡: {metrics['power_imbalance_normalized']:.4f}")
        
        # é‡ç½®å¹¶è®¡ç®—å³æ—¶å¥–åŠ±
        reward_function.reset_episode()
        
        # ç¬¬ä¸€æ­¥ï¼ˆåº”è¯¥è¿”å›0ï¼‰
        reward1, plateau1 = reward_function.compute_incremental_reward(partition, (0, 2))
        print(f"ç¬¬ä¸€æ­¥å¥–åŠ±: {reward1:.4f}")
        
        # ç¬¬äºŒæ­¥ï¼ˆåº”è¯¥æœ‰å®é™…å¥–åŠ±ï¼‰
        reward2, plateau2 = reward_function.compute_incremental_reward(partition, (1, 3))
        print(f"ç¬¬äºŒæ­¥å¥–åŠ±: {reward2:.4f}")
        
        # è®¡ç®—ç»ˆå±€å¥–åŠ±
        final_reward, components = reward_function.compute_final_reward(partition)
        print(f"ç»ˆå±€å¥–åŠ±: {final_reward:.4f}")
        print(f"ç»ˆå±€ç»„ä»¶: {components}")

def test_action_validity():
    """æµ‹è¯•åŠ¨ä½œæœ‰æ•ˆæ€§æ£€æŸ¥"""
    print("\nğŸ” æµ‹è¯•åŠ¨ä½œæœ‰æ•ˆæ€§...")
    
    # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„æµ‹è¯•ï¼Œä½†å…ˆç®€å•æ£€æŸ¥
    print("åŠ¨ä½œæœ‰æ•ˆæ€§æ£€æŸ¥éœ€è¦å®Œæ•´çš„ç¯å¢ƒè®¾ç½®")

if __name__ == "__main__":
    test_reward_calculation()
    test_action_validity()
