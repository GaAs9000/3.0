#!/usr/bin/env python3
"""
ç”µåŠ›ç½‘ç»œåˆ†åŒºå¼ºåŒ–å­¦ä¹ æµ‹è¯•è¯„ä¼°æ¨¡å—

ä¸“é—¨ç”¨äºæ¨¡å‹æµ‹è¯•ï¼Œä¸è®­ç»ƒåˆ†ç¦»ï¼š
- è·¨ç½‘ç»œæ³›åŒ–è¯„ä¼°
- å¯è§†åŒ–åˆ†æ  
- åŸºçº¿æ–¹æ³•å¯¹æ¯”
- æ€§èƒ½æŒ‡æ ‡åˆ†æ
"""

import torch
import numpy as np
import argparse
import yaml
import os
import sys
import time
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

# æ·»åŠ è·¯å¾„
sys.path.append(str(Path(__file__).parent / 'code' / 'src'))
sys.path.append(str(Path(__file__).parent / 'code'))

from train import UnifiedTrainingSystem, load_power_grid_data


class QuickTester:
    """å¿«é€Ÿæµ‹è¯•å™¨ - ç”¨äºéªŒè¯è·¨ç½‘ç»œæ³›åŒ–è¯„ä¼°"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.system = UnifiedTrainingSystem(config_path)
        self.config = self.system.config
        self.device = self.system.device
        
        print(f"ğŸ”¬ å¿«é€Ÿæµ‹è¯•å™¨åˆå§‹åŒ–")
        print(f"   è®­ç»ƒç½‘ç»œ: {self.config['data']['case_name']}")
        print(f"   è®¾å¤‡: {self.device}")
    
    def run_generalization_test(self, num_episodes: int = 5):
        """è¿è¡Œå¿«é€Ÿè·¨ç½‘ç»œæ³›åŒ–æµ‹è¯•"""
        print(f"\nğŸŒ å¼€å§‹è·¨ç½‘ç»œæ³›åŒ–æµ‹è¯•")
        print("=" * 50)
        
        # 1. å¿«é€Ÿè®­ç»ƒæ¨¡å‹
        print("ğŸ“ å¿«é€Ÿè®­ç»ƒæ¨¡å‹...")
        training_results = self.system.run_training(mode='fast')
        
        if not training_results.get('success', False):
            print("âŒ è®­ç»ƒå¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
            return
        
        print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³å¥–åŠ±: {training_results.get('best_reward', 0):.3f}")
        
        # 2. åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        print("\nğŸ”§ åˆ›å»ºæµ‹è¯•ç¯å¢ƒ...")
        agent, env = self._create_test_env()
        
        # 3. è·¨ç½‘ç»œæ³›åŒ–æµ‹è¯•
        print(f"\nğŸ” è·¨ç½‘ç»œæ³›åŒ–æµ‹è¯• (æ¯ä¸ªç½‘ç»œ{num_episodes}è½®)...")
        
        train_case = self.config['data']['case_name']
        test_cases = ['ieee14', 'ieee30', 'ieee57']
        test_cases = [case for case in test_cases if case != train_case][:2]  # åªæµ‹è¯•2ä¸ªç½‘ç»œèŠ‚çœæ—¶é—´
        
        print(f"   è®­ç»ƒç½‘ç»œ: {train_case}")
        print(f"   æµ‹è¯•ç½‘ç»œ: {test_cases}")
        
        results = []
        
        for test_case in test_cases:
            print(f"\n   ğŸ” æµ‹è¯• {test_case.upper()}...")
            
            try:
                # ç®€åŒ–çš„è·¨ç½‘ç»œæµ‹è¯•
                test_result = self._simple_cross_network_test(agent, test_case, num_episodes)
                results.append({
                    'network': test_case,
                    'success_rate': test_result['success_rate'],
                    'avg_reward': test_result['avg_reward']
                })
                
                # å³æ—¶åé¦ˆ
                if test_result['success_rate'] > 0.4:
                    status = "ğŸ‰ ä¼˜ç§€æ³›åŒ–"
                elif test_result['success_rate'] > 0.2:
                    status = "âœ… è‰¯å¥½æ³›åŒ–"
                else:
                    status = "âš ï¸ éœ€è¦æ”¹è¿›"
                
                print(f"     ç»“æœ: æˆåŠŸç‡ {test_result['success_rate']:.1%}, å¹³å‡å¥–åŠ± {test_result['avg_reward']:.3f} - {status}")
                
            except Exception as e:
                print(f"     âŒ æµ‹è¯•å¤±è´¥: {e}")
                results.append({
                    'network': test_case,
                    'success_rate': 0.0,
                    'avg_reward': -10.0,
                    'error': str(e)
                })
        
        # 4. æ€»ç»“ç»“æœ
        self._print_quick_summary(train_case, results)
        
        return results
    
    def _create_test_env(self):
        """åˆ›å»ºæµ‹è¯•ç¯å¢ƒå’Œæ™ºèƒ½ä½“"""
        from code.src.data_processing import PowerGridDataProcessor
        from code.src.gat import create_hetero_graph_encoder
        from code.src.rl.environment import PowerGridPartitioningEnv
        from code.src.rl.agent import PPOAgent
        
        # æ•°æ®å¤„ç†
        processor = PowerGridDataProcessor(
            normalize=self.config['data']['normalize'],
            cache_dir=self.config['data']['cache_dir']
        )
        mpc = load_power_grid_data(self.config['data']['case_name'])
        hetero_data = processor.graph_from_mpc(mpc, self.config).to(self.device)
        
        # GATç¼–ç å™¨
        gat_config = self.config['gat']
        encoder = create_hetero_graph_encoder(
            hetero_data,
            hidden_channels=gat_config['hidden_channels'],
            gnn_layers=gat_config['gnn_layers'],
            heads=gat_config['heads'],
            output_dim=gat_config['output_dim']
        ).to(self.device)
        
        with torch.no_grad():
            node_embeddings, attention_weights = encoder.encode_nodes_with_attention(hetero_data, self.config)
        
        # ç¯å¢ƒ
        env_config = self.config['environment']
        env = PowerGridPartitioningEnv(
            hetero_data=hetero_data,
            node_embeddings=node_embeddings,
            num_partitions=env_config['num_partitions'],
            reward_weights=env_config['reward_weights'],
            max_steps=env_config['max_steps'],
            device=self.device,
            attention_weights=attention_weights,
            config=self.config
        )
        
        # æ™ºèƒ½ä½“
        agent_config = self.config['agent']
        node_embedding_dim = env.state_manager.embedding_dim
        region_embedding_dim = node_embedding_dim * 2
        
        agent = PPOAgent(
            node_embedding_dim=node_embedding_dim,
            region_embedding_dim=region_embedding_dim,
            num_partitions=env.num_partitions,
            lr_actor=agent_config['lr_actor'],
            lr_critic=agent_config['lr_critic'],
            gamma=agent_config['gamma'],
            eps_clip=agent_config['eps_clip'],
            k_epochs=agent_config['k_epochs'],
            entropy_coef=agent_config['entropy_coef'],
            value_coef=agent_config['value_coef'],
            device=self.device
        )
        
        return agent, env
    
    def _simple_cross_network_test(self, agent, test_case: str, num_episodes: int):
        """ç®€åŒ–çš„è·¨ç½‘ç»œæµ‹è¯•"""
        # åŠ è½½æµ‹è¯•ç½‘ç»œ
        test_mpc = load_power_grid_data(test_case)
        
        # åˆ›å»ºæµ‹è¯•é…ç½®
        test_config = self.config.copy()
        test_config['data']['case_name'] = test_case
        
        # åŠ¨æ€è°ƒæ•´åˆ†åŒºæ•°
        test_bus_count = test_mpc['bus'].shape[0]
        if test_bus_count <= 14:
            test_partitions = 3
        elif test_bus_count <= 30:
            test_partitions = 4
        else:
            test_partitions = 5
        
        test_config['environment']['num_partitions'] = test_partitions
        
        # å¿«é€Ÿåˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        from code.src.data_processing import PowerGridDataProcessor
        from code.src.gat import create_hetero_graph_encoder
        from code.src.rl.environment import PowerGridPartitioningEnv
        
        processor = PowerGridDataProcessor(
            normalize=test_config['data']['normalize'],
            cache_dir=test_config['data']['cache_dir']
        )
        
        test_hetero_data = processor.graph_from_mpc(test_mpc, test_config).to(self.device)
        
        gat_config = test_config['gat']
        test_encoder = create_hetero_graph_encoder(
            test_hetero_data,
            hidden_channels=gat_config['hidden_channels'],
            gnn_layers=gat_config['gnn_layers'],
            heads=gat_config['heads'],
            output_dim=gat_config['output_dim']
        ).to(self.device)
        
        with torch.no_grad():
            test_node_embeddings, test_attention_weights = test_encoder.encode_nodes_with_attention(
                test_hetero_data, test_config
            )
        
        test_env = PowerGridPartitioningEnv(
            hetero_data=test_hetero_data,
            node_embeddings=test_node_embeddings,
            num_partitions=test_partitions,
            reward_weights=test_config['environment']['reward_weights'],
            max_steps=test_config['environment']['max_steps'],
            device=self.device,
            attention_weights=test_attention_weights,
            config=test_config
        )
        
        print(f"       ç¯å¢ƒ: {test_env.total_nodes}èŠ‚ç‚¹ â†’ {test_partitions}åˆ†åŒº")
        
        # è¯„ä¼°
        eval_rewards = []
        success_count = 0
        
        for episode in range(num_episodes):
            state, _ = test_env.reset()
            episode_reward = 0
            episode_info = {}
            
            for step in range(200):
                action, _, _ = agent.select_action(state, training=False)
                if action is None:
                    break
                
                state, reward, terminated, truncated, info = test_env.step(action)
                done = terminated or truncated
                episode_reward += reward
                
                if info:
                    episode_info.update(info)
                
                if done:
                    break
            
            eval_rewards.append(episode_reward)
            
            # è¯„ä¼°æˆåŠŸ
            is_success = self._evaluate_success(episode_reward, episode_info)
            if is_success:
                success_count += 1
        
        return {
            'success_rate': success_count / num_episodes,
            'avg_reward': np.mean(eval_rewards)
        }
    
    def _evaluate_success(self, episode_reward: float, episode_info: Dict[str, Any]) -> bool:
        """è¯„ä¼°æˆåŠŸæ ‡å‡†"""
        if episode_reward > -1.0:
            return True
        
        if episode_info and 'metrics' in episode_info:
            metrics = episode_info['metrics']
            cv = metrics.get('cv', metrics.get('load_cv', 1.0))
            if cv < 0.5:
                return True
        
        if episode_reward > -2.5:
            return True
        
        return False
    
    def _print_quick_summary(self, train_case: str, results: List[Dict]):
        """æ‰“å°å¿«é€Ÿæµ‹è¯•æ€»ç»“"""
        try:
            from rich.console import Console
            from rich.table import Table
            from rich.panel import Panel
            
            console = Console()
            
            # åˆ›å»ºç»“æœè¡¨æ ¼
            table = Table(title="ğŸŒ è·¨ç½‘ç»œæ³›åŒ–æµ‹è¯•ç»“æœ", show_header=True, header_style="bold cyan")
            table.add_column("æµ‹è¯•ç½‘ç»œ", style="bold")
            table.add_column("æˆåŠŸç‡", justify="center")
            table.add_column("å¹³å‡å¥–åŠ±", justify="center")
            table.add_column("æ³›åŒ–è¯„ä»·", justify="center")
            
            total_success_rate = 0
            valid_count = 0
            
            for result in results:
                network = result['network']
                success_rate = result['success_rate']
                avg_reward = result['avg_reward']
                
                if 'error' not in result:
                    total_success_rate += success_rate
                    valid_count += 1
                
                if success_rate > 0.4:
                    evaluation = "ğŸ‰ ä¼˜ç§€"
                    style = "bold green"
                elif success_rate > 0.2:
                    evaluation = "âœ… è‰¯å¥½"
                    style = "green"
                elif success_rate > 0.1:
                    evaluation = "âš ï¸ æœ‰é™"
                    style = "yellow"
                else:
                    evaluation = "âŒ ä¸è¶³"
                    style = "red"
                
                table.add_row(
                    network.upper(),
                    f"[{style}]{success_rate:.1%}[/{style}]",
                    f"[{style}]{avg_reward:.3f}[/{style}]",
                    evaluation
                )
            
            # è®¡ç®—æ€»ä½“æ³›åŒ–åˆ†æ•°
            overall_success_rate = total_success_rate / valid_count if valid_count > 0 else 0
            
            if overall_success_rate > 0.4:
                overall_status = "[bold green]ğŸŒŸ ä¼˜ç§€æ³›åŒ–èƒ½åŠ›[/bold green]"
            elif overall_success_rate > 0.2:
                overall_status = "[green]âœ… è‰¯å¥½æ³›åŒ–èƒ½åŠ›[/green]"
            elif overall_success_rate > 0.1:
                overall_status = "[yellow]âš ï¸ æœ‰é™æ³›åŒ–èƒ½åŠ›[/yellow]"
            else:
                overall_status = "[red]âŒ æ³›åŒ–èƒ½åŠ›ä¸è¶³[/red]"
            
            console.print(table)
            
            # æ€»ç»“é¢æ¿
            summary_text = f"è®­ç»ƒç½‘ç»œ: {train_case.upper()}\n"
            summary_text += f"æµ‹è¯•ç½‘ç»œ: {len(results)}ä¸ª\n"
            summary_text += f"å¹³å‡æˆåŠŸç‡: {overall_success_rate:.1%}\n"
            summary_text += f"æ€»ä½“è¯„ä»·: {overall_status}"
            
            console.print(Panel(summary_text, title="ğŸ“Š æ³›åŒ–èƒ½åŠ›æ€»ç»“", border_style="blue"))
            
        except ImportError:
            # å¤‡ç”¨è¾“å‡º
            print(f"\nğŸ“Š è·¨ç½‘ç»œæ³›åŒ–æµ‹è¯•æ€»ç»“:")
            print(f"   è®­ç»ƒç½‘ç»œ: {train_case}")
            
            total_success_rate = 0
            valid_count = 0
            
            for result in results:
                network = result['network']
                success_rate = result['success_rate']
                
                if 'error' not in result:
                    total_success_rate += success_rate
                    valid_count += 1
                
                print(f"   {network}: æˆåŠŸç‡ {success_rate:.1%}")
            
            overall_success_rate = total_success_rate / valid_count if valid_count > 0 else 0
            print(f"   æ€»ä½“æ³›åŒ–èƒ½åŠ›: {overall_success_rate:.1%}")

    def generate_performance_dashboard(self, test_results: List[Dict], output_filename: Optional[str] = None) -> Optional[Path]:
        """
        ç”Ÿæˆæ€§èƒ½åˆ†æHTMLä»ªè¡¨æ¿

        Args:
            test_results: æµ‹è¯•ç»“æœæ•°æ®
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

        Returns:
            ç”Ÿæˆçš„HTMLæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥åˆ™è¿”å›None
        """
        try:
            from code.src.html_dashboard_generator import HTMLDashboardGenerator

            # åˆ›å»ºHTMLä»ªè¡¨æ¿ç”Ÿæˆå™¨
            dashboard_config = self.config.get('html_dashboard', {})
            generator = HTMLDashboardGenerator(dashboard_config)

            # å‡†å¤‡æµ‹è¯•æ•°æ®
            networks = [result['network'] for result in test_results]
            success_rates = [result['success_rate'] for result in test_results if 'error' not in result]
            avg_rewards = [result['avg_reward'] for result in test_results if 'error' not in result]

            # è®¡ç®—æ€»ä½“æŒ‡æ ‡
            overall_success_rate = np.mean(success_rates) if success_rates else 0
            overall_avg_reward = np.mean(avg_rewards) if avg_rewards else 0

            performance_data = {
                'test_type': 'cross_network_generalization',
                'train_network': self.config['data']['case_name'],
                'test_networks': networks,
                'success_rates': success_rates,
                'avg_rewards': avg_rewards,
                'overall_success_rate': overall_success_rate,
                'overall_avg_reward': overall_avg_reward,
                'test_results': test_results,
                'config': self.config,
                'session_name': f"Performance_Test_{time.strftime('%Y%m%d_%H%M%S')}"
            }

            # ç”ŸæˆHTMLä»ªè¡¨æ¿
            html_path = generator.generate_performance_dashboard(
                performance_data, output_filename
            )

            return html_path

        except Exception as e:
            print(f"âš ï¸ æ€§èƒ½åˆ†æä»ªè¡¨æ¿ç”Ÿæˆå¤±è´¥: {e}")
            return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”µåŠ›ç½‘ç»œåˆ†åŒºRLæ¨¡å‹æµ‹è¯•ç³»ç»Ÿ')
    
    parser.add_argument('--config', type=str, default=None, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--episodes', type=int, default=5, help='æ¯ä¸ªæµ‹è¯•çš„è¯„ä¼°å›åˆæ•°')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿè·¨ç½‘ç»œæ³›åŒ–æµ‹è¯•')
    
    args = parser.parse_args()
    
    try:
        print("ğŸ”¬ å¯åŠ¨æ¨¡å‹æµ‹è¯•ç³»ç»Ÿ")
        print("=" * 50)
        
        if args.quick:
            # å¿«é€Ÿæ³›åŒ–æµ‹è¯•
            tester = QuickTester(config_path=args.config)
            results = tester.run_generalization_test(num_episodes=args.episodes)

            # ç”Ÿæˆæ€§èƒ½åˆ†æHTMLä»ªè¡¨æ¿
            print(f"\nğŸ“Š ç”Ÿæˆæ€§èƒ½åˆ†æä»ªè¡¨æ¿...")
            html_path = tester.generate_performance_dashboard(results)
            if html_path:
                print(f"âœ… æ€§èƒ½åˆ†æä»ªè¡¨æ¿å·²ç”Ÿæˆ: {html_path}")

            print(f"\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
            print(f"ğŸ’¡ ä½¿ç”¨ 'python test.py --help' æŸ¥çœ‹æ›´å¤šæµ‹è¯•é€‰é¡¹")
            
        else:
            print("ğŸ“‹ å®Œæ•´æµ‹è¯•åŠŸèƒ½å¼€å‘ä¸­...")
            print("ğŸš€ å½“å‰å¯ç”¨:")
            print("   python test.py --quick           # å¿«é€Ÿè·¨ç½‘ç»œæ³›åŒ–æµ‹è¯•")
            print("   python test.py --quick --episodes 10  # æ›´å¤šæµ‹è¯•å›åˆ")
        
        return 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
